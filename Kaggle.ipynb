{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoD7CxBn+1cifkMuvRhL6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/Laboratorio3/blob/main/Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modulos"
      ],
      "metadata": {
        "id": "crj3eqSV_WvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "eL3soxEh_cgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ColabNotebook = 'google.colab' in str(get_ipython())\n",
        "\n",
        "# if ColabNotebook: # maquina virtual colab\n",
        "#     # monta G-drive en entorno COLAB\n",
        "#     from google.colab import drive\n",
        "#     drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "HkJAzqZfivZx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore', category=ValueWarning)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Asegurarte de que Pandas muestre los valores con la máxima precisión\n",
        "pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
        "\n",
        "# Ajustar la opción para mostrar más filas\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Si también quieres mostrar más columnas\n",
        "pd.set_option('display.max_columns', 20)\n",
        "\n",
        "\n",
        "# Vamos a suprimir la notacion cientifica\n",
        "pd.set_option(\"display.float_format\", lambda x:\"%.2f\" %x)\n",
        "\n",
        "\n",
        "def print_ds(ds, take=3):\n",
        "    for ex in ds.take(take):\n",
        "        print(ex)\n"
      ],
      "metadata": {
        "id": "4dKLvveO9QDs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga Datos"
      ],
      "metadata": {
        "id": "CCBiyQvD_nC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local"
      ],
      "metadata": {
        "id": "rhxib23DtW_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Code to read csv file into Colaboratory:\n",
        "# # # !pip install -U -q PyDrive\n",
        "# # from pydrive.auth import GoogleAuth\n",
        "# # from pydrive.drive import GoogleDrive\n",
        "# # from google.colab import auth, drive\n",
        "# # from oauth2client.client import GoogleCredentials\n",
        "# #\n",
        "# # # Authenticate and create the PyDrive client.\n",
        "# # auth.authenticate_user()\n",
        "# # gauth = GoogleAuth()\n",
        "# # gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# # drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "\n",
        "# ################################# Datasets ###################################\n",
        "# # # Ventas\n",
        "# # id = \"158aOjqxaNO8l97yA6VWJkek_15YVLMhs\"\n",
        "# # downloaded = drive.CreateFile({'id':id})\n",
        "# # downloaded.GetContentFile('sell-in.txt')\n",
        "# data_ventas = pd.read_csv(\"G:\\\\My Drive\\\\Colab Notebooks\\\\Data\\\\Labo3\\\\sell-in.txt\", sep=\"\\t\")\n",
        "# data_ventas['periodo'] = pd.to_datetime(data_ventas['periodo'], format='%Y%m')\n",
        "# data_ventas['customer_id'] = data_ventas['customer_id'].astype(str)\n",
        "# data_ventas['product_id'] = data_ventas['product_id'].astype(str)\n",
        "# data = data_ventas.copy()\n",
        "# data.set_index('periodo', inplace=True)\n",
        "# data_bkp = data.copy()\n",
        "\n",
        "# # # # Productos\n",
        "# # id = \"15JS_k86LS0sgJXma7BOVXWlyNcMwxdhE\"\n",
        "# # downloaded = drive.CreateFile({'id':id})\n",
        "# # downloaded.GetContentFile('tb_productos.txt')\n",
        "# data_productos = pd.read_csv(\"G:\\\\My Drive\\\\Colab Notebooks\\\\Data\\\\Labo3\\\\tb_productos.txt\", sep=\"\\t\")\n",
        "# data_productos['product_id'] = data_productos['product_id'].astype(str)\n",
        "\n",
        "# # # # Stocks\n",
        "# # id = \"15EV-8f_U7onpA1AcTxxXeD-z8yVR4fQu\"\n",
        "# # downloaded = drive.CreateFile({'id':id})\n",
        "# # downloaded.GetContentFile('G:\\\\My Drive\\\\Colab Notebooks\\\\Data\\\\Labo3\\\\tb_stocks.txt')\n",
        "# data_stocks = pd.read_csv('G:\\\\My Drive\\\\Colab Notebooks\\\\Data\\\\Labo3\\\\tb_stocks.txt', sep=\"\\t\")\n",
        "# data_stocks['periodo'] = pd.to_datetime(data_stocks['periodo'], format='%Y%m')\n",
        "# data_stocks['product_id'] = data_stocks['product_id'].astype(str)\n",
        "\n",
        "# # # # Productos a predecir\n",
        "# # id = \"15LjADctFVwjzQFJvfJGFTEdgZx9xCoId\"\n",
        "# # downloaded = drive.CreateFile({'id':id})\n",
        "# # downloaded.GetContentFile('productos_a_predecir.txt')\n",
        "# data_productos_a_predecir = pd.read_csv(\"G:\\\\My Drive\\\\Colab Notebooks\\\\Data\\\\Labo3\\\\productos_a_predecir.txt\", sep=\"\\t\")\n",
        "# data_productos_a_predecir['product_id'] = data_productos_a_predecir['product_id'].astype(str)\n",
        "# data_productos_a_predecir.set_index('product_id', inplace=True)\n",
        "# # data_productos_a_predecir_con_categorias = data_productos_a_predecir.set_index('product_id').join(data_productos.drop_duplicates('product_id').set_index('product_id').sort_index()[['cat1', 'cat2', 'cat3']]) # Esta mal\n",
        "# data_productos_a_predecir_con_categorias = data_productos_a_predecir.join(data_productos.drop_duplicates('product_id').set_index('product_id').sort_index()[['cat1', 'cat2', 'cat3']])\n"
      ],
      "metadata": {
        "id": "jzQavP-RtCH2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab"
      ],
      "metadata": {
        "id": "04LDga8vtOpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "# !pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth, drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "\n",
        "################################# Datasets ###################################\n",
        "# # Ventas\n",
        "id = \"158aOjqxaNO8l97yA6VWJkek_15YVLMhs\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('sell-in.txt')\n",
        "data_ventas = pd.read_csv(\"sell-in.txt\", sep=\"\\t\")\n",
        "data_ventas['periodo'] = pd.to_datetime(data_ventas['periodo'], format='%Y%m')\n",
        "data_ventas['customer_id'] = data_ventas['customer_id'].astype(str)\n",
        "data_ventas['product_id'] = data_ventas['product_id'].astype(str)\n",
        "data = data_ventas.copy()\n",
        "data.set_index('periodo', inplace=True)\n",
        "data_bkp = data.copy()\n",
        "\n",
        "# # Productos\n",
        "id = \"15JS_k86LS0sgJXma7BOVXWlyNcMwxdhE\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_productos.txt')\n",
        "data_productos = pd.read_csv(\"tb_productos.txt\", sep=\"\\t\")\n",
        "data_productos['product_id'] = data_productos['product_id'].astype(str)\n",
        "\n",
        "# # Stocks\n",
        "id = \"15EV-8f_U7onpA1AcTxxXeD-z8yVR4fQu\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_stocks.txt')\n",
        "data_stocks = pd.read_csv(\"tb_stocks.txt\", sep=\"\\t\")\n",
        "data_stocks['periodo'] = pd.to_datetime(data_stocks['periodo'], format='%Y%m')\n",
        "data_stocks['product_id'] = data_stocks['product_id'].astype(str)\n",
        "\n",
        "# # Productos a predecir\n",
        "id = \"15LjADctFVwjzQFJvfJGFTEdgZx9xCoId\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('productos_a_predecir.txt')\n",
        "data_productos_a_predecir = pd.read_csv(\"productos_a_predecir.txt\", sep=\"\\t\")\n",
        "data_productos_a_predecir['product_id'] = data_productos_a_predecir['product_id'].astype(str)\n",
        "\n",
        "# # BASELINE modelo loco 1, 303 Public y 249 Private\n",
        "id = \"1Ai0WKKKyvU98vMUJHacCditl4TFNDNJV\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('modelo_loco (1)_303_249.csv')\n",
        "BASELINE = pd.read_csv(\"modelo_loco (1)_303_249.csv\")\n",
        "BASELINE.set_index('product_id', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# # Agregado 06/15, Ojo que puede romper en algun lado ya que antes no usaba el product_id como index\n",
        "data_productos_a_predecir_index = data_productos_a_predecir.set_index('product_id', inplace=True)\n",
        "# # No va\n",
        "# data_productos_a_predecir.set_index('product_id', inplace=True)\n",
        "\n",
        "\n",
        "# Comentado por las dudas 06/15\n",
        "# data_productos_a_predecir_con_categorias = data_productos_a_predecir.join(data_productos.drop_duplicates('product_id').set_index('product_id').sort_index()[['cat1', 'cat2', 'cat3']])\n",
        "\n",
        "\n",
        "# # Productos con Categorias extendidas\n",
        "id = \"1Bsn6voCvDogW4TGMu1LCYmUfqc3aurjw\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_productos_descripcion.txt')\n",
        "data_productos_con_categorias = pd.read_csv(\"tb_productos_descripcion.txt\", sep=\"\\t\")\n",
        "data_productos_con_categorias['product_id'] = data_productos_con_categorias['product_id'].astype(str)\n",
        "\n",
        "# # Hago el join de todos los datos brutos, y de las categorias extendidas\n",
        "data['periodo'] = data.index\n",
        "data_extended = pd.merge(data, data_productos_con_categorias, on='product_id', how='left')\n",
        "data_extended.set_index('periodo', inplace=True)\n",
        "data.drop(columns='periodo', inplace=True) # Elimino el index como columna del Dataframe original\n",
        "\n",
        "# Elimino los productos de la Categoria1 REF\n",
        "data_extended = data_extended[data_extended['cat1'] != 'REF']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8GISdopF_obd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d18270-cd28-4be3-a686-3246373c263b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Functions"
      ],
      "metadata": {
        "id": "dJckQiyL08r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################################################\n",
        "def filter_products_data_grouped(data_grouped, data_productos_a_predecir):\n",
        "    \"\"\"\n",
        "    Filtra las columnas del DataFrame 'data_grouped' para que solo contenga los productos especificados en 'data_productos_a_predecir'.\n",
        "\n",
        "    Parameters:\n",
        "    data_grouped (pd.DataFrame): DataFrame con los 'product_id' como nombres de columna.\n",
        "    data_productos_a_predecir (pd.DataFrame): DataFrame donde 'product_id' es el índice y contiene los productos de interés.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame filtrado que solo contiene los productos especificados en 'data_productos_a_predecir'.\n",
        "    \"\"\"\n",
        "    productos_interes = data_productos_a_predecir.index\n",
        "    data_filtrada = data_grouped[productos_interes]\n",
        "    return data_filtrada\n",
        "##############################################################################\n",
        "def filter_products_data(data, data_productos_a_predecir):\n",
        "    \"\"\"\n",
        "    Filtra el DataFrame 'data' para que solo contenga los productos especificados en 'data_productos_a_predecir'.\n",
        "\n",
        "    Parameters:\n",
        "    data (pd.DataFrame): DataFrame original que contiene una columna 'product_id'.\n",
        "    data_productos_a_predecir (pd.DataFrame): DataFrame donde 'product_id' es el índice y contiene los productos de interés.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame filtrado que solo contiene los productos especificados en 'data_productos_a_predecir'.\n",
        "    \"\"\"\n",
        "    productos_interes = data_productos_a_predecir.index\n",
        "    data_filtrada = data[data['product_id'].isin(productos_interes)]\n",
        "    return data_filtrada\n",
        "##############################################################################\n",
        "def filter_active_clients_data(df, show_plot=False):\n",
        "  presencia_clientes = df.groupby(['periodo', 'customer_id']).size().unstack(fill_value=0)\n",
        "  # Convertimos las cantidades en 1 para indicar presencia\n",
        "  presencia_clientes[presencia_clientes > 0] = 1\n",
        "  # Creamos la Maskara, en este caso para los ultimos 3 meses\n",
        "  mask_active_clients = presencia_clientes.loc['2019-10':'2019-12'].sum(axis=0) == 3\n",
        "  # Filtramos y devolvemos el Dataset\n",
        "  active_data = df[df['customer_id'].isin(mask_active_clients[mask_active_clients].index)]\n",
        "\n",
        "  if show_plot:\n",
        "    # Configuramos el tamaño de la figura\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Creamos el heatmap\n",
        "    sns.heatmap(presencia_clientes, cmap='viridis', cbar=False, linewidths=.5)\n",
        "\n",
        "    # Añadimos los títulos y etiquetas\n",
        "    plt.title('Presencia de Clientes por Mes')\n",
        "    plt.xlabel('Clientes')\n",
        "    plt.ylabel('Mes')\n",
        "\n",
        "    # Mostramos el gráfico\n",
        "    plt.show()\n",
        "\n",
        "  return active_data\n",
        "##############################################################################\n",
        "def filter_data_por_categoria(df, categoria, categoria_columna):\n",
        "    \"\"\"\n",
        "    Filtra los productos de un DataFrame dado una categoría y el DataFrame de productos con categorías.\n",
        "\n",
        "    Args:\n",
        "    dataframe (pd.DataFrame): DataFrame con las ventas de productos (cada columna es un product_id).\n",
        "    categoria (str): Categoría a filtrar (valor de cat1, cat2 o cat3).\n",
        "    categoria_columna (str): Nombre de la columna de categoría ('cat1', 'cat2' o 'cat3').\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame filtrado con solo los productos de la categoría especificada.\n",
        "    \"\"\"\n",
        "    # Filtrar los productos que pertenecen a la categoría especificada\n",
        "    productos_filtrados = data_productos_a_predecir_con_categorias[data_productos_a_predecir_con_categorias[categoria_columna] == categoria].index\n",
        "\n",
        "    # Filtrar el DataFrame de ventas usando los product_ids de los productos filtrados\n",
        "    productos_en_data = [col for col in df.columns if col in productos_filtrados]\n",
        "    df_filtrado = df[productos_en_data]\n",
        "\n",
        "    return df_filtrado\n",
        "##############################################################################\n",
        "# def filter_dataframe(dataframe, boolean_series):\n",
        "#     # Verificar que los índices de la Serie booleana y del DataFrame coinciden\n",
        "#     if not boolean_series.index.equals(dataframe.columns):\n",
        "#         raise ValueError(\"Los índices de la Serie booleana y las columnas del DataFrame no coinciden\")\n",
        "\n",
        "#     # Filtrar el DataFrame usando la Serie booleana\n",
        "#     filtered_dataframe = dataframe.loc[:, boolean_series]\n",
        "\n",
        "#     return filtered_dataframe\n",
        "# ##############################################################################\n",
        "# def filter_products_grouped(data_grouped, data_productos_a_predecir):\n",
        "#     # Obtener la lista de product_id a predecir\n",
        "#     product_ids = data_productos_a_predecir.index.tolist()\n",
        "\n",
        "#     # Filtrar el DataFrame original por los product_id\n",
        "#     data_filtrada = data_grouped[product_ids]\n",
        "\n",
        "#     return data_filtrada"
      ],
      "metadata": {
        "id": "nnSdLDk60-bO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Functions"
      ],
      "metadata": {
        "id": "w-TmJKaCP5gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "def plot_grouped_data_heatmap(df, eje_x):\n",
        "  presencia = df.groupby(['periodo', eje_x]).size().unstack(fill_value=0)\n",
        "  presencia[presencia > 0] = 1\n",
        "\n",
        "  # Configuramos el tamaño de la figura\n",
        "  plt.figure(figsize=(20, 10))\n",
        "  # Creamos el heatmap\n",
        "  sns.heatmap(presencia, cmap='viridis', cbar=False, linewidths=.5)\n",
        "#############################################################################\n",
        "def plot_products_sales(df, start=None, end=50, show_plot=True):\n",
        "    # Agrupa los datos por 'periodo' y 'product_id', luego deshace la pila para obtener una tabla con valores 0 o 1\n",
        "    presencia_productos = df.groupby(['periodo', 'product_id']).size().unstack(fill_value=0)\n",
        "    presencia_productos[presencia_productos > 0] = 1\n",
        "    subset = presencia_productos.iloc[:, start:end]  # Selecciona el subconjunto de productos para graficar\n",
        "\n",
        "    productos_decomisados = []  # Lista para productos que dejaron de venderse\n",
        "    productos_nuevos = []  # Lista para productos que empezaron a venderse después del inicio\n",
        "\n",
        "    if show_plot:\n",
        "        # Crear el gráfico de líneas\n",
        "        plt.figure(figsize=(20, 10))\n",
        "\n",
        "        for column in subset.columns:\n",
        "            series = subset[column]\n",
        "            # Detectar los meses con presencia\n",
        "            presencia = series == 1\n",
        "\n",
        "        # Resaltar productos que no se vendieron algún mes y añadir a la leyenda\n",
        "        for column in subset.columns:\n",
        "            series = subset[column]\n",
        "            if (series == 0).any():  # Verificar si hubo algún mes sin ventas para el producto\n",
        "                plt.plot(series.index, series, label=f\"{column} (sin ventas)\")\n",
        "                if series.iloc[0] == 1 and (series == 0).any():  # Producto que dejó de venderse\n",
        "                    productos_decomisados.append(column)\n",
        "                if series.iloc[0] == 0 and (series == 1).any():  # Producto que empezó a venderse después\n",
        "                    productos_nuevos.append(column)\n",
        "\n",
        "        # Añadir solo los productos sin ventas a la leyenda\n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        new_handles = [handle for handle, label in zip(handles, labels) if '(sin ventas)' in label]\n",
        "        new_labels = [label for label in labels if '(sin ventas)' in label]\n",
        "\n",
        "        # Añadir título y etiquetas a los ejes\n",
        "        plt.title('Ausencia de Ventas por Productos')\n",
        "        plt.xlabel('Mes')\n",
        "        plt.ylabel('Presencia (1 = Sí, 0 = No)')\n",
        "        plt.legend(new_handles, new_labels, loc='upper right', bbox_to_anchor=(1.15, 1))  # Posicionar la leyenda\n",
        "        plt.show()  # Mostrar el gráfico\n",
        "\n",
        "    # Calcular las listas de productos decomisados y nuevos aunque no se muestre el gráfico\n",
        "    for column in subset.columns:\n",
        "        series = subset[column]\n",
        "        if (series == 0).any():\n",
        "            if series.iloc[0] == 1 and (series == 0).any():  # Producto que dejó de venderse\n",
        "                productos_decomisados.append(column)\n",
        "            if series.iloc[0] == 0 and (series == 1).any():  # Producto que empezó a venderse después\n",
        "                productos_nuevos.append(column)\n",
        "\n",
        "    return productos_decomisados, productos_nuevos  # Devolver las listas de productos decomisados y nuevos\n",
        "#############################################################################\n",
        "def plot_history(history, start_epoch=0, metrics=None):\n",
        "    if isinstance(metrics, str):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    if metrics is None:\n",
        "        metrics = [x for x in history.history.keys() if x[:4] != 'val_']\n",
        "\n",
        "    if len(metrics) == 0:\n",
        "        print('No metrics to display.')\n",
        "        return\n",
        "\n",
        "    # Get the epochs and filter them starting from start_epoch\n",
        "    x = history.epoch[start_epoch:]\n",
        "\n",
        "    rows = 1\n",
        "    cols = len(metrics)\n",
        "    count = 0\n",
        "\n",
        "    plt.figure(figsize=(12 * cols, 8))\n",
        "\n",
        "    for metric in sorted(metrics):\n",
        "        count += 1\n",
        "        plt.subplot(rows, cols, count)\n",
        "        plt.plot(x, history.history[metric][start_epoch:], label='Train')\n",
        "        val_metric = f'val_{metric}'\n",
        "        if val_metric in history.history.keys():\n",
        "            plt.plot(x, history.history[val_metric][start_epoch:], label='Validation')\n",
        "        plt.title(metric.capitalize())\n",
        "        plt.legend()\n",
        "    plt.show()\n",
        "################################################################\n",
        "def plot_predictions(data_all, predictions):\n",
        "  data_conc = pd.concat([data_all, predictions])\n",
        "  separation = data_all.index[-1]\n",
        "\n",
        "  # Crear una figura y un eje\n",
        "  fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "  # Plotear toda la serie con un color\n",
        "  ax.plot(data_conc.index, data_conc.values, label='Datos', color='blue')\n",
        "\n",
        "  ax.axvline(x=separation, color='green', linestyle='--', label='Fecha de separación')\n",
        "\n",
        "  # Sobrescribir los últimos dos elementos con un color diferente\n",
        "  ax.plot(data_conc.index[-3:], data_conc.values[-3:], color='red')\n",
        "\n",
        "  # Añadir texto para la fecha de separación\n",
        "  ax.text(separation, ax.get_ylim()[1], separation.strftime('%Y-%m'),\n",
        "            color='green', verticalalignment='bottom', horizontalalignment='right')\n",
        "\n",
        "  # Añadir leyenda y mostrar el gráfico\n",
        "  ax.legend(['Datos', 'Predicciones'])\n",
        "  plt.show()\n",
        "  display(predictions)\n",
        "  ################################################################\n",
        "def plot_predictions_dec2019(data_all, predictions_original):\n",
        "  separation = data_all.index[-3]\n",
        "  predictions_updated = pd.concat([data_all.loc['2019-10'], predictions_original])\n",
        "\n",
        "  # Crear una figura y un eje\n",
        "  fig, ax = plt.subplots(figsize=(15, 6))\n",
        "\n",
        "  # Plotear toda la serie con un color\n",
        "  ax.plot(data_all.index, data_all.values, label='Datos', color='blue')\n",
        "\n",
        "  # Sobrescribir los últimos dos elementos con un color diferente\n",
        "  ax.plot(predictions_updated.index, predictions_updated.values, color='red', label='Predicciones')\n",
        "\n",
        "  # Linea de corte\n",
        "  ax.axvline(x=separation, color='black', linestyle='--', linewidth=0.5)\n",
        "\n",
        "  # Añadir texto para la fecha de corte\n",
        "  ax.text(separation, ax.get_ylim()[1], separation.strftime('%Y-%m'),\n",
        "            color='black', verticalalignment='bottom', horizontalalignment='right')\n",
        "\n",
        "  # Añadir una línea horizontal en el último valor de predictions_updated\n",
        "  ax.axhline(y=predictions_updated.iloc[-1], color='green', linestyle='--', linewidth=1)\n",
        "\n",
        "  # Calculo la Diferencia\n",
        "  diff =  np.round((predictions.iloc[-1] - data_all.iloc[-1]) / data_all.iloc[-1] * 100, 2)\n",
        "\n",
        "  # Añadir leyenda y mostrar el gráfico\n",
        "  ax.legend()\n",
        "  plt.title(f'Producto: {predictions.name}, Diferencia en la prediccion %{diff}')\n",
        "  plt.show()\n",
        "  print('Real value:', data_all.iloc[-1])\n",
        "  print(predictions)\n",
        "\n",
        "#############################################################################"
      ],
      "metadata": {
        "id": "vVoxNL0mP5od"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Data"
      ],
      "metadata": {
        "id": "5L-kvH-J_7SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Siempre como values toma las toneladas vendidas\n",
        "def group_data(data, column):\n",
        "  grouped_data = data.groupby([column, 'periodo']).sum().reset_index()\n",
        "\n",
        "  # Crea un DataFrame pivoteado donde las filas son las fechas y las columnas son los product_id\n",
        "  pivot_data = grouped_data.pivot(index='periodo', columns=column, values='tn')\n",
        "\n",
        "  # Asegúrate de que los nombres de las columnas sean strings\n",
        "  pivot_data.columns = pivot_data.columns.astype(str)\n",
        "\n",
        "  # Restablece el índice para asegurarse de que 'product_id' no sea un índice compuesto\n",
        "  pivot_data.columns.name = None\n",
        "\n",
        "  return pivot_data"
      ],
      "metadata": {
        "id": "Mrkkv5Kd0yCG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill & Fix Functions"
      ],
      "metadata": {
        "id": "p_XRfvor4fhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## INVESTIGAR InterpolacionLineal y Media Movil\n",
        "# # Interpolación lineal\n",
        "# df_interpolated = df.interpolate(method='linear')\n",
        "\n",
        "# # Mostrar la serie con interpolación\n",
        "# print(\"\\nSerie con interpolación lineal:\")\n",
        "# print(df_interpolated)\n",
        "\n",
        "# # Relleno hacia adelante (forward fill)\n",
        "# df_ffill = df.fillna(method='ffill')\n",
        "\n",
        "# # Mostrar la serie con relleno hacia adelante\n",
        "# print(\"\\nSerie con relleno hacia adelante:\")\n",
        "# print(df_ffill)\n",
        "\n",
        "# # Relleno hacia atrás (backward fill)\n",
        "# df_bfill = df.fillna(method='bfill')\n",
        "\n",
        "# # Mostrar la serie con relleno hacia atrás\n",
        "# print(\"\\nSerie con relleno hacia atrás:\")\n",
        "# print(df_bfill)\n",
        "\n",
        "# # Relleno con la media móvil\n",
        "# window_size = 3\n",
        "# df['value'] = df['value'].fillna(df['value'].rolling(window=window_size, min_periods=1).mean())\n",
        "# OJO, por ahora no tiene en cuenta los productos de ALTA ni BAJA, solo arrega los HOLES\n",
        "###########################################################################\n",
        "def fix_holes(df):\n",
        "  \"\"\"\n",
        "  Recibe data, agrupa por producto, elimina los innecesarios, agrego los huecos.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): DataFrame con las ventas bruto\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: data:grouped con las ventas agrupadas por producto\n",
        "  \"\"\"\n",
        "  # Creamos las listas de los productos dados de baja, y los nuevos\n",
        "  cant_productos = df['product_id'].unique().size\n",
        "  productos_baja, productos_alta = plot_products_sales(df, 0, cant_productos-1, False)\n",
        "\n",
        "  # Verificar cuáles productos de la lista de baja deben predecirse\n",
        "  productos_en_data = data_productos_a_predecir.index.isin(productos_baja)\n",
        "\n",
        "  # Filtrar los productos que están en la lista\n",
        "  productos_baja_en_data = data_productos_a_predecir.index[productos_en_data]\n",
        "\n",
        "  print(\"Productos con huecos en las ventasm, presentes en la lista de Productos a Predecir:\")\n",
        "  print(productos_baja_en_data)\n",
        "\n",
        "  # Generamos el Dataframe agrupando las ventas por producto\n",
        "  data_gruoped_fixed_holes = group_data(data, 'product_id')\n",
        "\n",
        "  # Arreglamos a manopla, todos analizados en el EDA\n",
        "  data_gruoped_fixed_holes['20089'].loc['2018-07'] = None\n",
        "  data_gruoped_fixed_holes['20192'] = data_gruoped_fixed_holes['20192'].ffill()\n",
        "  data_gruoped_fixed_holes['20313'] = data_gruoped_fixed_holes['20313'].bfill()\n",
        "  data_gruoped_fixed_holes['20426'] = data_gruoped_fixed_holes['20426'].bfill()\n",
        "  data_gruoped_fixed_holes['20456'].loc['2018-10'] = data_gruoped_fixed_holes['20456'].loc['2017-10'].values[0]*.9\n",
        "  data_gruoped_fixed_holes['20456'].loc['2018-11'] = data_gruoped_fixed_holes['20456'].loc['2017-11'].values[0]*.9\n",
        "  data_gruoped_fixed_holes['20469'].loc['2017-07'] = data_gruoped_fixed_holes['20469'].loc['2017-06'].values[0]\n",
        "  data_gruoped_fixed_holes['20596'].loc['2019-04'] = data_gruoped_fixed_holes['20596'].loc['2019-03'].values[0]*.8\n",
        "  data_gruoped_fixed_holes['20596'].loc['2019-05'] = data_gruoped_fixed_holes['20596'].loc['2019-03'].values[0]\n",
        "  data_gruoped_fixed_holes['20596'].loc['2019-06'] = data_gruoped_fixed_holes['20596'].loc['2019-03'].values[0]*.8\n",
        "  data_gruoped_fixed_holes['20641'].loc['2019-05'] = data_gruoped_fixed_holes['20641'].loc['2018-05'].values[0]*.9\n",
        "  data_gruoped_fixed_holes['20641'].loc['2019-06'] = data_gruoped_fixed_holes['20641'].loc['2018-06'].values[0]*.9\n",
        "  data_gruoped_fixed_holes['20666'].loc['2018-01'] = data_gruoped_fixed_holes['20666'].loc['2019-01'].values[0]*1.1\n",
        "  data_gruoped_fixed_holes['20666'].loc['2018-02'] = data_gruoped_fixed_holes['20666'].loc['2019-02'].values[0]*1.1\n",
        "  data_gruoped_fixed_holes['20786'].loc['2017-01'] = data_gruoped_fixed_holes['20786'].loc['2017-03'].values[0]\n",
        "  data_gruoped_fixed_holes['20786'].loc['2017-02'] = data_gruoped_fixed_holes['20786'].loc['2017-03'].values[0]\n",
        "  data_gruoped_fixed_holes['20793'].loc['2017-01'] = data_gruoped_fixed_holes['20793'].loc['2017-03'].values[0]*.5\n",
        "  data_gruoped_fixed_holes['20793'].loc['2017-02'] = data_gruoped_fixed_holes['20793'].loc['2017-03'].values[0]*.75\n",
        "  data_gruoped_fixed_holes['20824'].loc['2018-09'] = data_gruoped_fixed_holes['20824'].loc['2019-01'].values[0]*4\n",
        "  data_gruoped_fixed_holes['20824'].loc['2018-10'] = data_gruoped_fixed_holes['20824'].loc['2019-01'].values[0]*3\n",
        "  data_gruoped_fixed_holes['20824'].loc['2018-11'] = data_gruoped_fixed_holes['20824'].loc['2019-01'].values[0]*4\n",
        "  data_gruoped_fixed_holes['20824'].loc['2018-12'] = data_gruoped_fixed_holes['20824'].loc['2019-01'].values[0]*3\n",
        "  data_gruoped_fixed_holes['20879'] = data_gruoped_fixed_holes['20879'].bfill()\n",
        "  data_gruoped_fixed_holes['20885'].loc['2017-04'] = data_gruoped_fixed_holes['20885'].loc['2017-02'].values[0]\n",
        "  data_gruoped_fixed_holes['20885'].loc['2017-05'] = data_gruoped_fixed_holes['20885'].loc['2017-03'].values[0]\n",
        "  data_gruoped_fixed_holes['20936'].loc['2019-04'] = data_gruoped_fixed_holes['20936'].loc['2019-07'].values[0]*.25\n",
        "  data_gruoped_fixed_holes['20936'].loc['2019-05'] = data_gruoped_fixed_holes['20936'].loc['2019-07'].values[0]*.5\n",
        "  data_gruoped_fixed_holes['20936'].loc['2019-06'] = data_gruoped_fixed_holes['20936'].loc['2019-07'].values[0]*.75\n",
        "  data_gruoped_fixed_holes['21049'].loc['2018-05'] = data_gruoped_fixed_holes['21049'].loc['2018-07'].values[0]*.9\n",
        "  data_gruoped_fixed_holes['21049'].loc['2018-06'] = data_gruoped_fixed_holes['21049'].loc['2018-07'].values[0]*.9\n",
        "  # data_gruoped_fixed_holes['21170'].loc['2017-07'] = data_gruoped_fixed_holes['21170'].loc['2017-09'].values[0]*.9\n",
        "  # data_gruoped_fixed_holes['21170'].loc['2017-08'] = data_gruoped_fixed_holes['21170'].loc['2017-09'].values[0]*.9\n",
        "  data_gruoped_fixed_holes['21190'] = data_gruoped_fixed_holes['21190'].bfill()\n",
        "  data_gruoped_fixed_holes['21200'] = data_gruoped_fixed_holes['21200'].bfill()\n",
        "\n",
        "  return data_gruoped_fixed_holes\n",
        "###########################################################################\n",
        "def fix_aug2019(df_grouped, option):\n",
        "  if option == 'mean':\n",
        "    df_grouped_tmp = df_grouped.drop(index='2019-08', axis=1)\n",
        "    data_agosto_2019_mean = df_grouped_tmp.loc[['2019-07', '2019-09']].mean().to_frame().transpose()\n",
        "    data_agosto_2019_mean.index = pd.to_datetime(['2019-08-01'])\n",
        "    data_grouped_return = pd.concat([df_grouped_tmp, data_agosto_2019_mean]).sort_index()\n",
        "  elif option == 'drop':\n",
        "    data_grouped_return = df_grouped.drop(index='2019-08', axis=1)\n",
        "  elif option == 'julplus10':\n",
        "    df_grouped_tmp = df_grouped.drop(index='2019-08', axis=1)\n",
        "    data_agosto_2019_jul_plus10 = df_grouped_tmp.loc['2019-07']*1.1\n",
        "    data_agosto_2019_jul_plus10.index = pd.to_datetime(['2019-08-01'])\n",
        "    data_grouped_return = pd.concat([df_grouped_tmp, data_agosto_2019_jul_plus10]).sort_index()\n",
        "  else:\n",
        "    raise ValueError(\"Invalid option. Choose 'mean' or 'drop'.\")\n",
        "    data_grouped_return= None\n",
        "\n",
        "  return data_grouped_return\n",
        "###########################################################################\n",
        "def fill_nulls(df):\n",
        "  # Primero usamos bfill para completar las ordenes mas viejas con los valores de las ordenes mas recientes\n",
        "  df = df.bfill()\n",
        "  # Luego completamos con ceros los productos que dejamos de vender, o se discontinuaron\n",
        "  df = df.fillna(0)\n",
        "  return df\n",
        "###########################################################################"
      ],
      "metadata": {
        "id": "WPghARRT5HE3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize Data"
      ],
      "metadata": {
        "id": "a2ctIs9UCRRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo que solo come DataFrames\n",
        "###########################################################################\n",
        "def normalize_data(train, valid, normalization=\"MinMax\"):\n",
        "    if normalization == \"MinMax\":\n",
        "        scaler = MinMaxScaler()\n",
        "    elif normalization == \"ZScore\":\n",
        "        scaler = StandardScaler()\n",
        "    else:\n",
        "        raise ValueError(\"normalization parameter must be either 'MinMax' or 'ZScore'\")\n",
        "\n",
        "    # Normalizar el conjunto de entrenamiento\n",
        "    train_norm = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
        "\n",
        "    # Normalizar el conjunto de validación\n",
        "    valid_norm = pd.DataFrame(scaler.transform(valid), columns=valid.columns, index=valid.index)\n",
        "\n",
        "    if normalization == \"MinMax\":\n",
        "        normalization_params = pd.DataFrame({\n",
        "            'min': scaler.data_min_,\n",
        "            'max': scaler.data_max_\n",
        "        }, index=train.columns)\n",
        "    elif normalization == \"ZScore\":\n",
        "        normalization_params = pd.DataFrame({\n",
        "            'mean': scaler.mean_,\n",
        "            'std': scaler.scale_\n",
        "        }, index=train.columns)\n",
        "\n",
        "    return train_norm, valid_norm, normalization_params\n",
        "###########################################################################\n",
        "def denormalize_data(normalized_series, normalization_params, normalization=\"MinMax\"):\n",
        "    if normalization == \"MinMax\":\n",
        "        denormalized_data = normalized_series * (normalization_params['max'] - normalization_params['min']) + normalization_params['min']\n",
        "    elif normalization == \"ZScore\":\n",
        "        denormalized_data = normalized_series * normalization_params['std'] + normalization_params['mean']\n",
        "    else:\n",
        "        raise ValueError(\"normalization parameter must be either 'MinMax' or 'ZScore'\")\n",
        "\n",
        "    return denormalized_data\n",
        "###########################################################################"
      ],
      "metadata": {
        "id": "J2HbH2ew3yzL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hay que modificarlo, fit_transform en Train, y transform en Test\n",
        "\n",
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# def normalize_data(df, normalization=\"MinMax\"):\n",
        "#     \"\"\"\n",
        "#     Normaliza cada serie de tiempo (columna) de manera individual usando MinMax o Zscore.\n",
        "\n",
        "#     Args:\n",
        "#         df (pd.DataFrame): DataFrame con series de tiempo de distintos productos, cada columna es un producto.\n",
        "#         normalization (str): Tipo de normalización a aplicar. Opciones: \"MinMax\" o \"Zscore\". Default es \"MinMax\".\n",
        "\n",
        "#     Returns:\n",
        "#         normalized_df (pd.DataFrame): DataFrame con las series normalizadas.\n",
        "#         normalization_params (pd.DataFrame): DataFrame con los parámetros necesarios para desnormalizar cada columna.\n",
        "#             - Para \"MinMax\": valores min y max de cada columna.\n",
        "#             - Para \"Zscore\": valores mean y std de cada columna.\n",
        "#     \"\"\"\n",
        "#     normalization_params = pd.DataFrame(columns=[\"product_id\", \"min\", \"max\", \"mean\", \"std\"])\n",
        "#     normalized_df = pd.DataFrame(index=df.index)\n",
        "\n",
        "#     for column in df.columns:\n",
        "#         if normalization == \"MinMax\":\n",
        "#             scaler = MinMaxScaler()\n",
        "#             normalized_values = scaler.fit_transform(df[[column]]).flatten()\n",
        "#             new_params = pd.DataFrame({\n",
        "#                 \"product_id\": [column],\n",
        "#                 \"min\": [scaler.data_min_[0]],\n",
        "#                 \"max\": [scaler.data_max_[0]],\n",
        "#                 \"mean\": [None],\n",
        "#                 \"std\": [None]\n",
        "#             })\n",
        "#             normalization_params = pd.concat([normalization_params, new_params], ignore_index=True)\n",
        "#             normalized_df[column] = normalized_values\n",
        "\n",
        "#         elif normalization == \"ZScore\":\n",
        "#             scaler = StandardScaler()\n",
        "#             normalized_values = scaler.fit_transform(df[[column]]).flatten()\n",
        "#             new_params = pd.DataFrame({\n",
        "#                 \"product_id\": [column],\n",
        "#                 \"min\": [None],\n",
        "#                 \"max\": [None],\n",
        "#                 \"mean\": [scaler.mean_[0]],\n",
        "#                 \"std\": [scaler.scale_[0]]\n",
        "#             })\n",
        "#             normalization_params = pd.concat([normalization_params, new_params], ignore_index=True)\n",
        "#             normalized_df[column] = normalized_values\n",
        "\n",
        "#         else:\n",
        "#             raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'ZScore'.\")\n",
        "\n",
        "#     return normalized_df, normalization_params\n",
        "\n",
        "# def denormalize_series(normalized_series, normalization_params, normalization=\"MinMax\"):\n",
        "#     \"\"\"\n",
        "#     Desnormaliza una serie de tiempo usando los valores almacenados.\n",
        "\n",
        "#     Args:\n",
        "#         normalized_series (pd.Series or pd.DataFrame): Serie o DataFrame con los datos normalizados.\n",
        "#         normalization_params (pd.DataFrame): DataFrame con los parámetros necesarios para desnormalizar cada serie o columna.\n",
        "#             - Para \"MinMax\": valores min y max de cada serie o columna.\n",
        "#             - Para \"Zscore\": valores mean y std de cada serie o columna.\n",
        "#         normalization (str): Tipo de normalización a deshacer. Opciones: \"MinMax\" o \"Zscore\". Default es \"MinMax\".\n",
        "\n",
        "#     Returns:\n",
        "#         denormalized_series (pd.Series or pd.DataFrame): Serie o DataFrame con los datos desnormalizados.\n",
        "#     \"\"\"\n",
        "#     if isinstance(normalized_series, pd.DataFrame):\n",
        "#         denormalized_df = pd.DataFrame(index=normalized_series.index)\n",
        "#         for column in normalized_series.columns:\n",
        "#             params = normalization_params[normalization_params[\"product_id\"] == column]\n",
        "#             if normalization == \"MinMax\":\n",
        "#                 min_value = params[\"min\"].values[0]\n",
        "#                 max_value = params[\"max\"].values[0]\n",
        "#                 denormalized_values = normalized_series[column] * (max_value - min_value) + min_value\n",
        "#             elif normalization == \"ZScore\":\n",
        "#                 mean_value = params[\"mean\"].values[0]\n",
        "#                 std_value = params[\"std\"].values[0]\n",
        "#                 denormalized_values = normalized_series[column] * std_value + mean_value\n",
        "#             else:\n",
        "#                 raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'ZScore'.\")\n",
        "#             denormalized_df[column] = denormalized_values\n",
        "#         return denormalized_df\n",
        "#     elif isinstance(normalized_series, pd.Series):\n",
        "#         product_ids = normalized_series.index\n",
        "#         denormalized_values = []\n",
        "#         for product_id in product_ids:\n",
        "#             params = normalization_params[normalization_params[\"product_id\"] == product_id]\n",
        "#             if normalization == \"MinMax\":\n",
        "#                 min_value = params[\"min\"].values[0]\n",
        "#                 max_value = params[\"max\"].values[0]\n",
        "#                 denormalized_value = normalized_series[product_id] * (max_value - min_value) + min_value\n",
        "#             elif normalization == \"ZScore\":\n",
        "#                 mean_value = params[\"mean\"].values[0]\n",
        "#                 std_value = params[\"std\"].values[0]\n",
        "#                 denormalized_value = normalized_series[product_id] * std_value + mean_value\n",
        "#             else:\n",
        "#                 raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'ZScore'.\")\n",
        "#             denormalized_values.append(denormalized_value)\n",
        "#         denormalized_series = pd.Series(denormalized_values, index=product_ids, name=normalized_series.name)\n",
        "#         return denormalized_series\n",
        "#     else:\n",
        "#         raise TypeError(\"normalized_series should be either a pandas Series or DataFrame\")\n"
      ],
      "metadata": {
        "id": "L5vbt6hpxsNC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data"
      ],
      "metadata": {
        "id": "6z54dcDlIyHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "def split_data_201807(df, window_size):\n",
        "  if window_size == 12:\n",
        "    df_train = df.loc['2017-01':'2017-12']\n",
        "    df_valid = df.loc['2018-01':'2018-05']\n",
        "  elif window_size == 6:\n",
        "    df_train = df.loc['2017-01':'2017-10']\n",
        "    df_valid = df.loc['2017-11':'2018-05']\n",
        "  elif window_size == 3:\n",
        "    df_train = df.loc['2017-01':'2018-07']\n",
        "    df_valid = df.loc['2018-03':'2018-07']\n",
        "  else:\n",
        "    raise ValueError(\"window_size must be different\")\n",
        "  return pd.DataFrame(df_train), pd.DataFrame(df_valid)\n",
        "###############################################################################\n",
        "def split_data_201805(df, window_size):\n",
        "  if window_size == 12:\n",
        "    df_train = df.loc['2017-01':'2017-12']\n",
        "    df_valid = df.loc['2018-01':'2018-05']\n",
        "  elif window_size == 6:\n",
        "    df_train = df.loc['2017-01':'2017-10']\n",
        "    df_valid = df.loc['2017-11':'2018-05']\n",
        "  elif window_size == 3:\n",
        "    df_train = df.loc['2017-01':'2017-12']\n",
        "    df_valid = df.loc['2018-01':'2018-05']\n",
        "  else:\n",
        "    raise ValueError(\"window_size must be different\")\n",
        "  return pd.DataFrame(df_train), pd.DataFrame(df_valid)\n",
        "###############################################################################\n",
        "def split_data(df, window_size):\n",
        "  if window_size == 12:\n",
        "    df_train = df.loc['2017-01':'2018-10']\n",
        "    df_valid = df.loc['2018-11':'2019-12']\n",
        "  elif window_size == 6:\n",
        "    df_train = df.loc['2017-01':'2019-04']\n",
        "    df_valid = df.loc['2019-05':'2019-12']\n",
        "  elif window_size == 3:\n",
        "    df_train = df.loc['2017-01':'2019-07']\n",
        "    df_valid = df.loc['2019-08':'2019-12']\n",
        "  else:\n",
        "    raise ValueError(\"window_size must be different\")\n",
        "  return pd.DataFrame(df_train), pd.DataFrame(df_valid)\n",
        "#############################################################################\n",
        "# Hay que seguir probando con otras window (ej 6, 12)\n",
        "# y ver como no pincha el entrenamiento por quedarnos con pocos datos de validacion\n",
        "def split_data_dec2019(df, window_size):\n",
        "  if window_size == 3:\n",
        "    df_train = df.loc['2017-01':'2019-05']\n",
        "    df_valid = df.loc['2019-06':'2019-10']\n",
        "    df_test = df.loc['2019-11':'2019-12']\n",
        "  elif window_size == 4:\n",
        "    df_train = df.loc['2017-01':'2019-04']\n",
        "    df_valid = df.loc['2019-05':'2019-10']\n",
        "    df_test = df.loc['2019-11':'2019-12']\n",
        "  elif window_size == 6:\n",
        "    df_train = df.loc['2017-01':'2019-02']\n",
        "    df_valid = df.loc['2019-03':'2019-10']\n",
        "  else:\n",
        "    raise ValueError(\"window_size must be different\")\n",
        "  return pd.DataFrame(df_train), pd.DataFrame(df_valid)#, pd.DataFrame(df_test)\n",
        "#############################################################################\n",
        "# split mas chico posible, con window 3 y batch 1\n",
        "def split_data_test(df):\n",
        "  df_train = df.loc['2017-01':'2019-07']\n",
        "  df_valid = df.loc['2019-08':'2019-12']\n",
        "  return pd.DataFrame(df_train), pd.DataFrame(df_valid)\n",
        "############################################################################\n",
        "# # No se si este split tiene sentido, pierdo muchos datos de entrenamiento\n",
        "# def split_data_2019(df):\n",
        "#   df_train = df.loc['2017-01':'2018-12']\n",
        "#   df_valid = df.loc['2019-01':'2019-10']\n",
        "#   df_test =  df.loc['2019-11':'2019-12']\n",
        "#   return df_train, df_valid, df_test\n",
        "############################################################################"
      ],
      "metadata": {
        "id": "zZUKfILzC6Un"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window Data"
      ],
      "metadata": {
        "id": "xbYFP2j6EiEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def windowed_dataset(sequence, data_split, window_size, horizon, batch_size, shuffle_buffer=1000):\n",
        "    \"\"\"Generates dataset windows.\n",
        "\n",
        "    Args:\n",
        "      sequence (array-like): Contains the values of the time series.\n",
        "      data_split (str): Specifies if the dataset is for training or validation/test.\n",
        "      window_size (int): The number of time steps to include in the feature.\n",
        "      horizon (int): The number of future time steps to predict.\n",
        "      batch_size (int): The batch size.\n",
        "      shuffle_buffer (int): Buffer size to use for the shuffle method.\n",
        "\n",
        "    Returns:\n",
        "      tf.data.Dataset: TF Dataset containing time windows.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size + horizon, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + horizon))\n",
        "\n",
        "    # Create tuples with features and labels\n",
        "    dataset = dataset.map(lambda window: (window[:-horizon], window[-horizon:]))\n",
        "\n",
        "    if data_split == 'train':\n",
        "        # Shuffle the training data to improve generalization\n",
        "        dataset = dataset.shuffle(shuffle_buffer)\n",
        "    else:\n",
        "        # Cache the validation/test data for improved performance\n",
        "        dataset = dataset.cache()\n",
        "\n",
        "    # Create batches of windows and prefetch for performance\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "li3XXSO0YOJv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "# def windowed_dataset(sequence, data_split, window_size, horizon, batch_size, shuffle_buffer=1000):\n",
        "#     \"\"\"Generates dataset windows.\n",
        "\n",
        "#     Args:\n",
        "#       sequence (array-like): Contains the values of the time series.\n",
        "#       data_split (str): Specifies if the dataset is for training or validation/test.\n",
        "#       window_size (int): The number of time steps to include in the feature.\n",
        "#       horizon (int): The number of future time steps to predict.\n",
        "#       batch_size (int): The batch size.\n",
        "#       shuffle_buffer (int): Buffer size to use for the shuffle method.\n",
        "\n",
        "#     Returns:\n",
        "#       tf.data.Dataset: TF Dataset containing time windows.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Generate a TF Dataset from the series values\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "\n",
        "#     # Window the data but only take those with the specified size\n",
        "#     dataset = dataset.window(window_size + horizon, shift=1, drop_remainder=True)\n",
        "\n",
        "#     # Flatten the windows by putting its elements in a single batch\n",
        "#     dataset = dataset.flat_map(lambda window: window.batch(window_size + horizon))\n",
        "\n",
        "#     # Create tuples with features and labels\n",
        "#     dataset = dataset.map(lambda window: (window[:-horizon], window[-horizon:]))\n",
        "\n",
        "#     if data_split == 'train':\n",
        "#         # Shuffle the training data to improve generalization\n",
        "#         dataset = dataset.shuffle(shuffle_buffer)\n",
        "#     else:\n",
        "#         # Cache the validation/test data for improved performance\n",
        "#         dataset = dataset.cache()\n",
        "\n",
        "#     # Create batches of windows and prefetch for performance\n",
        "#     dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#     return dataset"
      ],
      "metadata": {
        "id": "OlImIwoE3Mh-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############################################\n",
        "# # Viejos\n",
        "##############################################\n",
        "# def window_dataset(sequence, data_split, window_size, batch_size, n_future, shuffle_buffer=1000, seed=None):\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "#     dataset = dataset.window(window_size + n_future, shift=1, drop_remainder=True)\n",
        "#     dataset = dataset.flat_map(lambda window: window.batch(window_size + n_future))\n",
        "#     dataset = dataset.map(lambda window: (window[:window_size], window[window_size:]))\n",
        "\n",
        "#     if data_split == 'train':\n",
        "#         dataset = dataset.shuffle(shuffle_buffer, seed=seed)\n",
        "#     else:\n",
        "#         dataset = dataset.cache()\n",
        "\n",
        "#     dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#     return dataset\n",
        "##############################################\n",
        "# def window_dataset(sequence, data_split, window_size, batch_size, n_future, shuffle_buffer=1000, seed=None):\n",
        "#     \"\"\"Generates dataset windows for multi-step forecasting in a multivariable context.\n",
        "\n",
        "#     Args:\n",
        "#       sequence (array-like): Contains the values of the time series, where each element is an array of feature values.\n",
        "#       data_split (str): Specifies if the dataset is for training or validation/test.\n",
        "#       window_size (int): The number of time steps to include in the feature.\n",
        "#       batch_size (int): The batch size.\n",
        "#       n_future (int): The number of future steps to predict.\n",
        "#       shuffle_buffer (int): Buffer size to use for the shuffle method.\n",
        "#       seed (int, optional): Random seed for reproducibility.\n",
        "\n",
        "#     Returns:\n",
        "#       tf.data.Dataset: TF Dataset containing time windows.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Generate a TF Dataset from the series values\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "\n",
        "#     # Window the data but only take those with the specified size\n",
        "#     dataset = dataset.window(window_size + n_future, shift=1, drop_remainder=True)\n",
        "\n",
        "#     # Flatten the windows by putting its elements in a single batch\n",
        "#     dataset = dataset.flat_map(lambda window: window.batch(window_size + n_future))\n",
        "\n",
        "#     # Create tuples with features and labels\n",
        "#     dataset = dataset.map(lambda window: (window[:window_size], window[window_size:]))\n",
        "\n",
        "#     if data_split == 'train':\n",
        "#         # Shuffle the training data to improve generalization\n",
        "#         dataset = dataset.shuffle(shuffle_buffer, seed=seed)\n",
        "#     else:\n",
        "#         # Cache the validation/test data for improved performance\n",
        "#         dataset = dataset.cache()\n",
        "\n",
        "#     # Create batches of windows and prefetch for performance\n",
        "#     dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#     return dataset\n"
      ],
      "metadata": {
        "id": "c5g4WjakEjcM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Functions"
      ],
      "metadata": {
        "id": "x_Zm-EgneATh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Este va a reemplazar al otro\n",
        "def generate_predictions_4(model_trained, data_valid_norm, data_norm_params):\n",
        "  data_norm_array = data_valid_norm.values\n",
        "  column_names = data_valid_norm.columns\n",
        "  input_data = data_norm_array[-window_size:].reshape((1, window_size, n_features))\n",
        "  pred = model_trained.predict(input_data)\n",
        "  pred = pred.reshape((1, horizon, n_features))\n",
        "  pred_df = pd.DataFrame(pred[0], columns=column_names)\n",
        "  pred_df.index = pd.date_range(start=data_valid_norm.index[-1] + pd.DateOffset(months=1), periods=horizon, freq='MS')\n",
        "\n",
        "  # Generamos la salida de la segunda prediccion, Febrero 2020 (Mes +2 del ultimo mes en data_validation_norm)\n",
        "  pred_plus2 = pred_df.iloc[1]\n",
        "  pred_plus2_denorm = denormalize_data(pred_plus2, data_norm_params, normalization=normalization)\n",
        "  # pred_plus2_denorm = pd.Series(pred_plus2_denorm, name=str(column_names.values[0]))\n",
        "  # pred_plus2_df = pd.DataFrame(pred_plus2_denorm)\n",
        "  # pred_plus2_df['periodo'] = pd.to_datetime(pred_df.iloc[1].name)\n",
        "  # pred_plus2_df.set_index('periodo', inplace=True)\n",
        "\n",
        "  # # Concateno las dos predicciones\n",
        "  # pred_final_df = pd.concat([pred_plus1_df,pred_plus2_df])\n",
        "\n",
        "  # # En lugar de DF, devuelvo una serie, para que matchee con el input\n",
        "  # pred_final_serie = pred_final_df.squeeze()\n",
        "\n",
        "  return pred_plus2_denorm\n",
        "##########################################################################\n",
        "# # Este va a reemplazar al otro\n",
        "def generate_predictions_3(model_trained, data_valid_norm, data_norm_params):\n",
        "  data_norm_array = data_valid_norm.values\n",
        "  column_names = data_valid_norm.columns\n",
        "  input_data = data_norm_array[-window_size:].reshape((1, window_size, n_features))\n",
        "  pred = model_trained.predict(input_data)\n",
        "  pred = pred.reshape((1, horizon, n_features))\n",
        "  pred_df = pd.DataFrame(pred[0], columns=column_names)\n",
        "  pred_df.index = pd.date_range(start=data_valid_norm.index[-1] + pd.DateOffset(months=1), periods=horizon, freq='MS')\n",
        "\n",
        "  # # Generamos la salida de la primer prediccion, Enero 2020 (Mes +1 del ultimo mes en data_validation_norm)\n",
        "  # pred_plus1 = pred_df.iloc[0]\n",
        "  # pred_plus1_denorm = denormalize_data(pred_plus1, data_norm_params, normalization=normalization)\n",
        "  # pred_plus1_denorm = pd.Series(pred_plus1_denorm, name=str(column_names.values[0]))\n",
        "  # pred_plus1_df = pd.DataFrame(pred_plus1_denorm)\n",
        "  # pred_plus1_df['periodo'] = pd.to_datetime(pred_df.iloc[0].name)\n",
        "  # pred_plus1_df.set_index('periodo', inplace=True)\n",
        "\n",
        "  # Generamos la salida de la segunda prediccion, Febrero 2020 (Mes +2 del ultimo mes en data_validation_norm)\n",
        "  pred_plus2 = pred_df.iloc[1]\n",
        "  pred_plus2_denorm = denormalize_data(pred_plus2, data_norm_params, normalization=normalization)\n",
        "  # pred_plus2_denorm = pd.Series(pred_plus2_denorm, name=str(column_names.values[0]))\n",
        "  # pred_plus2_df = pd.DataFrame(pred_plus2_denorm)\n",
        "  # pred_plus2_df['periodo'] = pd.to_datetime(pred_df.iloc[1].name)\n",
        "  # pred_plus2_df.set_index('periodo', inplace=True)\n",
        "\n",
        "  # # Concateno las dos predicciones\n",
        "  # pred_final_df = pd.concat([pred_plus1_df,pred_plus2_df])\n",
        "\n",
        "  # # En lugar de DF, devuelvo una serie, para que matchee con el input\n",
        "  # pred_final_serie = pred_final_df.squeeze()\n",
        "\n",
        "  return pred_plus2_denorm\n",
        "##########################################################################\n",
        "# # Este va a reemplazar al otro\n",
        "def generate_predictions_2(model_trained, data_valid_norm, data_norm_params):\n",
        "  data_norm_array = data_valid_norm.values\n",
        "  column_names = data_valid_norm.columns\n",
        "  input_data = data_norm_array[-window_size:].reshape((1, window_size, n_features))\n",
        "  pred = model_trained.predict(input_data)\n",
        "  pred = pred.reshape((1, horizon, n_features))\n",
        "  pred_df = pd.DataFrame(pred[0], columns=column_names)\n",
        "  pred_df.index = pd.date_range(start=data_valid_norm.index[-1] + pd.DateOffset(months=1), periods=horizon, freq='MS')\n",
        "\n",
        "  # Generamos la salida de la primer prediccion, Enero 2020 (Mes +1 del ultimo mes en data_validation_norm)\n",
        "  pred_plus1 = pred_df.iloc[0]\n",
        "  pred_plus1_denorm = denormalize_data(pred_plus1, data_norm_params, normalization=normalization)\n",
        "  pred_plus1_denorm = pd.Series(pred_plus1_denorm, name=str(column_names.values[0]))\n",
        "  pred_plus1_df = pd.DataFrame(pred_plus1_denorm)\n",
        "  pred_plus1_df['periodo'] = pd.to_datetime(pred_df.iloc[0].name)\n",
        "  pred_plus1_df.set_index('periodo', inplace=True)\n",
        "\n",
        "  # Generamos la salida de la segunda prediccion, Febrero 2020 (Mes +2 del ultimo mes en data_validation_norm)\n",
        "  pred_plus2 = pred_df.iloc[1]\n",
        "  pred_plus2_denorm = denormalize_data(pred_plus2, data_norm_params, normalization=normalization)\n",
        "  pred_plus2_denorm = pd.Series(pred_plus2_denorm, name=str(column_names.values[0]))\n",
        "  pred_plus2_df = pd.DataFrame(pred_plus2_denorm)\n",
        "  pred_plus2_df['periodo'] = pd.to_datetime(pred_df.iloc[1].name)\n",
        "  pred_plus2_df.set_index('periodo', inplace=True)\n",
        "\n",
        "  # Concateno las dos predicciones\n",
        "  pred_final_df = pd.concat([pred_plus1_df,pred_plus2_df])\n",
        "\n",
        "  # En lugar de DF, devuelvo una serie, para que matchee con el input\n",
        "  pred_final_serie = pred_final_df.squeeze()\n",
        "\n",
        "  return pred_final_serie\n",
        "##########################################################################\n",
        "def generate_predictions(data_norm, data_norm_params, export_csv):\n",
        "  data_norm_array = data_norm.values\n",
        "  column_names = data_norm.columns\n",
        "  input_data = data_norm_array[-window_size:].reshape((1, window_size, n_features))\n",
        "  pred = model.predict(input_data)\n",
        "  pred = pred.reshape((1, horizon, n_features))\n",
        "  pred_df = pd.DataFrame(pred[0], columns=column_names)\n",
        "  pred_df.index = pd.date_range(start='2020-01-01', periods=horizon, freq='MS')\n",
        "  pred_feb = pred_df.loc['2020-02-01']\n",
        "  pred_denorm = denormalize_data(pred_feb, norm_params, normalization)\n",
        "  pred_denorm = pred_denorm.reset_index()\n",
        "  pred_denorm.columns = ['product_id', 'tn']\n",
        "  # display(pred_denorm)\n",
        "  # # Esto no creo que sea necesario\n",
        "  # predicciones = filter_data(data_pred1_denorm, data_productos_a_predecir)\n",
        "\n",
        "  filename = f\"{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "\n",
        "  if export_csv:\n",
        "    pred_denorm.to_csv(filename, header=True, index=False)\n",
        "\n",
        "  # print(filename)\n",
        "\n",
        "  return pred_denorm['tn']\n",
        "##########################################################################\n",
        "def to_kaggle(serie, name='kaggle_submission'):\n",
        "  serie.columns = ['product_id', 'tn']\n",
        "  serie.to_csv(f'{name}.csv', header=True, index=False)\n",
        "##########################################################################\n",
        "def to_kaggle_2(serie, name='kaggle_submission'):\n",
        "    df = serie.reset_index()  # Convierte el índice en una columna\n",
        "    df.columns = ['product_id', 'tn']  # Asigna nombres a las columnas\n",
        "    df.to_csv(f'{name}.csv', header=True, index=False)  # Exporta el DataFrame a CSV\n",
        "##########################################################################\n",
        "def calcular_error(df):\n",
        "  error = np.divide(np.abs(predictions_df['true'] - predictions_df['predicted']).sum(), predictions_df['true'].sum()).round(4)\n",
        "  print(error)\n",
        "##########################################################################\n",
        "def sumar_predicciones(df1, df2):\n",
        "    # Asegúrate de que las columnas necesarias estén en los DataFrames\n",
        "    if 'product_id' not in df1.columns or 'tn' not in df1.columns:\n",
        "        raise ValueError(\"df1 debe contener las columnas 'product_id' y 'tn'\")\n",
        "    if 'product_id' not in df2.columns or 'tn' not in df2.columns:\n",
        "        raise ValueError(\"df2 debe contener las columnas 'product_id' y 'tn'\")\n",
        "\n",
        "    # Suma los valores de 'tn' para cada 'product_id' de ambos DataFrames\n",
        "    result = df1.set_index('product_id').add(df2.set_index('product_id'), fill_value=0).reset_index()\n",
        "\n",
        "    return result\n",
        "##########################################################################\n",
        "def sumar_series(series1, series2):\n",
        "    # Suma los valores de ambas Series\n",
        "    result = series1.add(series2, fill_value=0)\n",
        "\n",
        "    # Ordena el resultado por el índice (product_id)\n",
        "    result = result.sort_index()\n",
        "\n",
        "    return result\n",
        "##########################################################################"
      ],
      "metadata": {
        "id": "jmLuXgOGeC57"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ##########################################################################\n",
        "# def generate_predictions(data_norm, data_norm_params, export_csv): # Verificar\n",
        "# # def generate_predictions(export_csv): # Viejo\n",
        "#   data_norm_array = data_norm.values\n",
        "#   column_names = data_norm.columns\n",
        "#   input_data = data_norm_array[-window_size:].reshape((1, window_size, n_features))\n",
        "#   pred = model.predict(input_data)\n",
        "#   pred = pred.reshape((1, horizon, n_features))\n",
        "#   pred_df = pd.DataFrame(pred[0], columns=column_names)\n",
        "#   pred_df.index = pd.date_range(start='2020-01-01', periods=horizon, freq='MS')\n",
        "#   pred_feb = pred_df.loc['2020-02-01']\n",
        "#   pred_1_denorm = denormalize_series(pred_feb, data_norm_params, normalization=normalization)\n",
        "#   data_pred1_denorm = pred_1_denorm.reset_index()\n",
        "#   data_pred1_denorm.columns = ['product_id', 'tn']\n",
        "#   # Esto no creo que sea necesario\n",
        "#   predicciones = filter_data(data_pred1_denorm, data_productos_a_predecir)\n",
        "\n",
        "#   # Ojo con esto, caja negra. Vuelve a predecir usando lo predicho antes.\n",
        "#   input_data2 = np.append(input_data[:, 1:, :], pred[:, 0, :].reshape(1, 1, n_features), axis=1)\n",
        "#   pred2 = model.predict(input_data2)\n",
        "#   pred2 = pred2.reshape((1, horizon, n_features))\n",
        "#   pred2_df = pd.DataFrame(pred2[0], columns=column_names)\n",
        "#   pred2_df.index = pd.date_range(start='2020-02-01', periods=horizon, freq='MS')\n",
        "#   pred2_feb = pred2_df.loc['2020-02-01']\n",
        "#   pred_2_denorm = denormalize_series(pred2_feb, data_norm_params, normalization=normalization)\n",
        "#   data_pred2_denorm = pred_2_denorm.reset_index()\n",
        "#   data_pred2_denorm.columns = ['product_id', 'tn']\n",
        "#   predicciones2 = filter_data(data_pred2_denorm, data_productos_a_predecir)\n",
        "\n",
        "#   filename = f\"{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "#   filename2 = f\"RECURRENTE_{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "\n",
        "#   if export_csv:\n",
        "#     predicciones.to_csv(filename, header=True, index=False)\n",
        "\n",
        "#   # predicciones.to_csv(filename, header=True, index=False)\n",
        "#   # predicciones2.to_csv(filename2, header=True, index=False)\n",
        "#   print(filename)\n",
        "\n",
        "#   return predicciones # Probar con predicciones 2"
      ],
      "metadata": {
        "id": "KWsm0gdSDZ9w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "### OLD\n",
        "###############################################################################\n",
        "# def generate_predictions(data_norm, data_norm_params):\n",
        "\n",
        "#     # Convertir el DataFrame a un array de NumPy\n",
        "#     data_norm_array = data_norm.values\n",
        "\n",
        "#     # Extraer la última ventana de datos de 2019 para predecir enero de 2020\n",
        "#     column_names = data_norm.columns  # Obtener los nombres de las columnas\n",
        "\n",
        "#     # Extraer los últimos `window_size` meses de 2019\n",
        "#     input_data = data_norm_array[-window_size:].reshape((1, window_size, n_features))\n",
        "\n",
        "#     # Predecir enero de 2020\n",
        "#     pred_january = model.predict(input_data)\n",
        "\n",
        "#     # Asegurarse de que la predicción tenga la forma correcta\n",
        "#     pred_january = pred_january.reshape((1, n_future, n_features))\n",
        "\n",
        "#     # Crear un DataFrame para la predicción de enero de 2020\n",
        "#     pred_january_df = pd.DataFrame(pred_january[0], columns=column_names)\n",
        "#     pred_january_df.index = pd.date_range(start='2020-01-01', periods=n_future, freq='MS')\n",
        "\n",
        "#     # Actualizar la ventana de entrada para predecir febrero de 2020\n",
        "#     input_data = np.append(input_data[:, 1:, :], pred_january[:, 0, :].reshape(1, 1, n_features), axis=1)\n",
        "\n",
        "#     # Predecir febrero de 2020\n",
        "#     pred_february = model.predict(input_data)\n",
        "\n",
        "#     # Asegurarse de que la predicción tenga la forma correcta\n",
        "#     pred_february = pred_february.reshape((1, n_future, n_features))\n",
        "\n",
        "#     # Crear un DataFrame para la predicción de febrero de 2020\n",
        "#     pred_february_df = pd.DataFrame(pred_february[0], columns=column_names)\n",
        "#     pred_february_df.index = pd.date_range(start='2020-02-01', periods=n_future, freq='MS')\n",
        "\n",
        "#     # Obtener la predicción de febrero de 2020\n",
        "#     pred_1 = pred_january_df.loc['2020-02-01']\n",
        "\n",
        "#     # Desnormalizar la predicción\n",
        "#     pred_1_denorm = denormalize_series(pred_1, data_norm_params, normalization=normalization)\n",
        "#     data_pred1_denorm = pred_1_denorm.reset_index()\n",
        "#     data_pred1_denorm.columns = ['product_id', 'tn']\n",
        "#     predicciones = filter_data(data_pred1_denorm, data_productos_a_predecir)\n",
        "\n",
        "#     # Crear el nombre del archivo\n",
        "#     filename = f\"{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}_epochs{epochs}.csv\"\n",
        "#     predicciones.to_csv(filename, header=True, index=False)\n",
        "\n",
        "#     print(filename)\n",
        "\n",
        "#     return predicciones\n",
        "##########################################################################"
      ],
      "metadata": {
        "id": "G1YhW2wUNh6O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Sales"
      ],
      "metadata": {
        "id": "Tsi7tkBEgtWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_sales(df1, df2):\n",
        "    # Crear un rango de fechas desde enero 2017 hasta diciembre 2019\n",
        "    fechas_completas = pd.date_range(start='2017-01-01', end='2019-12-01', freq='MS')\n",
        "\n",
        "    # Reindexar el DataFrame para asegurar que todas las fechas estén presentes\n",
        "    df1 = df1.reindex(fechas_completas, fill_value=pd.NA)\n",
        "\n",
        "    # Obtener los product_id del primer DataFrame (nombres de las columnas)\n",
        "    product_ids_df1 = df1.columns.tolist()\n",
        "\n",
        "    # Obtener los product_id del segundo DataFrame (valores en la columna 'product_id')\n",
        "    product_ids_df2 = df2['product_id'].tolist()\n",
        "\n",
        "    # Identificar los product_id que faltan en df1\n",
        "    product_ids_faltantes = [pid for pid in product_ids_df2 if pid not in product_ids_df1]\n",
        "\n",
        "    # Crear un DataFrame con las columnas faltantes y valores NaN\n",
        "    df_faltantes = pd.DataFrame(index=df1.index, columns=product_ids_faltantes)\n",
        "\n",
        "    # Concatenar el DataFrame original con el DataFrame de faltantes\n",
        "    df_resultante = pd.concat([df1, df_faltantes], axis=1)\n",
        "\n",
        "    return df_resultante\n",
        "\n"
      ],
      "metadata": {
        "id": "aSHUuvHXgtf8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "brfkj2XkXena"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "def MyCallbacks(patience):\n",
        "    \"\"\"\n",
        "    Devuelve una lista de callbacks para el entrenamiento del modelo.\n",
        "\n",
        "    Parameters:\n",
        "    patience (int): Número de épocas a esperar para ver una mejora en 'val_loss' antes de detener el entrenamiento.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de callbacks de Keras.\n",
        "    \"\"\"\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
        "    return [early_stop]"
      ],
      "metadata": {
        "id": "fcfAKyAS_iD2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "#### VIEJO\n",
        "# #############################################################################\n",
        "# class MAEThresholdCallback(Callback):\n",
        "#     def __init__(self, threshold=0.15):\n",
        "#         super(MAEThresholdCallback, self).__init__()\n",
        "#         self.threshold = threshold\n",
        "\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         val_mae = logs.get('val_mae')\n",
        "#         if val_mae is not None and val_mae <= self.threshold:\n",
        "#             print(f'\\nEpoch {epoch+1}: Validation MAE has reached {val_mae:.4f}, stopping training.')\n",
        "#             self.model.stop_training = True\n",
        "\n",
        "# def MyCallbacks(model_name, patience):\n",
        "#     earlystop = tf.keras.callbacks.EarlyStopping('val_loss', patience=patience, restore_best_weights=True)\n",
        "#     # checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'ckpts/{model_name}-' + '{epoch:02d}-{val_loss:.4f}.h5', monitor='val_loss')\n",
        "#     # mae_threshold_callback = MAEThresholdCallback(threshold=0.015)\n",
        "#     return [earlystop] #, checkpoint] #, mae_threshold_callback]\n",
        "\n",
        "# #############################################################################"
      ],
      "metadata": {
        "id": "ETzh0JyBXgRt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Design"
      ],
      "metadata": {
        "id": "cGAz7W4mXqO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "def compile_model(new_model, loss, optimizer):\n",
        "    new_model.compile(optimizer=optimizer, loss=loss, metrics=['mae'])\n",
        "    print(new_model.summary())\n",
        "    return new_model\n",
        "#############################################################################\n",
        "def MyModel(loss, optimizer, window_size, horizon, n_features):\n",
        "    new_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer((window_size, n_features)),\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=False)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(n_features * horizon, activation='relu'),\n",
        "        tf.keras.layers.Reshape((horizon, n_features)),\n",
        "    ])\n",
        "    return compile_model(new_model, loss, optimizer)\n",
        "#############################################################################"
      ],
      "metadata": {
        "id": "v1XojStQ3FQw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #############################################################################\n",
        "# def compile_model(new_model, loss, optimizer):\n",
        "#   new_model.compile(optimizer=optimizer, loss=loss, metrics=['mse'])\n",
        "#   print(new_model.summary())\n",
        "#   return new_model\n",
        "# #############################################################################\n",
        "# def MyModel(loss, optimizer, window_size, n_future, n_features):\n",
        "#     new_model = tf.keras.Sequential([\n",
        "#         tf.keras.layers.InputLayer((window_size, n_features)),\n",
        "#         tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal'),\n",
        "#         tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "#         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "#         tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=False)),\n",
        "#         tf.keras.layers.Dropout(0.4),\n",
        "#         tf.keras.layers.Dense(n_features * n_future, activation='relu'),\n",
        "#         tf.keras.layers.Reshape((n_future, n_features)),\n",
        "#         ])\n",
        "#     return compile_model(new_model, loss, optimizer)"
      ],
      "metadata": {
        "id": "eCESYECOXr45"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Train"
      ],
      "metadata": {
        "id": "7uqfuDfTJD8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repetimos la prediccion n veces\n",
        "def model_train(epochs, iteraciones):\n",
        "  pred_list = []\n",
        "\n",
        "  for i in range(iteraciones):\n",
        "    print(f'Interacion {i+1}')\n",
        "    history = model.fit(\n",
        "        data_train_windowed,\n",
        "        validation_data = data_valid_windowed,\n",
        "        callbacks = callbacks,\n",
        "        verbose=0,\n",
        "        epochs=epochs)\n",
        "\n",
        "    predicted = generate_predictions(data_valid_norm, norm_params, False)\n",
        "    print(f'Prediction: {predicted}')\n",
        "    pred_list.append(generate_predictions(data_valid_norm, norm_params, False))\n",
        "\n",
        "    plot_history(history)\n",
        "  print('Producto: ', producto)\n",
        "  print(f'Mean Loss across all splits: {np.mean(pred_list)}')\n",
        "  print(f'Median Loss across all splits: {np.median(pred_list)}')\n",
        "\n",
        "  return(np.mean(pred_list), np.median(pred_list))\n",
        "\n"
      ],
      "metadata": {
        "id": "DSrrGEGPJFyO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipelines"
      ],
      "metadata": {
        "id": "F4yiWWu8FJZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "HWg00hIFX64c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_extended.copy()\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# # data_productos\n",
        "# # data_stocks\n",
        "# # data_productos_a_predecir\n",
        "\n",
        "# Pre-Processing Variables\n",
        "\n",
        "split_strategy = 'S1'\n",
        "normalization = 'MinMax'\n",
        "window_size = None\n",
        "horizon = 2\n",
        "batch_size = None\n",
        "\n",
        "\n",
        "# Model Variables: Dentro de cada Experimento, no son generales\n",
        "n_features = None  # Esto va a depender de cada modelo, es el data_train.shape[1]\n",
        "n_splits = None # No mas, la usabamos con el TimeSeriesSplit\n",
        "# model_name = 'CAT1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 10\n",
        "\n",
        "# Si quiero solo las ventas de los clientes activos\n",
        "data = filter_active_clients_data(data)\n",
        "print(data.shape)\n",
        "\n",
        "# Si quiero las ventas solo de los productos a predecir\n",
        "data =filter_products_data(data, data_productos_a_predecir)\n",
        "print(data.shape)\n",
        "\n",
        "\n",
        "# # # ACTUALIZAR\n",
        "# data = fix_holes(data) # Falta vacios al principioy final\n",
        "# print(data.shape)\n",
        "\n",
        "# # # ACTUALIZAR\n",
        "# # Estrategia para completar los NaN de los datos agrupados\n",
        "# # data_grouped = fill_nulls(data_grouped)\n",
        "\n",
        "# # Estrategia para solucionar el problema de Agosto 2019\n",
        "# data = fix_aug2019(data, 'julplus10')\n",
        "\n",
        "# # Ploteamos para ver como quedan las ventas totales acumuladas\n",
        "# data_grouped.sum(axis=1).plot()\n",
        "# plt.show()\n",
        "\n",
        "display(data.head())\n"
      ],
      "metadata": {
        "id": "vLrQTz5YEkPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "1a2c225f-27ac-4dce-90d1-67382aa751d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2939639, 12)\n",
            "(2536878, 12)\n",
            "(1978959, 12)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           customer_id product_id  plan_precios_cuidados  cust_request_qty  \\\n",
              "periodo                                                                      \n",
              "2017-01-01       10234      20524                      0                 2   \n",
              "2017-01-01       10032      20524                      0                 1   \n",
              "2017-01-01       10217      20524                      0                 1   \n",
              "2017-01-01       10012      20524                      0                11   \n",
              "2017-01-01       10080      20524                      0                 1   \n",
              "\n",
              "            cust_request_tn   tn cat1     cat2        cat3      brand  \\\n",
              "periodo                                                                 \n",
              "2017-01-01             0.05 0.05   HC  VAJILLA  Cristalino  Importado   \n",
              "2017-01-01             0.14 0.14   HC  VAJILLA  Cristalino  Importado   \n",
              "2017-01-01             0.03 0.03   HC  VAJILLA  Cristalino  Importado   \n",
              "2017-01-01             1.54 1.54   HC  VAJILLA  Cristalino  Importado   \n",
              "2017-01-01             0.02 0.02   HC  VAJILLA  Cristalino  Importado   \n",
              "\n",
              "            sku_size    descripcion  \n",
              "periodo                              \n",
              "2017-01-01    500.00  Abrillantador  \n",
              "2017-01-01    500.00  Abrillantador  \n",
              "2017-01-01    500.00  Abrillantador  \n",
              "2017-01-01    500.00  Abrillantador  \n",
              "2017-01-01    500.00  Abrillantador  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f464fca-3692-416b-a52a-ec3c36f86f6a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>plan_precios_cuidados</th>\n",
              "      <th>cust_request_qty</th>\n",
              "      <th>cust_request_tn</th>\n",
              "      <th>tn</th>\n",
              "      <th>cat1</th>\n",
              "      <th>cat2</th>\n",
              "      <th>cat3</th>\n",
              "      <th>brand</th>\n",
              "      <th>sku_size</th>\n",
              "      <th>descripcion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>periodo</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>10234</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>HC</td>\n",
              "      <td>VAJILLA</td>\n",
              "      <td>Cristalino</td>\n",
              "      <td>Importado</td>\n",
              "      <td>500.00</td>\n",
              "      <td>Abrillantador</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>10032</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>HC</td>\n",
              "      <td>VAJILLA</td>\n",
              "      <td>Cristalino</td>\n",
              "      <td>Importado</td>\n",
              "      <td>500.00</td>\n",
              "      <td>Abrillantador</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>10217</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>HC</td>\n",
              "      <td>VAJILLA</td>\n",
              "      <td>Cristalino</td>\n",
              "      <td>Importado</td>\n",
              "      <td>500.00</td>\n",
              "      <td>Abrillantador</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>10012</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.54</td>\n",
              "      <td>HC</td>\n",
              "      <td>VAJILLA</td>\n",
              "      <td>Cristalino</td>\n",
              "      <td>Importado</td>\n",
              "      <td>500.00</td>\n",
              "      <td>Abrillantador</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-01</th>\n",
              "      <td>10080</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>HC</td>\n",
              "      <td>VAJILLA</td>\n",
              "      <td>Cristalino</td>\n",
              "      <td>Importado</td>\n",
              "      <td>500.00</td>\n",
              "      <td>Abrillantador</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f464fca-3692-416b-a52a-ec3c36f86f6a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f464fca-3692-416b-a52a-ec3c36f86f6a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f464fca-3692-416b-a52a-ec3c36f86f6a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e68e9f1-3ad7-41c2-8caf-2a96b7643968\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e68e9f1-3ad7-41c2-8caf-2a96b7643968')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e68e9f1-3ad7-41c2-8caf-2a96b7643968 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"periodo\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2017-01-01 00:00:00\",\n        \"max\": \"2017-01-01 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2017-01-01 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"customer_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"10032\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"20524\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"plan_precios_cuidados\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cust_request_qty\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 11,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cust_request_tn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.666135234978604,\n        \"min\": 0.01514,\n        \"max\": 1.54452,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.13628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.666135234978604,\n        \"min\": 0.01514,\n        \"max\": 1.54452,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.13628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"HC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"VAJILLA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cat3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Cristalino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Importado\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sku_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 500.0,\n        \"max\": 500.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          500.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"descripcion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Abrillantador\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentos Individuales"
      ],
      "metadata": {
        "id": "SaiJuaUP3JUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/25 - Categorias Extendidas"
      ],
      "metadata": {
        "id": "RHIZ85HQoj14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "customers_top10 = group_data(data, 'customer_id').loc['2019'].sum().index[:10]"
      ],
      "metadata": {
        "id": "0f81U327A8hB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for customer in customers_top10[:2]:\n",
        "  # print(customer)\n",
        "  predicciones_by_customer = data_productos_a_predecir.copy()\n",
        "  predicciones_by_customer['tn'] = 0\n",
        "  predicciones_by_customer_serie = predicciones_by_customer.squeeze()\n",
        "\n",
        "\n",
        "  data_customer = data.loc[data['customer_id'] == customer]\n",
        "  # data_customer_grouped = group_data(data_customer, 'product_id')\n",
        "  # data_customer_grouped_fillna = fill_nulls(data_customer_grouped)\n",
        "  # display(data_customer.head())\n",
        "  for customer_cat1 in data_customer['cat1'].unique():\n",
        "    # print(customer_cat1)\n",
        "    for customer_cat1_cat2 in data_customer.loc[data_customer['cat1'] == customer_cat1]['cat2'].unique():\n",
        "      # print(customer_cat1, customer_cat1_cat2)\n",
        "      for customer_cat1_cat2_cat3 in data_customer.loc[(data_customer['cat1'] == customer_cat1) & (data_customer['cat2'] == customer_cat1_cat2)]['cat3'].unique():\n",
        "        # print(customer_cat1, customer_cat1_cat2, customer_cat1_cat2_cat3)\n",
        "        data_customer_cat1_cat2_cat3 = data_customer.loc[(data_customer['cat1'] == customer_cat1) & (data_customer['cat2'] == customer_cat1_cat2) & (data_customer['cat3'] == customer_cat1_cat2_cat3)]\n",
        "        data_customer_cat1_cat2_cat3_grouped = group_data(data_customer_cat1_cat2_cat3, 'product_id')\n",
        "        data_customer_cat1_cat2_cat3_grouped_fillna = fill_nulls(data_customer_cat1_cat2_cat3_grouped)\n",
        "        # display(data_customer_cat1_cat2_cat3_grouped_fillna)\n",
        "        split_strategy = 'S1'\n",
        "        normalization = 'MinMax'\n",
        "        window_size = None\n",
        "        horizon = 2\n",
        "        batch_size = None\n",
        "\n",
        "        # Model Variables: Dentro de cada Experimento, no son generales\n",
        "        n_features = None  # Esto va a depender de cada modelo, es el data_train.shape[1]\n",
        "        n_splits = None # No mas, la usabamos con el TimeSeriesSplit\n",
        "\n",
        "        # model_name = 'CAT1'\n",
        "        # loss = 'mse'\n",
        "        # optimizer = 'adam'\n",
        "        # patience = 30\n",
        "        # epochs = 10\n",
        "\n",
        "\n",
        "\n",
        "        window_size = 3\n",
        "        batch_size = 32\n",
        "\n",
        "\n",
        "        data_train, data_valid = split_data(data_customer_cat1_cat2_cat3_grouped_fillna, window_size)\n",
        "        # print(data_train.shape)\n",
        "        # print(data_valid.shape)\n",
        "        if data_train.shape[0] > 0 and data_valid.shape[0] > 0:\n",
        "          data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "\n",
        "\n",
        "          data_train_windowed = windowed_dataset(data_train, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "          data_valid_windowed = windowed_dataset(data_valid, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "          # Model Variables\n",
        "          model_name = 'M1'\n",
        "          loss = 'mse'\n",
        "          optimizer = 'adam'\n",
        "          patience = 40\n",
        "          epochs = 500\n",
        "          n_features = data_train.shape[1]\n",
        "\n",
        "          callbacks = MyCallbacks(patience)\n",
        "          model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "          history = model.fit(\n",
        "              data_train_windowed,\n",
        "              validation_data=data_valid_windowed,\n",
        "              callbacks=callbacks,\n",
        "              verbose=0,\n",
        "              epochs=epochs\n",
        "              )\n",
        "\n",
        "          plot_history(history)\n",
        "\n",
        "          predictions = generate_predictions_4(model, data_valid_norm, norm_params)\n",
        "          predicciones_by_customer_serie = sumar_series(predicciones_by_customer_serie, predictions)\n",
        "\n",
        "      filename = f\"{customer}_{customer_cat1}_{customer_cat1_cat2}\"\n",
        "      to_kaggle_2(predicciones_by_customer_serie, filename)\n",
        "      print(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PJV8X-u8w7Ak",
        "outputId": "01007074-bed2-4da6-c332-113fd2b7972f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_41 (Conv1D)          (None, 3, 64)             2560      \n",
            "                                                                 \n",
            " max_pooling1d_41 (MaxPooli  (None, 1, 64)             0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " bidirectional_82 (Bidirect  (None, 1, 64)             24832     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_83 (Bidirect  (None, 32)                10368     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 26)                858       \n",
            "                                                                 \n",
            " reshape_41 (Reshape)        (None, 2, 13)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38618 (150.85 KB)\n",
            "Trainable params: 38618 (150.85 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 14s 14s/step - loss: 156.7432 - mae: 6.0213 - val_loss: 40.1492 - val_mae: 4.0746\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 156.5917 - mae: 6.0134 - val_loss: 40.0542 - val_mae: 4.0681\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 156.3426 - mae: 6.0030 - val_loss: 39.9475 - val_mae: 4.0599\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 156.2950 - mae: 5.9951 - val_loss: 39.8343 - val_mae: 4.0510\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 156.1395 - mae: 5.9856 - val_loss: 39.7215 - val_mae: 4.0409\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 155.9007 - mae: 5.9770 - val_loss: 39.6092 - val_mae: 4.0303\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 155.7395 - mae: 5.9645 - val_loss: 39.4972 - val_mae: 4.0196\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 155.4955 - mae: 5.9511 - val_loss: 39.3847 - val_mae: 4.0090\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 155.4971 - mae: 5.9516 - val_loss: 39.2690 - val_mae: 3.9984\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 155.2262 - mae: 5.9318 - val_loss: 39.1491 - val_mae: 3.9876\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 154.8058 - mae: 5.9111 - val_loss: 39.0246 - val_mae: 3.9767\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 154.5687 - mae: 5.9070 - val_loss: 38.8949 - val_mae: 3.9667\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 154.5106 - mae: 5.8969 - val_loss: 38.7606 - val_mae: 3.9564\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 154.4805 - mae: 5.8867 - val_loss: 38.6218 - val_mae: 3.9453\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 154.0441 - mae: 5.8765 - val_loss: 38.4782 - val_mae: 3.9338\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 153.7152 - mae: 5.8555 - val_loss: 38.3301 - val_mae: 3.9219\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 153.5461 - mae: 5.8512 - val_loss: 38.1772 - val_mae: 3.9096\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 153.0163 - mae: 5.8218 - val_loss: 38.0188 - val_mae: 3.8969\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 153.2285 - mae: 5.8196 - val_loss: 37.8487 - val_mae: 3.8832\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 152.6818 - mae: 5.7999 - val_loss: 37.6709 - val_mae: 3.8689\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 152.5711 - mae: 5.7769 - val_loss: 37.4846 - val_mae: 3.8540\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 152.3593 - mae: 5.7836 - val_loss: 37.2803 - val_mae: 3.8381\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 151.9676 - mae: 5.7691 - val_loss: 37.0684 - val_mae: 3.8216\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 151.1126 - mae: 5.7221 - val_loss: 36.8497 - val_mae: 3.8044\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 151.1642 - mae: 5.7125 - val_loss: 36.6242 - val_mae: 3.7865\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 150.7027 - mae: 5.7094 - val_loss: 36.3921 - val_mae: 3.7680\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 150.2681 - mae: 5.6788 - val_loss: 36.1533 - val_mae: 3.7502\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 150.0202 - mae: 5.6763 - val_loss: 35.9081 - val_mae: 3.7342\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 149.4045 - mae: 5.6461 - val_loss: 35.6560 - val_mae: 3.7213\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 149.4570 - mae: 5.6364 - val_loss: 35.3991 - val_mae: 3.7092\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 148.2273 - mae: 5.5981 - val_loss: 35.1370 - val_mae: 3.6967\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 148.2613 - mae: 5.5955 - val_loss: 34.8706 - val_mae: 3.6840\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 148.2249 - mae: 5.5658 - val_loss: 34.6012 - val_mae: 3.6710\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 147.0888 - mae: 5.5045 - val_loss: 34.3299 - val_mae: 3.6578\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 147.2849 - mae: 5.5315 - val_loss: 34.0570 - val_mae: 3.6443\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 145.6658 - mae: 5.4844 - val_loss: 33.7810 - val_mae: 3.6296\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 146.3492 - mae: 5.4683 - val_loss: 33.5060 - val_mae: 3.6149\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 145.5230 - mae: 5.4492 - val_loss: 33.2318 - val_mae: 3.6030\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 145.7785 - mae: 5.4515 - val_loss: 32.9587 - val_mae: 3.5910\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 144.9675 - mae: 5.4289 - val_loss: 32.6868 - val_mae: 3.5789\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 143.6731 - mae: 5.3844 - val_loss: 32.4136 - val_mae: 3.5664\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 144.8072 - mae: 5.3994 - val_loss: 32.1384 - val_mae: 3.5531\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 143.8961 - mae: 5.3479 - val_loss: 31.8645 - val_mae: 3.5389\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 142.8082 - mae: 5.3235 - val_loss: 31.5914 - val_mae: 3.5263\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 144.2813 - mae: 5.3366 - val_loss: 31.3210 - val_mae: 3.5135\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 142.3000 - mae: 5.2780 - val_loss: 31.0508 - val_mae: 3.5004\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 141.3882 - mae: 5.2320 - val_loss: 30.7803 - val_mae: 3.4868\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 142.4308 - mae: 5.2666 - val_loss: 30.5116 - val_mae: 3.4729\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 141.6915 - mae: 5.2482 - val_loss: 30.2454 - val_mae: 3.4586\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 139.5074 - mae: 5.2129 - val_loss: 29.9813 - val_mae: 3.4439\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 140.3734 - mae: 5.1706 - val_loss: 29.7212 - val_mae: 3.4291\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 138.6694 - mae: 5.1550 - val_loss: 29.4643 - val_mae: 3.4139\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 139.7120 - mae: 5.1775 - val_loss: 29.2130 - val_mae: 3.3985\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 138.4276 - mae: 5.1307 - val_loss: 28.9666 - val_mae: 3.3830\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 138.7776 - mae: 5.1011 - val_loss: 28.7250 - val_mae: 3.3673\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 137.4739 - mae: 5.0708 - val_loss: 28.4878 - val_mae: 3.3522\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 138.2113 - mae: 5.1048 - val_loss: 28.2549 - val_mae: 3.3397\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 137.0437 - mae: 5.0345 - val_loss: 28.0257 - val_mae: 3.3296\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 137.0985 - mae: 5.0582 - val_loss: 27.8003 - val_mae: 3.3216\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 135.9487 - mae: 5.0197 - val_loss: 27.5775 - val_mae: 3.3135\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 136.2366 - mae: 5.0117 - val_loss: 27.3572 - val_mae: 3.3052\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 135.5761 - mae: 5.0125 - val_loss: 27.1390 - val_mae: 3.2972\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 134.6079 - mae: 4.9484 - val_loss: 26.9223 - val_mae: 3.2904\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 134.2273 - mae: 4.8838 - val_loss: 26.7076 - val_mae: 3.2833\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 133.5750 - mae: 4.9073 - val_loss: 26.4943 - val_mae: 3.2758\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 133.5582 - mae: 4.8956 - val_loss: 26.2827 - val_mae: 3.2681\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 132.8043 - mae: 4.8642 - val_loss: 26.0733 - val_mae: 3.2601\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 133.5506 - mae: 4.8731 - val_loss: 25.8663 - val_mae: 3.2517\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 132.2943 - mae: 4.8200 - val_loss: 25.6614 - val_mae: 3.2429\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 133.6091 - mae: 4.8407 - val_loss: 25.4599 - val_mae: 3.2340\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 131.2314 - mae: 4.8021 - val_loss: 25.2600 - val_mae: 3.2248\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 130.9846 - mae: 4.7657 - val_loss: 25.0620 - val_mae: 3.2152\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 131.2258 - mae: 4.7988 - val_loss: 24.8666 - val_mae: 3.2053\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 130.2660 - mae: 4.7730 - val_loss: 24.6724 - val_mae: 3.1949\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 131.9442 - mae: 4.7564 - val_loss: 24.4812 - val_mae: 3.1843\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 130.0386 - mae: 4.7729 - val_loss: 24.2921 - val_mae: 3.1733\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 129.3691 - mae: 4.7373 - val_loss: 24.1069 - val_mae: 3.1621\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 130.3352 - mae: 4.7340 - val_loss: 23.9243 - val_mae: 3.1508\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 129.4544 - mae: 4.6648 - val_loss: 23.7431 - val_mae: 3.1390\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 127.6826 - mae: 4.6941 - val_loss: 23.5631 - val_mae: 3.1268\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 128.7033 - mae: 4.6996 - val_loss: 23.3863 - val_mae: 3.1147\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 126.5182 - mae: 4.6041 - val_loss: 23.2111 - val_mae: 3.1026\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 127.4710 - mae: 4.6393 - val_loss: 23.0370 - val_mae: 3.0905\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 129.1557 - mae: 4.6261 - val_loss: 22.8658 - val_mae: 3.0784\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 127.4427 - mae: 4.6214 - val_loss: 22.6970 - val_mae: 3.0664\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 125.0399 - mae: 4.5632 - val_loss: 22.5298 - val_mae: 3.0543\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 126.7693 - mae: 4.5829 - val_loss: 22.3642 - val_mae: 3.0428\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 128.0312 - mae: 4.5620 - val_loss: 22.2019 - val_mae: 3.0334\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 125.6649 - mae: 4.5665 - val_loss: 22.0428 - val_mae: 3.0250\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 125.1135 - mae: 4.5540 - val_loss: 21.8856 - val_mae: 3.0165\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 125.0914 - mae: 4.5665 - val_loss: 21.7300 - val_mae: 3.0080\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 125.3608 - mae: 4.5230 - val_loss: 21.5767 - val_mae: 2.9994\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 123.6785 - mae: 4.4709 - val_loss: 21.4247 - val_mae: 2.9907\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 123.0544 - mae: 4.4707 - val_loss: 21.2741 - val_mae: 2.9817\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 123.7056 - mae: 4.4602 - val_loss: 21.1260 - val_mae: 2.9730\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 120.9249 - mae: 4.3914 - val_loss: 20.9782 - val_mae: 2.9639\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 124.1169 - mae: 4.4654 - val_loss: 20.8324 - val_mae: 2.9547\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 122.5763 - mae: 4.5291 - val_loss: 20.6881 - val_mae: 2.9456\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 122.1600 - mae: 4.4445 - val_loss: 20.5454 - val_mae: 2.9364\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 123.6926 - mae: 4.4538 - val_loss: 20.4057 - val_mae: 2.9271\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 122.8474 - mae: 4.4662 - val_loss: 20.2667 - val_mae: 2.9175\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 123.0997 - mae: 4.4194 - val_loss: 20.1304 - val_mae: 2.9085\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 122.6260 - mae: 4.4174 - val_loss: 19.9968 - val_mae: 2.8995\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 121.7617 - mae: 4.3739 - val_loss: 19.8643 - val_mae: 2.8905\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 120.7309 - mae: 4.4101 - val_loss: 19.7336 - val_mae: 2.8814\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 123.7088 - mae: 4.4557 - val_loss: 19.6044 - val_mae: 2.8726\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 119.0166 - mae: 4.3189 - val_loss: 19.4764 - val_mae: 2.8638\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 121.8546 - mae: 4.3877 - val_loss: 19.3518 - val_mae: 2.8554\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 123.7864 - mae: 4.4377 - val_loss: 19.2310 - val_mae: 2.8473\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 119.4065 - mae: 4.3089 - val_loss: 19.1125 - val_mae: 2.8391\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 118.2264 - mae: 4.3190 - val_loss: 18.9939 - val_mae: 2.8309\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 120.7018 - mae: 4.3625 - val_loss: 18.8771 - val_mae: 2.8228\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 120.3005 - mae: 4.3452 - val_loss: 18.7623 - val_mae: 2.8148\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 117.5668 - mae: 4.2586 - val_loss: 18.6485 - val_mae: 2.8068\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 121.1540 - mae: 4.3394 - val_loss: 18.5369 - val_mae: 2.7991\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 119.5046 - mae: 4.2601 - val_loss: 18.4269 - val_mae: 2.7915\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 117.2894 - mae: 4.3041 - val_loss: 18.3170 - val_mae: 2.7839\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 119.6753 - mae: 4.2964 - val_loss: 18.2080 - val_mae: 2.7764\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 116.0264 - mae: 4.2378 - val_loss: 18.0990 - val_mae: 2.7687\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 118.4910 - mae: 4.2637 - val_loss: 17.9920 - val_mae: 2.7612\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 117.6182 - mae: 4.2146 - val_loss: 17.8855 - val_mae: 2.7534\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 117.8293 - mae: 4.2442 - val_loss: 17.7802 - val_mae: 2.7456\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 116.0442 - mae: 4.1904 - val_loss: 17.6749 - val_mae: 2.7376\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 116.8745 - mae: 4.2339 - val_loss: 17.5707 - val_mae: 2.7297\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 116.7002 - mae: 4.1956 - val_loss: 17.4677 - val_mae: 2.7219\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 118.2514 - mae: 4.2519 - val_loss: 17.3668 - val_mae: 2.7144\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 115.1800 - mae: 4.2279 - val_loss: 17.2674 - val_mae: 2.7071\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 114.7848 - mae: 4.2231 - val_loss: 17.1696 - val_mae: 2.6999\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 114.2840 - mae: 4.1272 - val_loss: 17.0717 - val_mae: 2.6925\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 114.6145 - mae: 4.1548 - val_loss: 16.9749 - val_mae: 2.6850\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 117.0136 - mae: 4.1915 - val_loss: 16.8794 - val_mae: 2.6775\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 114.3088 - mae: 4.1321 - val_loss: 16.7854 - val_mae: 2.6703\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 115.0829 - mae: 4.1690 - val_loss: 16.6921 - val_mae: 2.6631\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 113.7357 - mae: 4.1240 - val_loss: 16.5987 - val_mae: 2.6557\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 112.2762 - mae: 4.0596 - val_loss: 16.5052 - val_mae: 2.6480\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 114.1807 - mae: 4.1393 - val_loss: 16.4118 - val_mae: 2.6404\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 114.8627 - mae: 4.1745 - val_loss: 16.3201 - val_mae: 2.6326\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 113.5847 - mae: 4.1010 - val_loss: 16.2300 - val_mae: 2.6265\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 111.5565 - mae: 4.1066 - val_loss: 16.1395 - val_mae: 2.6204\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 112.2562 - mae: 4.0802 - val_loss: 16.0493 - val_mae: 2.6141\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 112.0185 - mae: 4.0559 - val_loss: 15.9593 - val_mae: 2.6082\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 110.5488 - mae: 4.0423 - val_loss: 15.8702 - val_mae: 2.6022\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 111.3789 - mae: 4.0279 - val_loss: 15.7817 - val_mae: 2.5962\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 112.7156 - mae: 4.0296 - val_loss: 15.6941 - val_mae: 2.5902\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 110.8639 - mae: 4.0377 - val_loss: 15.6059 - val_mae: 2.5840\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 112.9365 - mae: 4.0707 - val_loss: 15.5184 - val_mae: 2.5777\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 113.1644 - mae: 4.0807 - val_loss: 15.4320 - val_mae: 2.5715\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 112.8006 - mae: 4.0671 - val_loss: 15.3381 - val_mae: 2.5640\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 109.9899 - mae: 4.0330 - val_loss: 15.2372 - val_mae: 2.5554\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 110.1946 - mae: 3.9784 - val_loss: 15.1366 - val_mae: 2.5469\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 113.2311 - mae: 4.1304 - val_loss: 15.0385 - val_mae: 2.5387\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 109.6323 - mae: 4.0393 - val_loss: 14.9406 - val_mae: 2.5304\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 111.9178 - mae: 3.9979 - val_loss: 14.8443 - val_mae: 2.5223\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 114.2502 - mae: 4.1402 - val_loss: 14.7499 - val_mae: 2.5144\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 110.5922 - mae: 3.9937 - val_loss: 14.6568 - val_mae: 2.5068\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 111.3662 - mae: 4.0141 - val_loss: 14.5650 - val_mae: 2.4991\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 110.1935 - mae: 3.9818 - val_loss: 14.4758 - val_mae: 2.4916\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 109.3388 - mae: 3.9893 - val_loss: 14.3863 - val_mae: 2.4840\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 110.6293 - mae: 4.0075 - val_loss: 14.2997 - val_mae: 2.4768\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 109.2334 - mae: 3.9929 - val_loss: 14.2162 - val_mae: 2.4700\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 109.3641 - mae: 3.9475 - val_loss: 14.1340 - val_mae: 2.4633\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 108.8418 - mae: 3.9212 - val_loss: 14.0531 - val_mae: 2.4567\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 106.2221 - mae: 3.8289 - val_loss: 13.9722 - val_mae: 2.4498\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 109.2800 - mae: 3.9131 - val_loss: 13.8926 - val_mae: 2.4430\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 109.6608 - mae: 3.9667 - val_loss: 13.8152 - val_mae: 2.4366\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 107.4773 - mae: 3.9052 - val_loss: 13.7380 - val_mae: 2.4301\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 109.2742 - mae: 3.8504 - val_loss: 13.6627 - val_mae: 2.4236\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 108.1296 - mae: 3.8954 - val_loss: 13.5900 - val_mae: 2.4177\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 107.3588 - mae: 3.8808 - val_loss: 13.5186 - val_mae: 2.4118\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 109.5606 - mae: 3.9673 - val_loss: 13.4476 - val_mae: 2.4059\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 105.9041 - mae: 3.8512 - val_loss: 13.3771 - val_mae: 2.3998\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 106.5173 - mae: 3.8567 - val_loss: 13.3078 - val_mae: 2.3938\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 104.7046 - mae: 3.8217 - val_loss: 13.2391 - val_mae: 2.3879\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 108.0051 - mae: 3.9006 - val_loss: 13.1726 - val_mae: 2.3825\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 107.4797 - mae: 3.9192 - val_loss: 13.1068 - val_mae: 2.3771\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 105.6577 - mae: 3.8610 - val_loss: 13.0410 - val_mae: 2.3717\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 106.2912 - mae: 3.8991 - val_loss: 12.9762 - val_mae: 2.3664\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 106.4113 - mae: 3.8327 - val_loss: 12.9111 - val_mae: 2.3609\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 106.8002 - mae: 3.8402 - val_loss: 12.8453 - val_mae: 2.3553\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 105.4697 - mae: 3.8682 - val_loss: 12.7821 - val_mae: 2.3502\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 105.3879 - mae: 3.8252 - val_loss: 12.7187 - val_mae: 2.3447\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 107.3022 - mae: 3.8548 - val_loss: 12.6583 - val_mae: 2.3397\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 105.6317 - mae: 3.8945 - val_loss: 12.5990 - val_mae: 2.3350\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 107.5062 - mae: 3.8423 - val_loss: 12.5398 - val_mae: 2.3302\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 106.5147 - mae: 3.8554 - val_loss: 12.4799 - val_mae: 2.3251\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 102.3324 - mae: 3.7893 - val_loss: 12.4201 - val_mae: 2.3198\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 106.7799 - mae: 3.9079 - val_loss: 12.3596 - val_mae: 2.3144\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 107.5447 - mae: 3.8436 - val_loss: 12.2999 - val_mae: 2.3091\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 105.6912 - mae: 3.8003 - val_loss: 12.2402 - val_mae: 2.3038\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 104.8688 - mae: 3.8080 - val_loss: 12.1806 - val_mae: 2.2985\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 102.4544 - mae: 3.7418 - val_loss: 12.1218 - val_mae: 2.2932\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 104.7301 - mae: 3.8219 - val_loss: 12.0620 - val_mae: 2.2874\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 103.8915 - mae: 3.8610 - val_loss: 12.0026 - val_mae: 2.2817\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 104.4176 - mae: 3.8168 - val_loss: 11.9429 - val_mae: 2.2757\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 105.4470 - mae: 3.8511 - val_loss: 11.8828 - val_mae: 2.2699\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 105.6345 - mae: 3.7926 - val_loss: 11.8233 - val_mae: 2.2642\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 104.4729 - mae: 3.7793 - val_loss: 11.7646 - val_mae: 2.2584\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 102.4722 - mae: 3.8043 - val_loss: 11.7044 - val_mae: 2.2520\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 103.5789 - mae: 3.7689 - val_loss: 11.6457 - val_mae: 2.2460\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 103.7664 - mae: 3.7971 - val_loss: 11.5892 - val_mae: 2.2405\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 105.2986 - mae: 3.8427 - val_loss: 11.5351 - val_mae: 2.2354\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 103.3397 - mae: 3.7407 - val_loss: 11.4825 - val_mae: 2.2304\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 102.9880 - mae: 3.7332 - val_loss: 11.4302 - val_mae: 2.2267\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 101.1553 - mae: 3.6911 - val_loss: 11.3783 - val_mae: 2.2229\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 102.1100 - mae: 3.8110 - val_loss: 11.3269 - val_mae: 2.2191\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 103.1999 - mae: 3.7707 - val_loss: 11.2750 - val_mae: 2.2152\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 105.3802 - mae: 3.7807 - val_loss: 11.2247 - val_mae: 2.2116\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 102.5104 - mae: 3.7515 - val_loss: 11.1750 - val_mae: 2.2081\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 103.3221 - mae: 3.7839 - val_loss: 11.1263 - val_mae: 2.2047\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 102.3168 - mae: 3.7717 - val_loss: 11.0772 - val_mae: 2.2012\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 103.5465 - mae: 3.7706 - val_loss: 11.0287 - val_mae: 2.1980\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 98.9739 - mae: 3.6524 - val_loss: 10.9798 - val_mae: 2.1948\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 101.6534 - mae: 3.7247 - val_loss: 10.9300 - val_mae: 2.1912\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 102.4511 - mae: 3.7636 - val_loss: 10.8804 - val_mae: 2.1874\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 101.5944 - mae: 3.7638 - val_loss: 10.8330 - val_mae: 2.1839\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 100.9899 - mae: 3.6526 - val_loss: 10.7848 - val_mae: 2.1801\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 100.6208 - mae: 3.6642 - val_loss: 10.7380 - val_mae: 2.1765\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 101.0447 - mae: 3.6688 - val_loss: 10.6908 - val_mae: 2.1728\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 104.1117 - mae: 3.7780 - val_loss: 10.6430 - val_mae: 2.1688\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 105.2740 - mae: 3.8308 - val_loss: 10.5946 - val_mae: 2.1648\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 101.1992 - mae: 3.6487 - val_loss: 10.5463 - val_mae: 2.1606\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 99.3524 - mae: 3.6740 - val_loss: 10.4989 - val_mae: 2.1565\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 100.1961 - mae: 3.6361 - val_loss: 10.4505 - val_mae: 2.1523\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 100.5648 - mae: 3.6230 - val_loss: 10.4030 - val_mae: 2.1481\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 103.1767 - mae: 3.7688 - val_loss: 10.3558 - val_mae: 2.1439\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 103.1174 - mae: 3.7390 - val_loss: 10.3091 - val_mae: 2.1398\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 99.4415 - mae: 3.5969 - val_loss: 10.2619 - val_mae: 2.1356\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 102.0692 - mae: 3.6168 - val_loss: 10.2156 - val_mae: 2.1316\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 103.4836 - mae: 3.7555 - val_loss: 10.1706 - val_mae: 2.1280\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 99.3783 - mae: 3.6319 - val_loss: 10.1250 - val_mae: 2.1242\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 98.2915 - mae: 3.5950 - val_loss: 10.0798 - val_mae: 2.1204\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 100.5136 - mae: 3.6506 - val_loss: 10.0348 - val_mae: 2.1166\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 98.0528 - mae: 3.5481 - val_loss: 9.9895 - val_mae: 2.1124\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 102.3011 - mae: 3.6435 - val_loss: 9.9449 - val_mae: 2.1085\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 102.0715 - mae: 3.6320 - val_loss: 9.9018 - val_mae: 2.1047\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 101.7974 - mae: 3.6930 - val_loss: 9.8584 - val_mae: 2.1008\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 98.3495 - mae: 3.6330 - val_loss: 9.8155 - val_mae: 2.0969\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 98.0634 - mae: 3.6128 - val_loss: 9.7724 - val_mae: 2.0930\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 97.6919 - mae: 3.5545 - val_loss: 9.7299 - val_mae: 2.0894\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 96.7408 - mae: 3.5256 - val_loss: 9.6896 - val_mae: 2.0862\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 96.3569 - mae: 3.6111 - val_loss: 9.6500 - val_mae: 2.0830\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 99.5257 - mae: 3.6122 - val_loss: 9.6122 - val_mae: 2.0802\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 95.7562 - mae: 3.5470 - val_loss: 9.5743 - val_mae: 2.0772\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 100.1306 - mae: 3.6897 - val_loss: 9.5359 - val_mae: 2.0740\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 97.4575 - mae: 3.6071 - val_loss: 9.4986 - val_mae: 2.0709\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 97.1104 - mae: 3.5831 - val_loss: 9.4621 - val_mae: 2.0682\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 98.6062 - mae: 3.6191 - val_loss: 9.4265 - val_mae: 2.0656\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 97.3217 - mae: 3.5546 - val_loss: 9.3918 - val_mae: 2.0631\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 95.1917 - mae: 3.5251 - val_loss: 9.3572 - val_mae: 2.0604\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 98.3796 - mae: 3.6202 - val_loss: 9.3229 - val_mae: 2.0578\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 96.6197 - mae: 3.5689 - val_loss: 9.2887 - val_mae: 2.0551\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 94.9589 - mae: 3.5296 - val_loss: 9.2538 - val_mae: 2.0522\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 99.7957 - mae: 3.6238 - val_loss: 9.2183 - val_mae: 2.0493\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 99.1363 - mae: 3.6274 - val_loss: 9.1832 - val_mae: 2.0463\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 95.5460 - mae: 3.4773 - val_loss: 9.1470 - val_mae: 2.0429\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 94.2103 - mae: 3.5052 - val_loss: 9.1102 - val_mae: 2.0404\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 98.1628 - mae: 3.5650 - val_loss: 9.0743 - val_mae: 2.0384\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 99.7023 - mae: 3.6264 - val_loss: 9.0409 - val_mae: 2.0367\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 98.3971 - mae: 3.6032 - val_loss: 9.0080 - val_mae: 2.0352\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 96.8462 - mae: 3.5282 - val_loss: 8.9758 - val_mae: 2.0339\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 100.5600 - mae: 3.6712 - val_loss: 8.9441 - val_mae: 2.0328\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 96.4636 - mae: 3.5063 - val_loss: 8.9129 - val_mae: 2.0316\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 96.6181 - mae: 3.5073 - val_loss: 8.8816 - val_mae: 2.0302\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 99.2222 - mae: 3.5694 - val_loss: 8.8515 - val_mae: 2.0290\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 94.9884 - mae: 3.4703 - val_loss: 8.8203 - val_mae: 2.0273\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 95.3680 - mae: 3.5306 - val_loss: 8.7878 - val_mae: 2.0252\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 95.0082 - mae: 3.5202 - val_loss: 8.7547 - val_mae: 2.0227\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 101.2140 - mae: 3.6333 - val_loss: 8.7215 - val_mae: 2.0203\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 91.9405 - mae: 3.4905 - val_loss: 8.6876 - val_mae: 2.0177\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 97.8546 - mae: 3.5604 - val_loss: 8.6534 - val_mae: 2.0150\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 93.6035 - mae: 3.5604 - val_loss: 8.6187 - val_mae: 2.0121\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 92.9200 - mae: 3.4766 - val_loss: 8.5849 - val_mae: 2.0092\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 92.7624 - mae: 3.4535 - val_loss: 8.5515 - val_mae: 2.0062\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 95.4760 - mae: 3.4490 - val_loss: 8.5191 - val_mae: 2.0033\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 93.0477 - mae: 3.4324 - val_loss: 8.4862 - val_mae: 1.9999\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 94.3180 - mae: 3.5242 - val_loss: 8.4536 - val_mae: 1.9967\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 94.2254 - mae: 3.4805 - val_loss: 8.4202 - val_mae: 1.9930\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 98.4187 - mae: 3.5457 - val_loss: 8.3873 - val_mae: 1.9894\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 93.7695 - mae: 3.4200 - val_loss: 8.3554 - val_mae: 1.9859\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 94.6708 - mae: 3.5060 - val_loss: 8.3235 - val_mae: 1.9825\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 96.1766 - mae: 3.5143 - val_loss: 8.2920 - val_mae: 1.9794\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 94.5015 - mae: 3.4802 - val_loss: 8.2596 - val_mae: 1.9759\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 97.0202 - mae: 3.4897 - val_loss: 8.2275 - val_mae: 1.9726\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 94.8188 - mae: 3.4864 - val_loss: 8.1960 - val_mae: 1.9695\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 93.4837 - mae: 3.4664 - val_loss: 8.1647 - val_mae: 1.9665\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 92.9020 - mae: 3.3938 - val_loss: 8.1334 - val_mae: 1.9636\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 93.7389 - mae: 3.4836 - val_loss: 8.1023 - val_mae: 1.9607\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 91.3942 - mae: 3.3929 - val_loss: 8.0699 - val_mae: 1.9572\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 93.1329 - mae: 3.4169 - val_loss: 8.0386 - val_mae: 1.9539\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 95.3811 - mae: 3.4233 - val_loss: 8.0090 - val_mae: 1.9511\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 94.4508 - mae: 3.4560 - val_loss: 7.9803 - val_mae: 1.9495\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 96.5919 - mae: 3.5166 - val_loss: 7.9504 - val_mae: 1.9479\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 92.8129 - mae: 3.4647 - val_loss: 7.9211 - val_mae: 1.9464\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 96.9237 - mae: 3.4304 - val_loss: 7.8935 - val_mae: 1.9452\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 92.1210 - mae: 3.4466 - val_loss: 7.8657 - val_mae: 1.9438\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 90.9199 - mae: 3.3888 - val_loss: 7.8370 - val_mae: 1.9422\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 97.3303 - mae: 3.4755 - val_loss: 7.8095 - val_mae: 1.9408\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 95.0684 - mae: 3.4768 - val_loss: 7.7829 - val_mae: 1.9397\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 93.7160 - mae: 3.4494 - val_loss: 7.7572 - val_mae: 1.9386\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 92.4804 - mae: 3.4372 - val_loss: 7.7330 - val_mae: 1.9378\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 93.2219 - mae: 3.4136 - val_loss: 7.7093 - val_mae: 1.9370\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 95.4878 - mae: 3.4144 - val_loss: 7.6868 - val_mae: 1.9367\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 90.9866 - mae: 3.4470 - val_loss: 7.6635 - val_mae: 1.9360\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 92.5008 - mae: 3.4410 - val_loss: 7.6403 - val_mae: 1.9354\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 92.3285 - mae: 3.4644 - val_loss: 7.6177 - val_mae: 1.9348\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 94.4850 - mae: 3.4878 - val_loss: 7.5938 - val_mae: 1.9338\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 91.1822 - mae: 3.3862 - val_loss: 7.5685 - val_mae: 1.9325\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 93.2610 - mae: 3.4540 - val_loss: 7.5431 - val_mae: 1.9311\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 90.3764 - mae: 3.3909 - val_loss: 7.5169 - val_mae: 1.9293\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 95.7629 - mae: 3.5399 - val_loss: 7.4914 - val_mae: 1.9277\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 89.5759 - mae: 3.3152 - val_loss: 7.4669 - val_mae: 1.9262\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 90.3627 - mae: 3.3582 - val_loss: 7.4425 - val_mae: 1.9246\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 92.8902 - mae: 3.3707 - val_loss: 7.4187 - val_mae: 1.9232\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 87.7642 - mae: 3.2746 - val_loss: 7.3946 - val_mae: 1.9217\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 92.4166 - mae: 3.3464 - val_loss: 7.3712 - val_mae: 1.9204\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 90.5815 - mae: 3.3813 - val_loss: 7.3474 - val_mae: 1.9190\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 91.2518 - mae: 3.5094 - val_loss: 7.3249 - val_mae: 1.9181\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 87.0651 - mae: 3.2616 - val_loss: 7.3022 - val_mae: 1.9169\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 90.3647 - mae: 3.3569 - val_loss: 7.2801 - val_mae: 1.9157\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 93.1477 - mae: 3.3326 - val_loss: 7.2577 - val_mae: 1.9143\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 93.0592 - mae: 3.4415 - val_loss: 7.2346 - val_mae: 1.9129\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 90.5437 - mae: 3.3754 - val_loss: 7.2132 - val_mae: 1.9117\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 89.8065 - mae: 3.3049 - val_loss: 7.1928 - val_mae: 1.9105\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 87.0374 - mae: 3.2496 - val_loss: 7.1732 - val_mae: 1.9094\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 91.2264 - mae: 3.3284 - val_loss: 7.1537 - val_mae: 1.9083\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 89.5564 - mae: 3.3507 - val_loss: 7.1339 - val_mae: 1.9071\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 88.0411 - mae: 3.3229 - val_loss: 7.1141 - val_mae: 1.9057\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 87.6733 - mae: 3.3504 - val_loss: 7.0947 - val_mae: 1.9044\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 88.3825 - mae: 3.2794 - val_loss: 7.0743 - val_mae: 1.9027\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 89.9677 - mae: 3.3385 - val_loss: 7.0536 - val_mae: 1.9009\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 87.9249 - mae: 3.3365 - val_loss: 7.0318 - val_mae: 1.8986\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 90.2197 - mae: 3.3270 - val_loss: 7.0104 - val_mae: 1.8964\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 88.6113 - mae: 3.3404 - val_loss: 6.9905 - val_mae: 1.8946\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 89.2446 - mae: 3.3047 - val_loss: 6.9701 - val_mae: 1.8925\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 92.6436 - mae: 3.3548 - val_loss: 6.9502 - val_mae: 1.8908\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 91.7886 - mae: 3.3570 - val_loss: 6.9313 - val_mae: 1.8892\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 89.1939 - mae: 3.2610 - val_loss: 6.9121 - val_mae: 1.8876\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 91.1355 - mae: 3.3480 - val_loss: 6.8920 - val_mae: 1.8859\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 90.2156 - mae: 3.3322 - val_loss: 6.8714 - val_mae: 1.8839\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 88.3798 - mae: 3.3142 - val_loss: 6.8514 - val_mae: 1.8822\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 85.4502 - mae: 3.3066 - val_loss: 6.8310 - val_mae: 1.8802\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 86.9107 - mae: 3.2794 - val_loss: 6.8110 - val_mae: 1.8783\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 87.7355 - mae: 3.3117 - val_loss: 6.7922 - val_mae: 1.8766\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 89.6181 - mae: 3.3230 - val_loss: 6.7730 - val_mae: 1.8748\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 88.0315 - mae: 3.2892 - val_loss: 6.7536 - val_mae: 1.8727\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 86.9904 - mae: 3.2709 - val_loss: 6.7341 - val_mae: 1.8712\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 88.8679 - mae: 3.3112 - val_loss: 6.7146 - val_mae: 1.8706\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 83.3814 - mae: 3.2337 - val_loss: 6.6958 - val_mae: 1.8703\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 85.5135 - mae: 3.2520 - val_loss: 6.6765 - val_mae: 1.8698\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 86.8099 - mae: 3.2864 - val_loss: 6.6567 - val_mae: 1.8692\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 85.7296 - mae: 3.3082 - val_loss: 6.6370 - val_mae: 1.8687\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 89.6582 - mae: 3.3612 - val_loss: 6.6179 - val_mae: 1.8685\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 91.3665 - mae: 3.3162 - val_loss: 6.5989 - val_mae: 1.8684\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 88.8037 - mae: 3.3278 - val_loss: 6.5811 - val_mae: 1.8686\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 89.5246 - mae: 3.2856 - val_loss: 6.5633 - val_mae: 1.8687\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 87.6546 - mae: 3.3020 - val_loss: 6.5463 - val_mae: 1.8687\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 88.5763 - mae: 3.3385 - val_loss: 6.5302 - val_mae: 1.8689\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 87.4226 - mae: 3.2500 - val_loss: 6.5157 - val_mae: 1.8697\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 89.6104 - mae: 3.3857 - val_loss: 6.5020 - val_mae: 1.8707\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 85.8666 - mae: 3.2685 - val_loss: 6.4894 - val_mae: 1.8719\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 89.8979 - mae: 3.3535 - val_loss: 6.4758 - val_mae: 1.8728\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 89.7125 - mae: 3.4265 - val_loss: 6.4623 - val_mae: 1.8747\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 86.6142 - mae: 3.2017 - val_loss: 6.4498 - val_mae: 1.8772\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 87.4730 - mae: 3.2501 - val_loss: 6.4369 - val_mae: 1.8796\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 91.5025 - mae: 3.4320 - val_loss: 6.4241 - val_mae: 1.8820\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 87.4076 - mae: 3.2935 - val_loss: 6.4114 - val_mae: 1.8842\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 83.0491 - mae: 3.1869 - val_loss: 6.3997 - val_mae: 1.8865\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 88.9413 - mae: 3.2540 - val_loss: 6.3870 - val_mae: 1.8885\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 89.2578 - mae: 3.4003 - val_loss: 6.3728 - val_mae: 1.8900\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 87.7230 - mae: 3.2902 - val_loss: 6.3591 - val_mae: 1.8915\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 87.1454 - mae: 3.3043 - val_loss: 6.3453 - val_mae: 1.8928\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 86.5441 - mae: 3.2247 - val_loss: 6.3314 - val_mae: 1.8938\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 90.9880 - mae: 3.3014 - val_loss: 6.3180 - val_mae: 1.8947\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 86.3473 - mae: 3.3223 - val_loss: 6.3055 - val_mae: 1.8958\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 88.2622 - mae: 3.3224 - val_loss: 6.2923 - val_mae: 1.8966\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 86.5292 - mae: 3.2841 - val_loss: 6.2796 - val_mae: 1.8973\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 85.6204 - mae: 3.2032 - val_loss: 6.2679 - val_mae: 1.8982\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 89.4682 - mae: 3.4237 - val_loss: 6.2558 - val_mae: 1.8989\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 85.0788 - mae: 3.2664 - val_loss: 6.2446 - val_mae: 1.8997\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 85.5047 - mae: 3.2899 - val_loss: 6.2325 - val_mae: 1.9002\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 86.6092 - mae: 3.2869 - val_loss: 6.2203 - val_mae: 1.9007\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 87.6813 - mae: 3.2886 - val_loss: 6.2080 - val_mae: 1.9012\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 86.7194 - mae: 3.2541 - val_loss: 6.1966 - val_mae: 1.9021\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 87.0211 - mae: 3.3237 - val_loss: 6.1847 - val_mae: 1.9027\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 86.2105 - mae: 3.2156 - val_loss: 6.1741 - val_mae: 1.9036\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 86.5088 - mae: 3.2508 - val_loss: 6.1641 - val_mae: 1.9046\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 85.0013 - mae: 3.2580 - val_loss: 6.1542 - val_mae: 1.9055\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 85.5476 - mae: 3.2103 - val_loss: 6.1444 - val_mae: 1.9065\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 85.3783 - mae: 3.2319 - val_loss: 6.1343 - val_mae: 1.9076\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 86.4738 - mae: 3.1833 - val_loss: 6.1240 - val_mae: 1.9089\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 85.8833 - mae: 3.2780 - val_loss: 6.1132 - val_mae: 1.9100\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 88.2544 - mae: 3.2621 - val_loss: 6.1027 - val_mae: 1.9112\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 82.6868 - mae: 3.2425 - val_loss: 6.0912 - val_mae: 1.9119\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 85.0395 - mae: 3.1981 - val_loss: 6.0799 - val_mae: 1.9128\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 87.1188 - mae: 3.2717 - val_loss: 6.0691 - val_mae: 1.9139\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 85.4152 - mae: 3.2653 - val_loss: 6.0588 - val_mae: 1.9150\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 84.5520 - mae: 3.1988 - val_loss: 6.0486 - val_mae: 1.9160\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 83.2317 - mae: 3.2282 - val_loss: 6.0381 - val_mae: 1.9171\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 85.6769 - mae: 3.1787 - val_loss: 6.0270 - val_mae: 1.9182\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 81.4777 - mae: 3.1326 - val_loss: 6.0157 - val_mae: 1.9190\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 83.6770 - mae: 3.2676 - val_loss: 6.0051 - val_mae: 1.9200\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 83.6834 - mae: 3.2484 - val_loss: 5.9928 - val_mae: 1.9204\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 82.3439 - mae: 3.1698 - val_loss: 5.9800 - val_mae: 1.9207\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 80.3073 - mae: 3.1275 - val_loss: 5.9676 - val_mae: 1.9210\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 84.2985 - mae: 3.1576 - val_loss: 5.9546 - val_mae: 1.9213\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 84.7694 - mae: 3.2567 - val_loss: 5.9412 - val_mae: 1.9210\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 89.3347 - mae: 3.3010 - val_loss: 5.9273 - val_mae: 1.9209\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 79.7922 - mae: 3.1978 - val_loss: 5.9140 - val_mae: 1.9207\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 86.7788 - mae: 3.3311 - val_loss: 5.9005 - val_mae: 1.9205\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 81.4669 - mae: 3.1161 - val_loss: 5.8870 - val_mae: 1.9200\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 83.3915 - mae: 3.1776 - val_loss: 5.8729 - val_mae: 1.9193\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 85.6504 - mae: 3.1902 - val_loss: 5.8593 - val_mae: 1.9187\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 86.7691 - mae: 3.2376 - val_loss: 5.8456 - val_mae: 1.9182\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 86.1232 - mae: 3.2181 - val_loss: 5.8327 - val_mae: 1.9179\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 83.6136 - mae: 3.1808 - val_loss: 5.8211 - val_mae: 1.9182\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 84.8583 - mae: 3.2416 - val_loss: 5.8094 - val_mae: 1.9186\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 87.3437 - mae: 3.3465 - val_loss: 5.7979 - val_mae: 1.9189\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 81.4872 - mae: 3.2642 - val_loss: 5.7869 - val_mae: 1.9194\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 84.6771 - mae: 3.1754 - val_loss: 5.7771 - val_mae: 1.9202\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 81.8751 - mae: 3.2257 - val_loss: 5.7680 - val_mae: 1.9212\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 80.0714 - mae: 3.0653 - val_loss: 5.7605 - val_mae: 1.9226\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 81.9530 - mae: 3.1406 - val_loss: 5.7531 - val_mae: 1.9240\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 81.7012 - mae: 3.1334 - val_loss: 5.7465 - val_mae: 1.9256\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 80.7390 - mae: 3.1182 - val_loss: 5.7398 - val_mae: 1.9270\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 87.4900 - mae: 3.2251 - val_loss: 5.7340 - val_mae: 1.9285\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 86.1004 - mae: 3.2616 - val_loss: 5.7273 - val_mae: 1.9296\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 80.6556 - mae: 3.1905 - val_loss: 5.7204 - val_mae: 1.9308\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 83.2344 - mae: 3.1504 - val_loss: 5.7136 - val_mae: 1.9319\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 81.3005 - mae: 3.1200 - val_loss: 5.7066 - val_mae: 1.9327\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 81.7590 - mae: 3.2045 - val_loss: 5.6990 - val_mae: 1.9333\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 80.1181 - mae: 3.1403 - val_loss: 5.6914 - val_mae: 1.9338\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 80.4188 - mae: 3.0972 - val_loss: 5.6853 - val_mae: 1.9345\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 80.5641 - mae: 3.1886 - val_loss: 5.6801 - val_mae: 1.9356\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 83.1856 - mae: 3.1263 - val_loss: 5.6739 - val_mae: 1.9365\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 84.3956 - mae: 3.1211 - val_loss: 5.6666 - val_mae: 1.9371\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 80.2737 - mae: 3.1010 - val_loss: 5.6603 - val_mae: 1.9379\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 79.1738 - mae: 3.1541 - val_loss: 5.6536 - val_mae: 1.9385\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 77.2203 - mae: 3.0970 - val_loss: 5.6464 - val_mae: 1.9388\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 83.9777 - mae: 3.1919 - val_loss: 5.6391 - val_mae: 1.9391\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 82.4610 - mae: 3.1959 - val_loss: 5.6323 - val_mae: 1.9395\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 80.1869 - mae: 3.1907 - val_loss: 5.6263 - val_mae: 1.9403\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 78.9170 - mae: 3.0466 - val_loss: 5.6203 - val_mae: 1.9411\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 83.7088 - mae: 3.2139 - val_loss: 5.6132 - val_mae: 1.9414\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 82.2165 - mae: 3.1389 - val_loss: 5.6051 - val_mae: 1.9415\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 80.4738 - mae: 3.1696 - val_loss: 5.5979 - val_mae: 1.9418\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 82.3960 - mae: 3.1375 - val_loss: 5.5912 - val_mae: 1.9422\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 80.6202 - mae: 3.1297 - val_loss: 5.5830 - val_mae: 1.9422\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 79.9486 - mae: 3.1757 - val_loss: 5.5740 - val_mae: 1.9418\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 83.8133 - mae: 3.1701 - val_loss: 5.5650 - val_mae: 1.9413\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 79.7881 - mae: 3.0897 - val_loss: 5.5568 - val_mae: 1.9410\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 85.7553 - mae: 3.2005 - val_loss: 5.5489 - val_mae: 1.9407\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 81.8726 - mae: 3.1946 - val_loss: 5.5413 - val_mae: 1.9407\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 85.5716 - mae: 3.1966 - val_loss: 5.5341 - val_mae: 1.9407\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 82.4172 - mae: 3.1085 - val_loss: 5.5281 - val_mae: 1.9414\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 79.5231 - mae: 3.1343 - val_loss: 5.5222 - val_mae: 1.9418\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 81.2579 - mae: 3.1377 - val_loss: 5.5164 - val_mae: 1.9423\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 78.4239 - mae: 3.0073 - val_loss: 5.5110 - val_mae: 1.9429\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 79.5546 - mae: 3.0668 - val_loss: 5.5057 - val_mae: 1.9435\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 82.0542 - mae: 3.2095 - val_loss: 5.5004 - val_mae: 1.9441\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 82.8191 - mae: 3.1834 - val_loss: 5.4941 - val_mae: 1.9444\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 82.6291 - mae: 3.1799 - val_loss: 5.4876 - val_mae: 1.9445\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 81.7638 - mae: 3.1742 - val_loss: 5.4809 - val_mae: 1.9445\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 79.7640 - mae: 3.1239 - val_loss: 5.4750 - val_mae: 1.9447\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 79.3705 - mae: 3.0845 - val_loss: 5.4693 - val_mae: 1.9450\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 79.4083 - mae: 3.0714 - val_loss: 5.4649 - val_mae: 1.9456\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 79.7163 - mae: 3.1470 - val_loss: 5.4607 - val_mae: 1.9462\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 80.2824 - mae: 3.1525 - val_loss: 5.4566 - val_mae: 1.9468\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 77.9175 - mae: 3.0741 - val_loss: 5.4525 - val_mae: 1.9475\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 82.1139 - mae: 3.1594 - val_loss: 5.4491 - val_mae: 1.9485\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 77.7560 - mae: 3.0696 - val_loss: 5.4467 - val_mae: 1.9497\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 81.1590 - mae: 3.1449 - val_loss: 5.4441 - val_mae: 1.9509\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 83.9517 - mae: 3.1651 - val_loss: 5.4408 - val_mae: 1.9518\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 78.3968 - mae: 3.1153 - val_loss: 5.4376 - val_mae: 1.9526\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 83.9865 - mae: 3.2205 - val_loss: 5.4354 - val_mae: 1.9538\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 80.8569 - mae: 3.1172 - val_loss: 5.4330 - val_mae: 1.9550\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 79.3637 - mae: 3.1175 - val_loss: 5.4304 - val_mae: 1.9560\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 80.8822 - mae: 3.0893 - val_loss: 5.4268 - val_mae: 1.9567\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 81.8310 - mae: 3.1521 - val_loss: 5.4240 - val_mae: 1.9575\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 82.5779 - mae: 3.2152 - val_loss: 5.4219 - val_mae: 1.9586\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 85.8652 - mae: 3.2214 - val_loss: 5.4208 - val_mae: 1.9599\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 77.6850 - mae: 3.0998 - val_loss: 5.4187 - val_mae: 1.9609\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 77.4108 - mae: 3.1711 - val_loss: 5.4160 - val_mae: 1.9615\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 82.3060 - mae: 3.1036 - val_loss: 5.4126 - val_mae: 1.9617\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 83.2525 - mae: 3.1939 - val_loss: 5.4100 - val_mae: 1.9623\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 77.8856 - mae: 3.0619 - val_loss: 5.4078 - val_mae: 1.9632\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 76.1796 - mae: 3.0486 - val_loss: 5.4058 - val_mae: 1.9640\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 75.6278 - mae: 3.0770 - val_loss: 5.4042 - val_mae: 1.9649\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 77.6963 - mae: 3.0888 - val_loss: 5.4029 - val_mae: 1.9657\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 78.8664 - mae: 3.0606 - val_loss: 5.4017 - val_mae: 1.9665\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 78.6982 - mae: 3.0839 - val_loss: 5.4009 - val_mae: 1.9672\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 80.7854 - mae: 3.2172 - val_loss: 5.3996 - val_mae: 1.9677\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 81.6396 - mae: 3.1184 - val_loss: 5.3987 - val_mae: 1.9683\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 77.3203 - mae: 3.1674 - val_loss: 5.3969 - val_mae: 1.9685\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 85.1500 - mae: 3.2175 - val_loss: 5.3951 - val_mae: 1.9687\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 80.9251 - mae: 3.0802 - val_loss: 5.3940 - val_mae: 1.9690\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 78.9480 - mae: 3.0812 - val_loss: 5.3932 - val_mae: 1.9692\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 78.2688 - mae: 3.0881 - val_loss: 5.3923 - val_mae: 1.9694\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 79.1559 - mae: 3.1307 - val_loss: 5.3929 - val_mae: 1.9700\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 77.9620 - mae: 3.0988 - val_loss: 5.3934 - val_mae: 1.9704\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 81.0179 - mae: 3.2009 - val_loss: 5.3931 - val_mae: 1.9707\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 82.9584 - mae: 3.0794 - val_loss: 5.3925 - val_mae: 1.9709\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 77.8435 - mae: 3.1047 - val_loss: 5.3922 - val_mae: 1.9712\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 80.8001 - mae: 3.0598 - val_loss: 5.3922 - val_mae: 1.9716\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 79.9936 - mae: 3.0755 - val_loss: 5.3930 - val_mae: 1.9722\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 78.2747 - mae: 3.1143 - val_loss: 5.3955 - val_mae: 1.9733\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 82.9040 - mae: 3.2033 - val_loss: 5.3970 - val_mae: 1.9744\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 81.7525 - mae: 3.0631 - val_loss: 5.3978 - val_mae: 1.9754\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 79.3009 - mae: 3.0667 - val_loss: 5.3976 - val_mae: 1.9758\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 80.3043 - mae: 3.1190 - val_loss: 5.3966 - val_mae: 1.9761\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 80.7395 - mae: 3.1124 - val_loss: 5.3960 - val_mae: 1.9765\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 80.6845 - mae: 3.1233 - val_loss: 5.3947 - val_mae: 1.9768\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 79.1796 - mae: 3.0658 - val_loss: 5.3935 - val_mae: 1.9771\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 78.9095 - mae: 3.1197 - val_loss: 5.3917 - val_mae: 1.9773\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 79.7870 - mae: 3.1180 - val_loss: 5.3902 - val_mae: 1.9775\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 78.5760 - mae: 3.0754 - val_loss: 5.3888 - val_mae: 1.9777\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 77.8794 - mae: 3.0717 - val_loss: 5.3876 - val_mae: 1.9780\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 79.4286 - mae: 3.1041 - val_loss: 5.3868 - val_mae: 1.9782\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 78.2750 - mae: 3.0875 - val_loss: 5.3851 - val_mae: 1.9781\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 78.6807 - mae: 3.1288 - val_loss: 5.3838 - val_mae: 1.9781\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 79.0400 - mae: 3.0228 - val_loss: 5.3829 - val_mae: 1.9783\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 80.0788 - mae: 3.1991 - val_loss: 5.3814 - val_mae: 1.9781\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 79.4959 - mae: 3.1565 - val_loss: 5.3788 - val_mae: 1.9775\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 84.9064 - mae: 3.2101 - val_loss: 5.3777 - val_mae: 1.9775\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 78.6597 - mae: 3.1075 - val_loss: 5.3764 - val_mae: 1.9774\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 79.8566 - mae: 3.1372 - val_loss: 5.3753 - val_mae: 1.9774\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 78.4106 - mae: 3.0350 - val_loss: 5.3750 - val_mae: 1.9776\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 80.7751 - mae: 3.1025 - val_loss: 5.3751 - val_mae: 1.9780\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 77.1302 - mae: 3.0649 - val_loss: 5.3751 - val_mae: 1.9782\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 76.3903 - mae: 3.0478 - val_loss: 5.3748 - val_mae: 1.9784\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 79.4849 - mae: 3.1113 - val_loss: 5.3743 - val_mae: 1.9785\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 77.2639 - mae: 3.1543 - val_loss: 5.3726 - val_mae: 1.9783\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 78.9762 - mae: 3.1026 - val_loss: 5.3714 - val_mae: 1.9783\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 81.6666 - mae: 3.1619 - val_loss: 5.3709 - val_mae: 1.9784\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 79.3157 - mae: 3.0228 - val_loss: 5.3712 - val_mae: 1.9789\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 79.7834 - mae: 3.1263 - val_loss: 5.3713 - val_mae: 1.9793\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 76.5800 - mae: 3.0446 - val_loss: 5.3719 - val_mae: 1.9798\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 78.0817 - mae: 3.0368 - val_loss: 5.3726 - val_mae: 1.9802\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 79.2363 - mae: 3.0321 - val_loss: 5.3729 - val_mae: 1.9805\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 81.2223 - mae: 3.0760 - val_loss: 5.3735 - val_mae: 1.9808\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 76.0699 - mae: 3.0052 - val_loss: 5.3744 - val_mae: 1.9811\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 80.2196 - mae: 3.1171 - val_loss: 5.3750 - val_mae: 1.9814\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 72.6172 - mae: 2.9619 - val_loss: 5.3762 - val_mae: 1.9816\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 77.0208 - mae: 2.9961 - val_loss: 5.3780 - val_mae: 1.9820\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 77.5178 - mae: 3.0786 - val_loss: 5.3801 - val_mae: 1.9824\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 80.5795 - mae: 3.0721 - val_loss: 5.3831 - val_mae: 1.9832\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 78.0114 - mae: 3.0752 - val_loss: 5.3847 - val_mae: 1.9834\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 75.9512 - mae: 3.0168 - val_loss: 5.3868 - val_mae: 1.9838\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 78.6246 - mae: 3.0395 - val_loss: 5.3895 - val_mae: 1.9844\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 78.9223 - mae: 3.1172 - val_loss: 5.3917 - val_mae: 1.9849\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 80.4445 - mae: 3.1133 - val_loss: 5.3937 - val_mae: 1.9852\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 77.4963 - mae: 3.0517 - val_loss: 5.3957 - val_mae: 1.9856\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 73.3389 - mae: 2.9690 - val_loss: 5.3972 - val_mae: 1.9858\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 80.1651 - mae: 3.0477 - val_loss: 5.3994 - val_mae: 1.9862\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 78.3303 - mae: 3.0115 - val_loss: 5.4013 - val_mae: 1.9865\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 73.9475 - mae: 2.9694 - val_loss: 5.4028 - val_mae: 1.9865\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 77.0929 - mae: 2.9853 - val_loss: 5.4045 - val_mae: 1.9866\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 78.1294 - mae: 3.1161 - val_loss: 5.4052 - val_mae: 1.9865\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 78.7554 - mae: 3.0801 - val_loss: 5.4060 - val_mae: 1.9863\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 73.3859 - mae: 2.9748 - val_loss: 5.4070 - val_mae: 1.9861\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 72.3538 - mae: 2.9595 - val_loss: 5.4070 - val_mae: 1.9855\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 77.3986 - mae: 3.0649 - val_loss: 5.4070 - val_mae: 1.9850\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 73.8778 - mae: 2.9720 - val_loss: 5.4072 - val_mae: 1.9845\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 80.3957 - mae: 3.0616 - val_loss: 5.4088 - val_mae: 1.9845\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 74.3442 - mae: 3.0250 - val_loss: 5.4103 - val_mae: 1.9845\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 76.5563 - mae: 2.9821 - val_loss: 5.4122 - val_mae: 1.9847\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 76.6758 - mae: 3.0540 - val_loss: 5.4137 - val_mae: 1.9848\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 76.2805 - mae: 3.0728 - val_loss: 5.4139 - val_mae: 1.9844\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 81.9704 - mae: 3.1079 - val_loss: 5.4148 - val_mae: 1.9844\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 74.8479 - mae: 3.0298 - val_loss: 5.4157 - val_mae: 1.9843\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 78.8143 - mae: 2.9886 - val_loss: 5.4176 - val_mae: 1.9844\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 77.4669 - mae: 3.1090 - val_loss: 5.4194 - val_mae: 1.9846\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 76.8767 - mae: 3.0760 - val_loss: 5.4204 - val_mae: 1.9845\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 77.9882 - mae: 3.0134 - val_loss: 5.4222 - val_mae: 1.9847\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 76.7906 - mae: 3.0222 - val_loss: 5.4253 - val_mae: 1.9852\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 74.8070 - mae: 2.9607 - val_loss: 5.4290 - val_mae: 1.9858\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 74.1037 - mae: 2.9987 - val_loss: 5.4322 - val_mae: 1.9862\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 80.9066 - mae: 3.1179 - val_loss: 5.4336 - val_mae: 1.9860\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 75.7458 - mae: 3.0446 - val_loss: 5.4345 - val_mae: 1.9855\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 80.4758 - mae: 3.1487 - val_loss: 5.4363 - val_mae: 1.9853\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 76.9087 - mae: 3.0872 - val_loss: 5.4384 - val_mae: 1.9851\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 76.1562 - mae: 3.0482 - val_loss: 5.4393 - val_mae: 1.9847\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 72.9533 - mae: 3.0773 - val_loss: 5.4392 - val_mae: 1.9838\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 79.0204 - mae: 3.1178 - val_loss: 5.4393 - val_mae: 1.9831\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_42 (Conv1D)          (None, 3, 64)             1600      \n",
            "                                                                 \n",
            " max_pooling1d_42 (MaxPooli  (None, 1, 64)             0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " bidirectional_84 (Bidirect  (None, 1, 64)             24832     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " bidirectional_85 (Bidirect  (None, 32)                10368     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " reshape_42 (Reshape)        (None, 2, 8)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37328 (145.81 KB)\n",
            "Trainable params: 37328 (145.81 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 12s 12s/step - loss: 233.2878 - mae: 8.7572 - val_loss: 74.6910 - val_mae: 5.6267\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 232.9137 - mae: 8.7459 - val_loss: 74.5161 - val_mae: 5.6199\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 232.4256 - mae: 8.7359 - val_loss: 74.3246 - val_mae: 5.6122\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 232.1562 - mae: 8.7283 - val_loss: 74.1197 - val_mae: 5.6031\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 231.6841 - mae: 8.7160 - val_loss: 73.9045 - val_mae: 5.5930\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 231.0613 - mae: 8.7026 - val_loss: 73.6846 - val_mae: 5.5826\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 230.9686 - mae: 8.6941 - val_loss: 73.4582 - val_mae: 5.5719\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 230.6795 - mae: 8.6851 - val_loss: 73.2238 - val_mae: 5.5607\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 230.1697 - mae: 8.6766 - val_loss: 72.9829 - val_mae: 5.5491\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 230.1860 - mae: 8.6705 - val_loss: 72.7321 - val_mae: 5.5370\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 228.9654 - mae: 8.6388 - val_loss: 72.4710 - val_mae: 5.5244\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 228.6277 - mae: 8.6389 - val_loss: 72.1960 - val_mae: 5.5110\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 228.1442 - mae: 8.6164 - val_loss: 71.9083 - val_mae: 5.4970\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 227.7557 - mae: 8.5982 - val_loss: 71.6066 - val_mae: 5.4820\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 226.9061 - mae: 8.5863 - val_loss: 71.2917 - val_mae: 5.4663\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 226.7645 - mae: 8.5731 - val_loss: 70.9645 - val_mae: 5.4497\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 226.5088 - mae: 8.5591 - val_loss: 70.6243 - val_mae: 5.4322\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 226.1649 - mae: 8.5546 - val_loss: 70.2733 - val_mae: 5.4138\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 225.2071 - mae: 8.5195 - val_loss: 69.9111 - val_mae: 5.3946\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 224.6219 - mae: 8.5107 - val_loss: 69.5367 - val_mae: 5.3773\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 224.1877 - mae: 8.4997 - val_loss: 69.1531 - val_mae: 5.3596\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 223.2539 - mae: 8.4828 - val_loss: 68.7560 - val_mae: 5.3442\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 222.5487 - mae: 8.4333 - val_loss: 68.3459 - val_mae: 5.3297\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 222.3081 - mae: 8.4340 - val_loss: 67.9219 - val_mae: 5.3147\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 221.9638 - mae: 8.4274 - val_loss: 67.4827 - val_mae: 5.2990\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 220.6803 - mae: 8.4026 - val_loss: 67.0312 - val_mae: 5.2829\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 220.1383 - mae: 8.3619 - val_loss: 66.5704 - val_mae: 5.2663\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 219.3236 - mae: 8.3716 - val_loss: 66.1012 - val_mae: 5.2492\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 217.4445 - mae: 8.2946 - val_loss: 65.6216 - val_mae: 5.2313\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 216.8607 - mae: 8.2844 - val_loss: 65.1329 - val_mae: 5.2128\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 217.0403 - mae: 8.3110 - val_loss: 64.6377 - val_mae: 5.1939\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 215.4507 - mae: 8.2329 - val_loss: 64.1357 - val_mae: 5.1743\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 215.1615 - mae: 8.2385 - val_loss: 63.6279 - val_mae: 5.1542\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 214.3726 - mae: 8.2126 - val_loss: 63.1137 - val_mae: 5.1337\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 213.7370 - mae: 8.2016 - val_loss: 62.5960 - val_mae: 5.1129\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 213.7234 - mae: 8.2017 - val_loss: 62.0752 - val_mae: 5.0916\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 211.9916 - mae: 8.1560 - val_loss: 61.5508 - val_mae: 5.0735\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 211.7366 - mae: 8.1623 - val_loss: 61.0260 - val_mae: 5.0559\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 211.0332 - mae: 8.1213 - val_loss: 60.5031 - val_mae: 5.0376\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 209.7894 - mae: 8.0721 - val_loss: 59.9813 - val_mae: 5.0187\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 209.9934 - mae: 8.0957 - val_loss: 59.4629 - val_mae: 5.0047\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 210.0132 - mae: 8.0978 - val_loss: 58.9394 - val_mae: 4.9895\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 207.0303 - mae: 8.0096 - val_loss: 58.4087 - val_mae: 4.9728\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 206.3558 - mae: 8.0312 - val_loss: 57.8796 - val_mae: 4.9552\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 205.8222 - mae: 7.9747 - val_loss: 57.3529 - val_mae: 4.9381\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 204.7827 - mae: 7.9446 - val_loss: 56.8308 - val_mae: 4.9237\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 205.1076 - mae: 7.9452 - val_loss: 56.3105 - val_mae: 4.9083\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 202.4274 - mae: 7.9201 - val_loss: 55.7924 - val_mae: 4.8924\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 202.4762 - mae: 7.9076 - val_loss: 55.2755 - val_mae: 4.8757\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 202.0246 - mae: 7.8824 - val_loss: 54.7597 - val_mae: 4.8581\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 202.3387 - mae: 7.8924 - val_loss: 54.2426 - val_mae: 4.8389\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 199.3632 - mae: 7.8531 - val_loss: 53.7263 - val_mae: 4.8189\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 200.4470 - mae: 7.8536 - val_loss: 53.2138 - val_mae: 4.7984\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 200.6597 - mae: 7.8394 - val_loss: 52.7079 - val_mae: 4.7775\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 197.2743 - mae: 7.7736 - val_loss: 52.2104 - val_mae: 4.7562\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 197.0557 - mae: 7.7755 - val_loss: 51.7227 - val_mae: 4.7344\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 193.9133 - mae: 7.6905 - val_loss: 51.2453 - val_mae: 4.7121\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 197.0283 - mae: 7.7168 - val_loss: 50.7803 - val_mae: 4.6899\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 194.9191 - mae: 7.7246 - val_loss: 50.3257 - val_mae: 4.6676\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 192.6621 - mae: 7.6270 - val_loss: 49.8817 - val_mae: 4.6451\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 191.4253 - mae: 7.5856 - val_loss: 49.4477 - val_mae: 4.6224\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 193.3846 - mae: 7.6236 - val_loss: 49.0252 - val_mae: 4.5998\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 191.8943 - mae: 7.5911 - val_loss: 48.6118 - val_mae: 4.5771\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 191.0531 - mae: 7.5681 - val_loss: 48.2085 - val_mae: 4.5545\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 190.0682 - mae: 7.5390 - val_loss: 47.8144 - val_mae: 4.5320\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 191.1910 - mae: 7.5929 - val_loss: 47.4289 - val_mae: 4.5096\n",
            "Epoch 67/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4b7b972b0676>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m           \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m           history = model.fit(\n\u001b[0m\u001b[1;32m     67\u001b[0m               \u001b[0mdata_train_windowed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_valid_windowed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/24 - Entrenamiento a 2018-05"
      ],
      "metadata": {
        "id": "9j2ZF_Jixctg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Todos los productos\n",
        "# data_201805 = data_extended.loc[:'2018-05']\n",
        "# data_201807 = data_extended.loc['2018-07']\n",
        "\n",
        "# # # Filtando por categorias\n",
        "# # data_201805 = data_extended.loc[:'2018-05'].query('cat1 == \"FOODS\"') # PC, HC, FOODS\n",
        "# # data_201807 = data_extended.loc['2018-07'].query('cat1 == \"FOODS\"') # PC, HC, FOODS\n",
        "\n",
        "# print('Cantidad productos al 201805:', data_201805['product_id'].unique().shape)\n",
        "# print('Cantidad productos en 201807:', data_201807['product_id'].unique().shape)\n",
        "\n",
        "# ytrue = data_201807.groupby('product_id')['tn'].sum()\n",
        "# # print(ytrue.head())\n",
        "\n",
        "# data_201805_grouped = group_data(data_201805, 'product_id')\n",
        "# data_201805_grouped_fillna = fill_nulls(data_201805_grouped)\n",
        "# # display(data_201805_grouped_fillna)\n",
        "\n",
        "# # Ojo que en Mayo tene,ps 976 prodictos, pero en Julio solo 846\n",
        "\n",
        "\n",
        "\n",
        "# split_strategy = 'S1'\n",
        "# normalization = 'MinMax'\n",
        "# window_size = None\n",
        "# horizon = 2\n",
        "# batch_size = None\n",
        "\n",
        "\n",
        "# # Model Variables: Dentro de cada Experimento, no son generales\n",
        "# n_features = None  # Esto va a depender de cada modelo, es el data_train.shape[1]\n",
        "# n_splits = None # No mas, la usabamos con el TimeSeriesSplit\n",
        "# # model_name = 'CAT1'\n",
        "# # loss = 'mse'\n",
        "# # optimizer = 'adam'\n",
        "# # patience = 30\n",
        "# # epochs = 10\n",
        "\n",
        "\n",
        "# window_size = 3\n",
        "# batch_size = 32\n",
        "\n",
        "# # Para el primer pipeline, entrenamiento correcto hasta 201805\n",
        "# data_train, data_valid = split_data_201805(data_201805_grouped_fillna, window_size)\n",
        "\n",
        "# data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "# print(data_train_norm.shape)\n",
        "\n",
        "# data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'M1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "# n_features = data_train.shape[1]\n",
        "\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data=data_valid_windowed,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=0,\n",
        "#     epochs=epochs\n",
        "#     )\n",
        "\n",
        "# plot_history(history)\n",
        "# predictions = generate_predictions_3(model, data_valid_norm, norm_params)\n",
        "\n",
        "# # Filtrar para obtener solo los índices que están en ambas series\n",
        "# common_indices = ytrue.index.intersection(predictions.index)\n",
        "\n",
        "# # Crear un DataFrame concatenando las dos series usando solo los índices comunes\n",
        "# predictions_df = pd.concat([ytrue[common_indices], predictions[common_indices]], axis=1)\n",
        "# predictions_df.columns = ['true', 'predicted']\n",
        "\n",
        "# calcular_error(predictions_df)"
      ],
      "metadata": {
        "id": "2Lc3n6sULjSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/24 - Entrenamiento con Datos del futuro (2018-07)"
      ],
      "metadata": {
        "id": "0hHUz3DaH72Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # OJO QUE ESTE ENTRENA HASTA 201807\n",
        "# # # no le cambio los nombres a la variable para que sea mas sencillo de correr\n",
        "\n",
        "# # Todos los productos\n",
        "# data_201805 = data_extended.loc[:'2018-07']\n",
        "# data_201807 = data_extended.loc['2018-07']\n",
        "\n",
        "# # # Filtando por categorias\n",
        "# # data_201805 = data_extended.loc[:'2018-07'].query('cat1 == \"PC\"') # PC, HC, FOODS\n",
        "# # data_201807 = data_extended.loc['2018-07'].query('cat1 == \"PC\"') # PC, HC, FOODS\n",
        "\n",
        "# print('Cantidad productos al 201805:', data_201805['product_id'].unique().shape)\n",
        "# print('Cantidad productos en 201807:', data_201807['product_id'].unique().shape)\n",
        "\n",
        "# ytrue = data_201807.groupby('product_id')['tn'].sum()\n",
        "# # print(ytrue.head())\n",
        "\n",
        "# data_201805_grouped = group_data(data_201805, 'product_id')\n",
        "# data_201805_grouped_fillna = fill_nulls(data_201805_grouped)\n",
        "# # display(data_201805_grouped_fillna)\n",
        "\n",
        "# # Ojo que en Mayo tene,ps 976 prodictos, pero en Julio solo 846\n",
        "\n",
        "\n",
        "\n",
        "# split_strategy = 'S1'\n",
        "# normalization = 'MinMax'\n",
        "# window_size = None\n",
        "# horizon = 2\n",
        "# batch_size = None\n",
        "\n",
        "\n",
        "# # Model Variables: Dentro de cada Experimento, no son generales\n",
        "# n_features = None  # Esto va a depender de cada modelo, es el data_train.shape[1]\n",
        "# n_splits = None # No mas, la usabamos con el TimeSeriesSplit\n",
        "# # model_name = 'CAT1'\n",
        "# # loss = 'mse'\n",
        "# # optimizer = 'adam'\n",
        "# # patience = 30\n",
        "# # epochs = 10\n",
        "\n",
        "\n",
        "\n",
        "# window_size = 3\n",
        "# batch_size = 32\n",
        "\n",
        "# # Segudno Pipeline, validacion con datos del futuro hasta 201807\n",
        "# data_train, data_valid = split_data_201807(data_201805_grouped_fillna, window_size)\n",
        "\n",
        "# data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "# print(data_train_norm.shape)\n",
        "\n",
        "# data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'M1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "# n_features = data_train.shape[1]\n",
        "\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data=data_valid_windowed,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=0,\n",
        "#     epochs=epochs\n",
        "#     )\n",
        "\n",
        "# plot_history(history)\n",
        "# predictions = generate_predictions_3(model, data_valid_norm, norm_params)\n",
        "\n",
        "# # Filtrar para obtener solo los índices que están en ambas series\n",
        "# common_indices = ytrue.index.intersection(predictions.index)\n",
        "\n",
        "# # Crear un DataFrame concatenando las dos series usando solo los índices comunes\n",
        "# predictions_df = pd.concat([ytrue[common_indices], predictions[common_indices]], axis=1)\n",
        "# predictions_df.columns = ['true', 'predicted']\n",
        "\n",
        "# calcular_error(predictions_df)"
      ],
      "metadata": {
        "id": "uo1QU5XWHW9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/20 - Prediccion de Producto, Multivariada por Clientes"
      ],
      "metadata": {
        "id": "mKJiBByKaaXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Inicializamos el vector de predicciones\n",
        "# vector_predictions = data_productos_a_predecir.copy()\n",
        "# vector_predictions['tn'] = 0\n",
        "# # vector_predictions['nulls'] = 0\n",
        "\n",
        "# # Eliminamos los productos que no nos interesan\n",
        "# data_products_filtered = filter_products_data(data_bkp, data_productos_a_predecir)\n",
        "\n",
        "# # Iteramos por cada producto\n",
        "# for product in data_productos_a_predecir.index[1:2]:\n",
        "#   # print(f'Producto {product}')\n",
        "\n",
        "#   data_product_grouped = group_data(data_products_filtered, 'customer_id')\n",
        "#   # print(data_product_grouped.shape)\n",
        "\n",
        "#   data_product_grouped_customer = data_product_grouped.columns\n",
        "#   # print(data_product_grouped_customer)\n",
        "\n",
        "#   # Inicializamos el vector predicciones por cliente, para ese producto\n",
        "#   vector_clientes = pd.DataFrame(pd.Series(data_product_grouped_customer.copy(), name='customer'))\n",
        "#   vector_clientes.set_index('customer', inplace=True)\n",
        "#   vector_clientes['tn'] = 0\n",
        "#   vector_clientes['nulls'] = 0\n",
        "\n",
        "#   # print(vector_clientes.head())\n",
        "\n",
        "#   # Recorremos las ventas de cada customer\n",
        "\n",
        "#   for customer in data_product_grouped_customer[3:5]:\n",
        "#     print(f'Producto {product}')\n",
        "#     print(f'Customer {customer}')\n",
        "#     data_product = data_product_grouped[customer].copy()\n",
        "#     cant_nulos = data_product.isnull().sum()\n",
        "#     data_product = data_product.to_frame()\n",
        "#     data_product.fillna(0, inplace=True)\n",
        "#     # print(data_product)\n",
        "\n",
        "\n",
        "#     # Añadir indicador de disponibilidad al producto\n",
        "#     # first_sale_date = data_product[data_product > 0].index[0]\n",
        "#     data_product['available'] = (data_product > 0).astype(int)\n",
        "#     # print(data_product)\n",
        "\n",
        "#     # Jugamos con esto acá, para ver el tema de la validación en el entrenamiento\n",
        "#     window_size = 6\n",
        "#     batch_size = 1\n",
        "\n",
        "#     data_train, data_valid = split_data(data_product, window_size)\n",
        "#     data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "\n",
        "#     # Convertir DataFrame a numpy array\n",
        "#     train_sequence = data_train_norm.values\n",
        "#     valid_sequence = data_valid_norm.values\n",
        "\n",
        "#     data_train_windowed = windowed_dataset(train_sequence, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#     data_valid_windowed = windowed_dataset(valid_sequence, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "#       # Model Variables\n",
        "#     model_name = 'xx'\n",
        "#     loss = 'mse'\n",
        "#     optimizer = 'adam'\n",
        "#     patience = 30\n",
        "#     epochs = 300\n",
        "#     n_features = data_train.shape[1]\n",
        "\n",
        "#     callbacks = MyCallbacks(patience)\n",
        "#     model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#     history = model.fit(\n",
        "#         data_train_windowed,\n",
        "#         validation_data=data_valid_windowed,\n",
        "#         callbacks=callbacks,\n",
        "#         verbose=1,\n",
        "#         epochs=epochs\n",
        "#     )\n",
        "\n",
        "#     plot_history(history)\n",
        "#     predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "\n",
        "#     # Vamos sumando en el vector de acum\n",
        "#     value_to_add = predictions.loc['2020-02'].values[0]\n",
        "#     vector_clientes.loc[customer, 'nulls'] = cant_nulos\n",
        "#     vector_clientes.loc[customer, 'tn'] += value_to_add\n",
        "#     # print(vector_clientes)\n",
        "\n",
        "#   # print(vector_predictions.head())\n",
        "#   filename_cliente = f\"{product}_win{window_size}.csv\"\n",
        "#   # print(filename)\n",
        "#   vector_clientes.to_csv(filename_cliente, header=True, index=True)\n",
        "\n",
        "#   vector_predictions.loc[product, 'tn'] += vector_clientes['tn'].sum()\n",
        "\n",
        "# filename_predicciones = f\"SumaPredicciones_win{window_size}.csv\"\n",
        "# # print(filename)\n",
        "# vector_predictions.to_csv(filename_predicciones, header=True, index=True)\n"
      ],
      "metadata": {
        "id": "oJRVKBJnHV2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Analizamos la prediccion de un producto en particular, generanzo una matriz multivariada con columnas por cliente\n",
        "\n",
        "# # Producto 20001\n",
        "# data_20001 = data_bkp.query('product_id == \"20001\"')[['customer_id', 'tn']].copy()\n",
        "\n",
        "# print(data_20001.shape)\n",
        "# display(data_20001.head())\n",
        "\n",
        "# # plot_grouped_data_heatmap(data_20001, 'customer_id')\n",
        "\n",
        "# # No siempre se vende el producto estrella, inclusve as los clientes mas importantes\n",
        "\n",
        "# data_products_filtered = filter_products_data(data_bkp, data_productos_a_predecir)\n",
        "# print(data_products_filtered.shape)"
      ],
      "metadata": {
        "id": "lavrxuh_QKOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Creamos el Dataframe de ventas agrupadas por cliente/producto seleccionado\n",
        "# data_20001_grouped = group_data(data_20001, 'customer_id')\n",
        "\n",
        "# # Creamos el vector de clientes, pero solo los que tuvieron ventas del producto 20001\n",
        "# data_20001_customers = data_20001_grouped.columns\n",
        "\n",
        "# # Inicializamos el vector de predicciones\n",
        "# vector_clientes_20001 = pd.DataFrame(pd.Series(data_20001_customers.copy(), name='customer'))\n",
        "# vector_clientes_20001.set_index('customer', inplace=True)\n",
        "# vector_clientes_20001['tn'] = 0\n",
        "# vector_clientes_20001['nulls'] = 0\n",
        "# vector_clientes_20001.head()\n",
        "\n",
        "\n",
        "\n",
        "# for customer in data_20001_customers:\n",
        "#   # print(customer)\n",
        "#   data_product = data_20001_grouped[customer].copy()\n",
        "#   cant_nulos = data_product.isnull().sum()\n",
        "#   data_product = data_product.to_frame()\n",
        "#   data_product.fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "#     # Añadir indicador de disponibilidad al producto\n",
        "#   first_sale_date = data_product[data_product > 0].index[0]\n",
        "#   data_product['available'] = (data_product > 0).astype(int)\n",
        "\n",
        "#   # Jugamos con esto acá, para ver el tema de la validación en el entrenamiento\n",
        "#   window_size = 6\n",
        "#   batch_size = 1\n",
        "\n",
        "#   data_train, data_valid = split_data(data_product, window_size)\n",
        "#   data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "\n",
        "#   # Convertir DataFrame a numpy array\n",
        "#   train_sequence = data_train_norm.values\n",
        "#   valid_sequence = data_valid_norm.values\n",
        "\n",
        "#   data_train_windowed = windowed_dataset(train_sequence, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#   data_valid_windowed = windowed_dataset(valid_sequence, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "#   # Model Variables\n",
        "#   model_name = 'xx'\n",
        "#   loss = 'mse'\n",
        "#   optimizer = 'adam'\n",
        "#   patience = 30\n",
        "#   epochs = 300\n",
        "#   n_features = data_train.shape[1]\n",
        "\n",
        "#   callbacks = MyCallbacks(patience)\n",
        "#   model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#   history = model.fit(\n",
        "#       data_train_windowed,\n",
        "#       validation_data=data_valid_windowed,\n",
        "#       callbacks=callbacks,\n",
        "#       verbose=1,\n",
        "#       epochs=epochs\n",
        "#   )\n",
        "\n",
        "#   plot_history(history)\n",
        "\n",
        "#   predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "\n",
        "#   # Vamos sumando en el vector de acum\n",
        "#   value_to_add = predictions.loc['2020-02'].values[0]\n",
        "#   vector_clientes_20001.loc[customer, 'nulls'] = cant_nulos\n",
        "#   vector_clientes_20001.loc[customer, 'tn'] += value_to_add\n",
        "#   # vector_predictions.loc[predictions.name] += value_to_add\n",
        "#   # vector_predictions.loc[predictions.name, 'nulls'] = cant_nulos\n",
        "\n",
        "# # print(vector_predictions.head())\n",
        "# filename = f\"PrediccionesIndividuales{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "# # print(filename)\n",
        "# vector_clientes_20001.to_csv(filename, header=True, index=True)\n"
      ],
      "metadata": {
        "id": "uw9gbDzXf0Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/19 - Union de Distintas Predicciones"
      ],
      "metadata": {
        "id": "z8l2uyPVM23-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE.set_index('product_id', inplace=True)\n",
        "# completos = pd.read_csv('completos.csv')\n",
        "# completos.set_index('product_id', inplace=True)\n",
        "# completos.rename(columns={'tn': 'tn_comp'}, inplace=True)\n",
        "# incompletos = pd.read_csv('incompletos.csv')\n",
        "# incompletos.set_index('product_id', inplace=True)\n",
        "# incompletos.rename(columns={'tn': 'tn_inco'}, inplace=True)\n",
        "# data = BASELINE.join(completos, on='product_id', how='left').join(incompletos, on='product_id', how='left')\n",
        "\n",
        "# # Crear la columna tn_cand con las condiciones especificadas\n",
        "# data['tn_cand'] = np.where(data['tn_inco'].isna(), data['tn_comp'],\n",
        "#                            np.where(data['tn_comp'].isna(), data['tn_inco'], np.nan))\n",
        "\n",
        "\n",
        "\n",
        "# data['diff'] = abs((data['tn'] - data['tn_cand']))\n",
        "# data.loc[data['nulls'] > 24, 'tn_cand'] = data['tn']\n",
        "\n",
        "# casos_particualres = [20022, 20001, 20071]\n",
        "# data.loc[casos_particualres, 'tn_cand'] = data.loc[casos_particualres, 'tn']"
      ],
      "metadata": {
        "id": "o1XKtVI8LUUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/18 - Pruebas contra Diciembre 2019, nos olvidamos de Kaggle"
      ],
      "metadata": {
        "id": "-ORvfte2nIee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Separamos el Dataframe,\n",
        "# mask_productos_completos = data.isnull().sum() == 0\n",
        "# data_productos_completos = data.loc[:, mask_productos_completos]\n",
        "# data_productos_incompletos = data.loc[:, ~mask_productos_completos]\n",
        "# print(data_productos_completos.shape)\n",
        "# print(data_productos_incompletos.shape)\n"
      ],
      "metadata": {
        "id": "l-gvI28s-rs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Productos Incompletos\n",
        "# # Inicializamos el vector de predicciones\n",
        "# vector_predictions = data_productos_a_predecir[~mask_productos_completos].copy()\n",
        "# vector_predictions['tn'] = 0\n",
        "# vector_predictions['nulls'] = 0\n",
        "\n",
        "# for product in data_productos_incompletos.columns:\n",
        "#     print(product)\n",
        "\n",
        "#     # Modificar el valor del filtro, para analizar otros Productos. Ojo que hay productos que no tenemos todos los años y pincha\n",
        "#     data_product = data_productos_incompletos[product].copy()\n",
        "#     cant_nulos = data_product.isnull().sum()\n",
        "#     data_product = data_product.to_frame()\n",
        "#     data_product.fillna(0, inplace=True)\n",
        "\n",
        "#     # Añadir indicador de disponibilidad al producto\n",
        "#     first_sale_date = data_product[data_product > 0].index[0]\n",
        "#     data_product['available'] = (data_product.index >= first_sale_date).astype(int)\n",
        "#     # display(data_product.head())\n",
        "\n",
        "#     # Jugamos con esto acá, para ver el tema de la validación en el entrenamiento\n",
        "#     window_size = 6\n",
        "#     batch_size = 1\n",
        "\n",
        "#     data_train, data_valid = split_data(data_product, window_size)\n",
        "#     data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "\n",
        "#     # Convertir DataFrame a numpy array\n",
        "#     train_sequence = data_train_norm.values\n",
        "#     valid_sequence = data_valid_norm.values\n",
        "\n",
        "#     data_train_windowed = windowed_dataset(train_sequence, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#     data_valid_windowed = windowed_dataset(valid_sequence, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "#     # Model Variables\n",
        "#     model_name = 'xx'\n",
        "#     loss = 'mse'\n",
        "#     optimizer = 'adam'\n",
        "#     patience = 30\n",
        "#     epochs = 300\n",
        "#     n_features = data_train.shape[1]\n",
        "\n",
        "#     callbacks = MyCallbacks(patience)\n",
        "#     model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#     history = model.fit(\n",
        "#         data_train_windowed,\n",
        "#         validation_data=data_valid_windowed,\n",
        "#         callbacks=callbacks,\n",
        "#         verbose=1,\n",
        "#         epochs=epochs\n",
        "#     )\n",
        "\n",
        "#     plot_history(history)\n",
        "\n",
        "#     predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "\n",
        "#     # Vamos sumando en el vector de acum\n",
        "#     value_to_add = predictions.loc['2020-02'].values[0]\n",
        "#     vector_predictions.loc[predictions.name] += value_to_add\n",
        "#     vector_predictions.loc[predictions.name, 'nulls'] = cant_nulos\n",
        "\n",
        "# print(vector_predictions.head())\n",
        "# filename = f\"ProductosIncompletos2_{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "# print(filename)\n",
        "# vector_predictions.to_csv(filename, header=True, index=True)\n"
      ],
      "metadata": {
        "id": "xChrPJi2YcT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # Inicializamos el vector de predicciones\n",
        "# vector_predictions = data_productos_a_predecir[mask_productos_completos].copy()\n",
        "# vector_predictions['tn'] =0\n",
        "# # vector_predictions = vector_predictions.squeeze()\n",
        "\n",
        "# for product in data_productos_completos.columns:\n",
        "#   print(product)\n",
        "\n",
        "#   # Modificar el valor del filtro, para analizar otros Productos. Ojo que hay productos que no tenemos todos los anos y pincha\n",
        "#   data_product = data_productos_completos[product]\n",
        "\n",
        "#   # Jugamos con esto aca, para ver el tema de la validacion en el entrenamiento\n",
        "#   window_size = 6\n",
        "#   batch_size = 1\n",
        "\n",
        "\n",
        "#   data_train, data_valid = split_data(data_product, window_size)\n",
        "#   data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "#   # print(data_train.index)\n",
        "#   # print(data_valid.index)\n",
        "#   data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#   data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# #   # Model Variables\n",
        "#   model_name = 'xx'\n",
        "#   loss = 'mse'\n",
        "#   optimizer = 'adam'\n",
        "#   patience = 30\n",
        "#   epochs = 300\n",
        "#   n_features = data_train.shape[1]\n",
        "\n",
        "\n",
        "#   callbacks = MyCallbacks(patience)\n",
        "#   model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#   history = model.fit(\n",
        "#       data_train_windowed,\n",
        "#       validation_data = data_valid_windowed,\n",
        "#       callbacks = callbacks,\n",
        "#       verbose=0,\n",
        "#       epochs=epochs)\n",
        "\n",
        "#   # plot_history(history)\n",
        "\n",
        "#   predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "#   # plot_predictions_dec2019(data_product, predictions)\n",
        "\n",
        "#   # Vamos sumando en el vector de acum\n",
        "#   value_to_add = predictions.loc['2020-02'].values[0]\n",
        "#   vector_predictions.loc[predictions.name]+= value_to_add\n",
        "\n",
        "# print(vector_predictions.head())\n",
        "# filename = f\"ProductosCompletos_{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "# print(filename)\n",
        "# vector_predictions.to_csv(filename, header=True, index=False)"
      ],
      "metadata": {
        "id": "Jf49KKPC_uGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/17 - Ventas por dia"
      ],
      "metadata": {
        "id": "1HbokWwRHZEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data_bkp.copy()\n",
        "# data.sort_values(by=['periodo', 'customer_id', 'product_id'])\n",
        "# data = data[['customer_id', 'product_id', 'tn']]\n",
        "# data = data.merge(data_productos_a_predecir_con_categorias, left_on='product_id', right_on='product_id', how='left')\n",
        "# data.set_index(data_bkp.index, inplace=True)\n",
        "# data.sort_index(inplace=True)\n",
        "# data.sort_values(by=['periodo', 'customer_id', 'product_id'], inplace=True)\n",
        "\n",
        "\n",
        "# # # Vemos los nulos por variable\n",
        "# # print(data_merged.isnull().sum())\n",
        "\n",
        "\n",
        "# mask_cat1_null = data['cat1'].isnull()\n",
        "# # display(data_merged[mask_cat1_null])\n",
        "\n",
        "# # # Ninguno de estos productos nos interesa, no estan en nuestas categorias\n",
        "# # print(data_productos_a_predecir_con_categorias.index.isin(data_merged[mask_cat1_null]['product_id']).sum())\n",
        "# # print(data_merged.shape[0])\n",
        "\n",
        "# # Elimino los nulos\n",
        "# data.dropna(subset=['cat1'], inplace=True)\n",
        "# # print(\"Nulos:\", data.isnull().sum())\n",
        "# # print(data.shape)\n",
        "\n",
        "\n",
        "# # Contar las ocurrencias de cada combinación de periodo, customer_id y product_id\n",
        "# repeated_entries = data.groupby(['periodo', 'customer_id', 'product_id']).size()\n",
        "\n",
        "# # Filtrar combinaciones que aparecen más de una vez\n",
        "# repeated_entries = repeated_entries[repeated_entries > 1]\n",
        "\n",
        "# # Mostrar las combinaciones repetidas\n",
        "# print(repeated_entries)\n",
        "\n",
        "# # sin combinaciones repetidas\n",
        "\n",
        "# print(data.shape)\n",
        "# display(data.head())"
      ],
      "metadata": {
        "id": "N6XR0zgQTFJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ############################################################################################################\n",
        "# # # Verificamos los clientes Activos\n",
        "# ############################################################################################################\n",
        "# # Generamos la matriz de presencia\n",
        "# presencia_clientes = data.groupby(['periodo', 'customer_id']).size().unstack(fill_value=0)\n",
        "# presencia_clientes[presencia_clientes > 0] = 1  # Convertimos las cantidades en 1 para indicar presencia\n",
        "# mask_active_clients = presencia_clientes.loc['2019-10':'2019-12'].sum(axis=0) == 3\n",
        "\n",
        "# # Configuramos el tamaño de la figura\n",
        "# plt.figure(figsize=(15, 10))\n",
        "\n",
        "# # Creamos el heatmap\n",
        "# sns.heatmap(presencia_clientes, cmap='viridis', cbar=False, linewidths=.5)\n",
        "\n",
        "# # Añadimos los títulos y etiquetas\n",
        "# plt.title('Presencia de Clientes por Mes')\n",
        "# plt.xlabel('Clientes')\n",
        "# plt.ylabel('Mes')\n",
        "\n",
        "# # Mostramos el gráfico\n",
        "# plt.show()\n",
        "# ############################################################################################################\n",
        "\n",
        "# # Verificamos que el cliente 10039 no compro en el ultimo semestre, como algunos otros.\n",
        "# # Maybe podemos removerlos del experimento, ya que sabemos que no van a volver a comprar\n",
        "# display(data.groupby(['customer_id', 'periodo']).count()[['product_id']].loc[['10039']])\n",
        "\n",
        "\n",
        "# presencia_clientes = data.groupby(['periodo', 'customer_id']).size().unstack(fill_value=0)\n",
        "# presencia_clientes[presencia_clientes > 0] = 1\n",
        "\n",
        "# # Vemos 173 clientes, no compraron en diciembre\n",
        "# print(presencia_clientes.loc['2019-12'].sum(axis=0).value_counts())\n",
        "\n",
        "\n",
        "# # Y que de esos 173, 111 tampoco compraron en noviembre\n",
        "# print(presencia_clientes.loc['2019-11':'2019-12'].sum(axis=0).value_counts())\n",
        "\n",
        "# # y de esos 111, 98 tampoco compraron en Octubre\n",
        "# print(presencia_clientes.loc['2019-10':'2019-12'].sum(axis=0).value_counts())\n",
        "\n",
        "# Concluimos que los 111 clientes que no nos compraron en Octibre, Noviembre ni Diciembre\n",
        "# no son mas nuestros clietnes, y damos de baja sus ventas, ya que es muy probable\n",
        "# que no nos vuelvan a comprar, aunque si un porcentje sera absosrvido por la competencia\n",
        "\n",
        "\n",
        "# print(mask_active_clients.shape)\n",
        "# display(mask_active_clients.head())"
      ],
      "metadata": {
        "id": "P0D6gjK_54l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ####################################################################################################################\n",
        "# # 2024-06-07: Excluyo las ventas de los clientes marcados como desactivados\n",
        "# # Ventas de clientes que no compraron en los ultimos dos meses, eliminadas\n",
        "# active_data = data[data['customer_id'].isin(mask_active_clients[mask_active_clients].index)]\n",
        "\n",
        "# # Pivotear los datos\n",
        "# data_grouped_active_clients = active_data.pivot_table(\n",
        "#     index='periodo',\n",
        "#     columns='product_id',\n",
        "#     values='tn',\n",
        "#     aggfunc='sum'\n",
        "# )\n",
        "\n",
        "# # Asegurarnos de que el índice esté en el formato correcto\n",
        "# data_grouped_active_clients.index = pd.to_datetime(data_grouped_active_clients.index)\n",
        "\n",
        "# # Ordenar el índice si fuera necesario\n",
        "# data_grouped_active_clients = data_grouped_active_clients.sort_index()\n",
        "# ####################################################################################################################\n",
        "# # Si quiero usar el Dataset con las ventas de los clientes desactivados excluidas\n",
        "# # Y trasca le completo los nulos\n",
        "# data_grouped = fill_nulls(data_grouped_active_clients)\n",
        "\n",
        "# # Relacion entre el promedio anual anterior, y el febrero siguiente\n",
        "# data_2017_mean = pd.Series(data_grouped.loc['2017'].mean(axis=0), name='2017_mean')\n",
        "# data_2018_mean = pd.Series(data_grouped.loc['2018'].mean(axis=0), name='2018_mean')\n",
        "# data_2019_mean = pd.Series(data_grouped.loc['2019'].mean(axis=0), name='2019_mean')\n",
        "# feb_2018 = pd.Series(data_grouped.loc['2018-02'].T.squeeze(), name='Feb_2018')\n",
        "# feb_2019 = pd.Series(data_grouped.loc['2019-02'].T.squeeze(), name='Feb_2019')\n",
        "\n",
        "# data = pd.concat([data_2017_mean, feb_2018, data_2018_mean, feb_2019, data_2019_mean], axis=1)\n",
        "\n",
        "# # display(data.head())\n",
        "\n",
        "# # Calculamos cuanto represetan las ventas de Febrero, con respecto al Mean de todo el ano anterior\n",
        "# ratio_2017 = pd.Series(data['Feb_2018'] / data['2017_mean'], name='Ratio_2017')\n",
        "# ratio_2018 = pd.Series(data['Feb_2019'] / data['2018_mean'], name='Ratio_2018')\n",
        "# data_ratios = pd.concat([ratio_2017, ratio_2018], axis=1)\n",
        "\n",
        "# # Nos enfocamos solo en los primeros 40 productos, los mas importantes\n",
        "# data_ratios[:40].plot(figsize=(25, 6))\n",
        "# plt.show()\n",
        "\n",
        "# # display(data_ratios.head())\n",
        "# # Vemos el huevo del producto #32, ya que no tenemos ventas todos los meses\n",
        "# # Vemos como son bastantes parecidas\n",
        "# # Se ve que el producto 19 fue suplementado por el 22 en las ventas del 2018\n",
        "\n",
        "\n",
        "# # Si el ratio del producto vendido entre el promedo del Ano y Febrero del ano siguiente es menor al 3%, sigue manteniendo ese ratio\n",
        "# data_ratios['diff3'] = (abs(data_ratios['Ratio_2017'] - data_ratios['Ratio_2018']) <= 0.03)\n",
        "# data_final = pd.concat([data_ratios, data_2019_mean], axis=1)\n",
        "\n",
        "# # Inflation Multiplier, dejar en 1 para que no modifique las predicciones\n",
        "# inflation = .92\n",
        "# data_final['tn'] = data_final.apply(lambda row: row['2019_mean'] * row['Ratio_2018'] * inflation if row['diff3'] else row['2019_mean'], axis=1)\n",
        "\n",
        "# # display(data_final.head())\n",
        "\n",
        "# # Formateo y exporto a Kaggle.\n",
        "# to_kaggle(data_final['tn'].reset_index(), name='modelo_loco_3diff_inlf92_active3')\n",
        "\n",
        "# # Guardo los productos que tengo que mejorar, los que los ratio de ventas con Febrero sobrepasan el 3%\n",
        "# mask_mejorar = ~ data_final['diff3']\n",
        "# ####################################################################################################################\n",
        "# # Comentar esta linea para que no se excluyan los clientes desactivados\n",
        "# data_grouped = data_grouped_active_clients\n",
        "\n",
        "# # Igual que Diciembre 2020 (ultimos datos)\n",
        "# pred_202012 = data_grouped.loc['2019-12'].T.reset_index()\n",
        "# pred_202012.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_202012.to_csv('BASELINE-pred_202012.csv', header=True, index=False)\n",
        "\n",
        "# # Promedio ultimos 3 meses\n",
        "# pred_mean3 = data_grouped.loc['2019-10':'2019-12'].T.mean(axis=1).reset_index()\n",
        "# pred_mean3.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_mean3.to_csv('BASELINE-pred_mean3.csv', header=True, index=False)\n",
        "\n",
        "# # Promedio ultimos 6 meses\n",
        "# pred_mean6 = data_grouped.loc['2019-07':'2019-12'].T.mean(axis=1).reset_index()\n",
        "# pred_mean6.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_mean6.to_csv('BASELINE-pred_mean6.csv', header=True, index=False)\n",
        "\n",
        "# # Promedio ultimos 12 meses\n",
        "# pred_mean12 = data_grouped.loc['2019-01':'2019-12'].T.mean(axis=1).reset_index()\n",
        "# pred_mean12.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_mean12.to_csv('BASELINE-pred_mean12_act3.csv', header=True, index=False)\n",
        "# pred_mean12"
      ],
      "metadata": {
        "id": "Zg8foW6XMcMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/17 - Concatenamos Estadistica con Redes Neuronales"
      ],
      "metadata": {
        "id": "-sB43EDztBui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # De la noebook anterior\n",
        "\n",
        "# # Relacion entre el promedio anual anterior, y el febrero siguiente\n",
        "# data_2017_mean = pd.Series(data_grouped.loc['2017'].mean(axis=0), name='2017_mean')\n",
        "# data_2018_mean = pd.Series(data_grouped.loc['2018'].mean(axis=0), name='2018_mean')\n",
        "# data_2019_mean = pd.Series(data_grouped.loc['2019'].mean(axis=0), name='2019_mean')\n",
        "# feb_2018 = pd.Series(data_grouped.loc['2018-02'].T.squeeze(), name='Feb_2018')\n",
        "# feb_2019 = pd.Series(data_grouped.loc['2019-02'].T.squeeze(), name='Feb_2019')\n",
        "\n",
        "# data = pd.concat([data_2017_mean, feb_2018, data_2018_mean, feb_2019, data_2019_mean], axis=1)\n",
        "\n",
        "# # display(data.head())\n",
        "\n",
        "# # Calculamos cuanto represetan las ventas de Febrero, con respecto al Mean de todo el ano anterior\n",
        "# ratio_2017 = pd.Series(data['Feb_2018'] / data['2017_mean'], name='Ratio_2017')\n",
        "# ratio_2018 = pd.Series(data['Feb_2019'] / data['2018_mean'], name='Ratio_2018')\n",
        "# data_ratios = pd.concat([ratio_2017, ratio_2018], axis=1)\n",
        "\n",
        "# # # Nos enfocamos solo en los primeros 40 productos, los mas importantes\n",
        "# # data_ratios[:40].plot(figsize=(25, 6))\n",
        "# # plt.show()\n",
        "\n",
        "# # display(data_ratios.head())\n",
        "# # Vemos el huevo del producto #32, ya que no tenemos ventas todos los meses\n",
        "# # Vemos como son bastantes parecidas\n",
        "# # Se ve que el producto 19 fue suplementado por el 22 en las ventas del 2018\n",
        "\n",
        "\n",
        "# # Si el ratio del producto vendido entre el promedo del Ano y Febrero del ano siguiente es menor al 3%, sigue manteniendo ese ratio\n",
        "# data_ratios['diff3'] = (abs(data_ratios['Ratio_2017'] - data_ratios['Ratio_2018']) <= 0.03)\n",
        "# data_final = pd.concat([data_ratios, data_2019_mean], axis=1)\n",
        "\n",
        "# # Inflation Multiplier, dejar en 1 para que no modifique las predicciones\n",
        "# inflation = 0.90\n",
        "# data_final['tn'] = data_final.apply(lambda row: row['2019_mean'] * row['Ratio_2018'] * inflation if row['diff3'] else row['2019_mean'], axis=1)\n",
        "\n",
        "# # display(data_final.head())\n",
        "\n",
        "# # # Formateo y exporto a Kaggle.\n",
        "# # to_kaggle(data_final['tn'].reset_index(), name='modelo_loco_3diff_inlf90')\n",
        "\n",
        "# # Guardo los productos que tengo que mejorar, los que los ratio de ventas con Febrero sobrepasan el 3%\n",
        "# mask_mejorar = ~ data_final['diff3']"
      ],
      "metadata": {
        "id": "cL2qjeKy481y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Predecimos las ventas de productos que no fueron buenos usando la estadistica clasica\n",
        "\n",
        "# #########################################################################################\n",
        "# # # Viene de otro EDA, si da error hay que ejecutar ese analisis primero que genera esta variable\n",
        "# # mask_mejorar = ~ data_final['diff3']\n",
        "\n",
        "# products_list = mask_mejorar[mask_mejorar == True].index\n",
        "\n",
        "# # Probamos con los datos de los clientes activos only\n",
        "# data_grouped_filled = fill_nulls(data_grouped_active_clients)\n",
        "\n",
        "# # Probamos reemplazando la crisis de Agosto 2019 por Julio + 10% (visto en el EDA)\n",
        "# data_grouped_filled.drop(index='2019-08', axis=1, inplace=True)\n",
        "# data_agosto_2019_jul_plus10 = data_grouped_filled.loc['2019-07']*1.1\n",
        "# data_agosto_2019_jul_plus10.index = pd.to_datetime(['2019-08-01'])\n",
        "# data_grouped_filled = pd.concat([data_grouped_filled, data_agosto_2019_jul_plus10]).sort_index()\n",
        "# #########################################################################################\n",
        "\n",
        "# # Inicializamos el vector de predicciones\n",
        "# vector_predictions = data_productos_a_predecir.copy()\n",
        "# vector_predictions['tn'] =0\n",
        "# # vector_predictions = vector_predictions.squeeze()\n",
        "\n",
        "# for product in products_list[:50]:\n",
        "#   print(product)\n",
        "\n",
        "#   # Modificar el valor del filtro, para analizar otros Productos. Ojo que hay productos que no tenemos todos los anos y pincha\n",
        "#   data_product = data_grouped[product]\n",
        "\n",
        "#   # Jugamos con esto aca, para ver el tema de la validacion en el entrenamiento\n",
        "#   window_size = 12\n",
        "#   batch_size = 1\n",
        "\n",
        "\n",
        "#   data_train, data_valid = split_data(data_product, window_size)\n",
        "#   data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "#   # print(data_train.index)\n",
        "#   # print(data_valid.index)\n",
        "#   data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#   data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "#   # Model Variables\n",
        "#   model_name = 'xx'\n",
        "#   loss = 'mse'\n",
        "#   optimizer = 'adam'\n",
        "#   patience = 30\n",
        "#   epochs = 300\n",
        "#   n_features = data_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "#   callbacks = MyCallbacks(patience)\n",
        "#   model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#   history = model.fit(\n",
        "#       data_train_windowed,\n",
        "#       validation_data = data_valid_windowed,\n",
        "#       callbacks = callbacks,\n",
        "#       verbose=0,\n",
        "#       epochs=epochs)\n",
        "\n",
        "#   # plot_history(history)\n",
        "\n",
        "#   predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "#   # plot_predictions_dec2019(data_product, predictions)\n",
        "\n",
        "#   # Vamos sumando en el vector de acum\n",
        "#   value_to_add = predictions.loc['2020-02'].values[0]\n",
        "#   vector_predictions.loc[predictions.name]+= value_to_add\n",
        "\n",
        "# vector_predictions.to_csv('predicciones_win12.csv')"
      ],
      "metadata": {
        "id": "xPSg0lhQtM6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/17 - Errores contra Diciembre 2019 (WIP)"
      ],
      "metadata": {
        "id": "70vs0Lkdlgsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Analizamos las series de los productos mas vendidos, pero esta vez testeamos contra los ultimos dos meses del dataset Nov y Dev 2019\n",
        "\n",
        "# # # Inicializamos el vector de predicciones\n",
        "# # vector_predictions = data_productos_a_predecir.copy()\n",
        "# # vector_predictions['tn'] =0\n",
        "\n",
        "\n",
        "# # Modificar el valor del filtro, para analizar otros Productos. Ojo que hay productos que no tenemos todos los anos y pincha\n",
        "# data_product = data_grouped['20003']\n",
        "\n",
        "# # Jugamos con esto aca, para ver el tema de la validacion en el entrenamiento\n",
        "# window_size = 6\n",
        "# batch_size = 1\n",
        "\n",
        "\n",
        "# data_train, data_valid = split_data_dec2019(data_product, window_size)\n",
        "# data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "# # print(data_train.index)\n",
        "# # print(data_valid.index)\n",
        "# data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'xx'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 300\n",
        "# n_features = data_train.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data = data_valid_windowed,\n",
        "#     callbacks = callbacks,\n",
        "#     verbose=1,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# plot_history(history)\n",
        "\n",
        "# predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "# # plot_predictions_dec2019(data_product, predictions)\n",
        "# display(predictions)"
      ],
      "metadata": {
        "id": "ENuMHEl_nL-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/17 - Ratio Febrero con Promedio de anos anteriores"
      ],
      "metadata": {
        "id": "_a6ldKf-vb-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Si quiero usar el Dataset con las ventas de los clientes desactivados excluidas\n",
        "# # Y trasca le completo los nulos\n",
        "# data_grouped = fill_nulls(data_grouped_active_clients)\n",
        "\n",
        "# # Relacion entre el promedio anual anterior, y el febrero siguiente\n",
        "# data_2017_mean = pd.Series(data_grouped.loc['2017'].mean(axis=0), name='2017_mean')\n",
        "# data_2018_mean = pd.Series(data_grouped.loc['2018'].mean(axis=0), name='2018_mean')\n",
        "# data_2019_mean = pd.Series(data_grouped.loc['2019'].mean(axis=0), name='2019_mean')\n",
        "# feb_2018 = pd.Series(data_grouped.loc['2018-02'].T.squeeze(), name='Feb_2018')\n",
        "# feb_2019 = pd.Series(data_grouped.loc['2019-02'].T.squeeze(), name='Feb_2019')\n",
        "\n",
        "# data = pd.concat([data_2017_mean, feb_2018, data_2018_mean, feb_2019, data_2019_mean], axis=1)\n",
        "\n",
        "# # display(data.head())\n",
        "\n",
        "# # Calculamos cuanto represetan las ventas de Febrero, con respecto al Mean de todo el ano anterior\n",
        "# ratio_2017 = pd.Series(data['Feb_2018'] / data['2017_mean'], name='Ratio_2017')\n",
        "# ratio_2018 = pd.Series(data['Feb_2019'] / data['2018_mean'], name='Ratio_2018')\n",
        "# data_ratios = pd.concat([ratio_2017, ratio_2018], axis=1)\n",
        "\n",
        "# # Nos enfocamos solo en los primeros 40 productos, los mas importantes\n",
        "# data_ratios[:40].plot(figsize=(25, 6))\n",
        "# plt.show()\n",
        "\n",
        "# # display(data_ratios.head())\n",
        "# # Vemos el huevo del producto #32, ya que no tenemos ventas todos los meses\n",
        "# # Vemos como son bastantes parecidas\n",
        "# # Se ve que el producto 19 fue suplementado por el 22 en las ventas del 2018\n",
        "\n",
        "\n",
        "# # Si el ratio del producto vendido entre el promedo del Ano y Febrero del ano siguiente es menor al 3%, sigue manteniendo ese ratio\n",
        "# data_ratios['diff3'] = (abs(data_ratios['Ratio_2017'] - data_ratios['Ratio_2018']) <= 0.03)\n",
        "# data_final = pd.concat([data_ratios, data_2019_mean], axis=1)\n",
        "\n",
        "# # Inflation Multiplier, dejar en 1 para que no modifique las predicciones\n",
        "# inflation = .92\n",
        "# data_final['tn'] = data_final.apply(lambda row: row['2019_mean'] * row['Ratio_2018'] * inflation if row['diff3'] else row['2019_mean'], axis=1)\n",
        "\n",
        "# # display(data_final.head())\n",
        "\n",
        "# # Formateo y exporto a Kaggle.\n",
        "# to_kaggle(data_final['tn'].reset_index(), name='modelo_loco_3diff_inlf92_active3')\n",
        "\n",
        "# # Guardo los productos que tengo que mejorar, los que los ratio de ventas con Febrero sobrepasan el 3%\n",
        "# mask_mejorar = ~ data_final['diff3']"
      ],
      "metadata": {
        "id": "dcF-bI-2vgIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/17 - Error Analysis: Predicciones contra Diciembre 2019"
      ],
      "metadata": {
        "id": "pc4pDaocEdhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/16 - Error Analysis"
      ],
      "metadata": {
        "id": "GiO91wV2MWuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Analizamos las series de los productos mas vendidos, vemos si las redes neuronales pueden entenderlas\n",
        "\n",
        "# # Modificar el valor del filtro, para analizar otros Productos. Ojo que hay productos que no tenemos todos los anos y pincha\n",
        "# data_product = data_grouped['20024']\n",
        "\n",
        "\n",
        "# data_train, data_valid = split_data_test(data_product)\n",
        "# data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "# data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'xx'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 20\n",
        "# epochs = 200\n",
        "# n_features = data_train.shape[1]\n",
        "\n",
        "\n",
        "# # Jugamos con esto aca, para ver el tema de la validacion en el entrenamiento\n",
        "# window_size = 3\n",
        "# batch_size = 1\n",
        "\n",
        "\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data = data_valid_windowed,\n",
        "#     callbacks = callbacks,\n",
        "#     verbose=2,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# plot_history(history)\n",
        "\n",
        "# predictions = generate_predictions_2(model, data_valid_norm, norm_params)\n",
        "# plot_predictions(data_product, predictions)"
      ],
      "metadata": {
        "id": "2Fr3EDZnMbQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/15 - BASELINE + TOP Productos"
      ],
      "metadata": {
        "id": "Waoyxx3TzKh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # PARA LOCAL ONLY, DEMORA MUCHO\n",
        "\n",
        "# #############################################################################################\n",
        "# #############################################################################################\n",
        "#  # El EDA tiene que estar arriba\n",
        "# mask_product_id_sold36 = (data_grouped > 0).sum(axis=0)==36\n",
        "# # print('Productos vendidos los 36 meses:', mask_product_id_sold36.sum())\n",
        "# # mask_product_id_sold12 = (data_grouped > 0).sum(axis=0)<=12\n",
        "# # print('Productos vendidos en 12 meses o menos:', mask_product_id_sold12.sum())\n",
        "\n",
        "# # Marco los que se vendieron los 36 meses\n",
        "# mask_products_id_top74 = mask_product_id_sold36\n",
        "\n",
        "# # No me interesan los +75\n",
        "# mask_products_id_top74.loc['20085':] = False\n",
        "# mask_products_id_top74.sum()\n",
        "# #############################################################################################\n",
        "# #############################################################################################\n",
        "# top_productos = data_productos_a_predecir[mask_products_id_top74].index\n",
        "\n",
        "# # # Prueba con los dos primeros\n",
        "# # top_productos = top_productos[:2]\n",
        "\n",
        "\n",
        "# # # Continuacion a mano desde producto 20017\n",
        "# # mask_17 = mask_products_id_top74.loc['20017':]\n",
        "# # data_17 = data_productos_a_predecir.loc['20017':]\n",
        "# # data_17[mask_17]\n",
        "# # top_productos = data_17[mask_17].index\n",
        "\n",
        "# data_prod_pred = data_productos_a_predecir.copy()\n",
        "# data_prod_pred['mean'] = 0\n",
        "# data_prod_pred['median'] = 0\n",
        "\n",
        "# for producto in top_productos:\n",
        "#   # print(f'Producto: {producto}')\n",
        "#   data_grouped_loc = group_data(data, 'product_id')[producto]\n",
        "#   # display(data_grouped_loc)\n",
        "\n",
        "#   data_train, data_valid = split_data(data_grouped_loc)\n",
        "#   data_train = pd.DataFrame(data_train)\n",
        "#   data_valid = pd.DataFrame(data_valid)\n",
        "#   # display(data_train.head())\n",
        "\n",
        "#   data_train_norm, data_valid_norm, norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "#   # display(data_valid_norm.head())\n",
        "\n",
        "#   data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#   data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "#   # Model Variables\n",
        "#   model_name = 'M1'\n",
        "#   loss = 'mse'\n",
        "#   optimizer = 'adam'\n",
        "#   patience = 20\n",
        "#   epochs = 100\n",
        "#   interaciones = 10\n",
        "#   n_features = data_train.shape[1]\n",
        "#   # print(n_features)\n",
        "\n",
        "\n",
        "#   callbacks = MyCallbacks(patience)\n",
        "#   model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#   # Promedio 810\n",
        "#   mean, median = model_train(epochs, interaciones)\n",
        "#   data_prod_pred.loc[producto, ['mean', 'median']] = mean, median\n",
        "\n",
        "# # data_prod_pred.to_csv('predicciones_top74.csv', header=True, index=True)"
      ],
      "metadata": {
        "id": "Rce7LpdHi__X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/15 - Nuevos BASELINES"
      ],
      "metadata": {
        "id": "J6t7e7l9bEeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ####################################################################################################################\n",
        "# # 2024-06-07: Excluyo las ventas de los clientes marcados como desactivados\n",
        "# # Ventas de clientes que no compraron en los ultimos dos meses, eliminadas\n",
        "# active_data = data[data['customer_id'].isin(mask_active_clients[mask_active_clients].index)]\n",
        "\n",
        "# # Pivotear los datos\n",
        "# data_grouped_active_clients = active_data.pivot_table(\n",
        "#     index='periodo',\n",
        "#     columns='product_id',\n",
        "#     values='tn',\n",
        "#     aggfunc='sum'\n",
        "# )\n",
        "\n",
        "# # Asegurarnos de que el índice esté en el formato correcto\n",
        "# data_grouped_active_clients.index = pd.to_datetime(data_grouped_active_clients.index)\n",
        "\n",
        "# # Ordenar el índice si fuera necesario\n",
        "# data_grouped_active_clients = data_grouped_active_clients.sort_index()\n",
        "# ####################################################################################################################\n",
        "\n",
        "# # Comentar esta linea para que no se excluyan los clientes desactivados\n",
        "# data_grouped = data_grouped_active_clients\n",
        "\n",
        "# # Igual que Diciembre 2020 (ultimos datos)\n",
        "# pred_202012 = data_grouped.loc['2019-12'].T.reset_index()\n",
        "# pred_202012.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_202012.to_csv('BASELINE-pred_202012.csv', header=True, index=False)\n",
        "\n",
        "# # Promedio ultimos 3 meses\n",
        "# pred_mean3 = data_grouped.loc['2019-10':'2019-12'].T.mean(axis=1).reset_index()\n",
        "# pred_mean3.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_mean3.to_csv('BASELINE-pred_mean3.csv', header=True, index=False)\n",
        "\n",
        "# # Promedio ultimos 6 meses\n",
        "# pred_mean6 = data_grouped.loc['2019-07':'2019-12'].T.mean(axis=1).reset_index()\n",
        "# pred_mean6.columns = ['product_id', 'tn']\n",
        "\n",
        "# # pred_mean6.to_csv('BASELINE-pred_mean6.csv', header=True, index=False)\n",
        "\n",
        "# # Promedio ultimos 12 meses\n",
        "# pred_mean12 = data_grouped.loc['2019-01':'2019-12'].T.mean(axis=1).reset_index()\n",
        "# pred_mean12.columns = ['product_id', 'tn']\n",
        "\n",
        "# pred_mean12.to_csv('BASELINE-pred_mean12_act4.csv', header=True, index=False)\n"
      ],
      "metadata": {
        "id": "Sy0QnKMklwzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/12 - Walk Forward Validation\n",
        "- Son muy pocos datos los que tenemos, no funciona bien"
      ],
      "metadata": {
        "id": "PCQSAqstQinS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # # #########################################################################\n",
        "# # # # TimeSeriesSplit\n",
        "# # # # #########################################################################\n",
        "\n",
        "# # TimeSeriesSplit: 3 splits para ejemplo\n",
        "# tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# # Almacenar las pérdidas para cada split\n",
        "# split_losses = []\n",
        "\n",
        "# # Inicializo el vector de predicciones\n",
        "# predicciones_all = data_productos_a_predecir.copy()\n",
        "# predicciones_all['tn'] = 0\n",
        "\n",
        "# # Probar si esto se puede sacar del bucle\n",
        "# model_name = 'M1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "\n",
        "# # Iterar sobre cada split\n",
        "# for i, (train_index, test_index) in enumerate(tscv.split(data_norm)):\n",
        "#     train_tscv = data_norm.iloc[train_index]\n",
        "#     test_tscv = data_norm.iloc[test_index]\n",
        "#     print('Train:\\n', train_tscv.shape[0])\n",
        "#     print('Test:\\n', test_tscv.shape[0])\n",
        "\n",
        "\n",
        "#     # Crear datasets de ventanas\n",
        "#     data_train_wrangled = windowed_dataset(train_tscv.values, 'train', window_size, horizon, batch_size)\n",
        "#     data_valid_wrangled = windowed_dataset(test_tscv.values, 'valid', window_size, horizon, batch_size)\n",
        "\n",
        "#     # Check if datasets are empty and adjust if necessary\n",
        "#     if len(list(data_train_wrangled)) == 0 or len(list(data_valid_wrangled)) == 0:\n",
        "#       print(f\"Warning: Empty dataset encountered for split {i+1}. Skipping this split.\")\n",
        "#       continue  # Skip to the next split\n",
        "\n",
        "#     history = model.fit(\n",
        "#     data_train_wrangled,\n",
        "#     validation_data = data_valid_wrangled,\n",
        "#     epochs=epochs,\n",
        "#     verbose=2,\n",
        "#     callbacks = callbacks)\n",
        "\n",
        "#     # Evaluar el modelo en el conjunto de validación\n",
        "#     val_loss = model.evaluate(data_valid_wrangled)\n",
        "#     print(f'Split {i+1} - Loss: {val_loss}')\n",
        "#     split_losses.append(val_loss)\n",
        "#     plot_history(history)\n",
        "\n",
        "#     predicciones_all = sumar_predicciones(predicciones_all, generate_predictions(False))\n",
        "\n",
        "\n",
        "# # Promedio de las pérdidas en todos los splits. El axis es por si analizamos mas de una metrica\n",
        "# avg_loss = np.mean(split_losses, axis=0)\n",
        "# print(f'Average Loss across all splits: {avg_loss}')\n",
        "\n",
        "# # Promedio las predicciones\n",
        "# predicciones_final = data_productos_a_predecir.copy()\n",
        "# predicciones_final['tn'] = predicciones_all['tn']/n_splits\n",
        "\n",
        "# # Exporto el CSV para Kaggle\n",
        "# filename = f\"{split_strategy}_{model_name}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "# predicciones_final.to_csv(filename, header=True, index=False)\n",
        "# print(filename)"
      ],
      "metadata": {
        "id": "LA0pXJB_7OD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/11 - Agrupando por Categoria 1"
      ],
      "metadata": {
        "id": "Mj0hs54Uc8_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Inicializo el vector de predicciones\n",
        "# predictions_acum = data_productos_a_predecir.copy()\n",
        "# predictions_acum['tn'] = 0\n",
        "# # predictions_acum.set_index('product_id', inplace=True)\n",
        "# predictions_acum = predictions_acum.squeeze()\n",
        "# predictions_acum\n",
        "\n",
        "# # Genero el vector de categorias\n",
        "# categorias = data_productos_a_predecir_con_categorias.cat1.unique()\n",
        "\n",
        "# # Creo un modelo para cada categoria 1\n",
        "# for cat in categorias:\n",
        "#   data_cat1 = filter_data_por_categoria(data_grouped, cat, 'cat1')\n",
        "#   n_features = data_cat1.shape[1]\n",
        "#   # display(data_cat1)\n",
        "#   data_train_cat1, data_valid_cat1 = split_data(data_cat1)\n",
        "#   print(f'Categoria {cat}: {data_train_cat1.shape}, {data_valid_cat1.shape}')\n",
        "#   data_train_cat1_norm, data_valid_cat1_norm, data_norm_params = normalize_data(data_train_cat1, data_valid_cat1, normalization)\n",
        "#   data_train_windowed = windowed_dataset(data_train_cat1_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#   data_valid_windowed = windowed_dataset(data_train_cat1, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "#   # Creo que tengo que llenar los huecos\n",
        "\n",
        "#   # Model Variables\n",
        "#   model_name = 'CAT1'\n",
        "#   loss = 'mse'\n",
        "#   optimizer = 'adam'\n",
        "#   patience = 50\n",
        "#   epochs = 500\n",
        "#   callbacks = MyCallbacks(patience)\n",
        "#   model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#   history = model.fit(\n",
        "#       data_train_windowed,\n",
        "#       validation_data = data_valid_windowed,\n",
        "#       callbacks = callbacks,\n",
        "#       verbose=0,\n",
        "#       epochs=epochs)\n",
        "\n",
        "#   plot_history(history)\n",
        "\n",
        "# #   # Seleccionar los últimos x meses de data_train\n",
        "# #   data_for_prediction = data_train_cat1[-window_size:]\n",
        "# #   # Convierte los datos a un formato compatible con la función window_dataset\n",
        "# #   data_for_prediction = data_for_prediction.values.reshape((1, window_size, n_features))\n",
        "# #   predictions = model.predict(data_for_prediction)\n",
        "\n",
        "# #   # # Convertir las predicciones a un DataFrame para desnormalizar\n",
        "# #   predictions_df = pd.DataFrame(predictions[0], columns=data_train_cat1.columns)\n",
        "\n",
        "# #   # # Desnormalizar las predicciones\n",
        "# #   predictions_denorm_cat1 = denormalize_series(predictions_df, data_norm_params, normalization=normalization).iloc[1]\n",
        "\n",
        "# #   # Voy sumando las predicciones de cada categoria\n",
        "# #   predictions_acum = predictions_acum.add(predictions_denorm_cat1, fill_value=0)\n",
        "\n",
        "# # # Exporto a formato Kaggle\n",
        "# # predictions_acum_df = pd.DataFrame(predictions_acum).reset_index()\n",
        "# # predictions_acum_df.columns = ['product_id', 'tn']\n",
        "# # filename = f\"{model_name}_{split_strategy}_win{window_size}_batch{batch_size}_{normalization}_{loss}.csv\"\n",
        "# # predictions_acum_df.to_csv(filename, header=True, index=False)\n",
        "# # print(filename)"
      ],
      "metadata": {
        "id": "4i5vHk16uOl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/11 - Analisis del Error por Producto"
      ],
      "metadata": {
        "id": "OisFvYA0feHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # # NO FUNCIONA\n",
        "# # # # # # #########################################################################\n",
        "# # # # # # Train hasta 2019-10, para predecir 2019-12\n",
        "# # # # # # #########################################################################\n",
        "# split_data_2019\n",
        "# data_filled = fill_nulls(data_grouped)\n",
        "# data_train, data_valid, data_test = split_data_2019(data_filled)\n",
        "# data_train = pd.DataFrame(data_train)\n",
        "# data_valid = pd.DataFrame(data_valid)\n",
        "# data_test = pd.DataFrame(data_test)\n",
        "# print(data_train.shape, data_valid.shape, data_test.shape)\n",
        "\n",
        "\n",
        "# data_train_norm, data_valid_norm, data_norm_params = normalize_data(data_train, data_valid, normalization)\n",
        "# data_train_windowed = windowed_dataset(data_train_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# data_valid_windowed = windowed_dataset(data_valid_norm, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size,)\n",
        "# display(data_test)\n",
        "\n",
        "# # Al hacer el split disitnto, hay que modificar esto sino me voy de rango creando las window\n",
        "# # split_strategy = 'S1'\n",
        "# # window_size = 3\n",
        "# # horizon = 2\n",
        "# # batch_size = 1\n",
        "# # normalization = 'MinMax'\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'ErrorAnalysis'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 20\n",
        "# epochs = 200\n",
        "# n_features = data_train.shape[1]\n",
        "\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data = data_valid_windowed,\n",
        "#     callbacks = callbacks,\n",
        "#     verbose=2,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# plot_history(history)\n",
        "\n",
        "# # # No sirve para este caso, esta hardcodeada a Febrero 2020. Tengo que actualizar esta funcion\n",
        "# # # generate_predictions(data_norm, data_norm_params)\n",
        "\n",
        "# # # Seleccionar los últimos x meses de data_train\n",
        "# # data_for_prediction = data_train[-window_size:]\n",
        "# # # Convierte los datos a un formato compatible con la función window_dataset\n",
        "# # data_for_prediction = data_for_prediction.values.reshape((1, window_size, n_features))\n",
        "# # predictions = model.predict(data_for_prediction)\n",
        "\n",
        "# # # Convertir las predicciones a un DataFrame para desnormalizar\n",
        "# # predictions_df = pd.DataFrame(predictions[0], columns=data_train.columns)\n",
        "\n",
        "# # # Desnormalizar las predicciones\n",
        "# # predictions_denorm = denormalize_series(predictions_df, data_norm_params, normalization=normalization)\n",
        "\n",
        "# # # Imprimir las predicciones desnormalizadas\n",
        "# # # display(predictions_denorm)\n",
        "\n",
        "\n",
        "# # # Genero las Series para plotear el error entre predicho y real. Armo un Dataframe\n",
        "# # data_dec2019_pred = pd.Series(predictions_denorm.iloc[1], name='Pred')\n",
        "# # data_dec2019_true = pd.Series(data_grouped.fillna(0).loc['2019-12-01'], name='True')\n",
        "# # data_dec2019_error = pd.concat([data_dec2019_pred, data_dec2019_true], axis=1)\n",
        "\n",
        "# # # Clusterizo por Categorias 1 y 2 de productos\n",
        "# # data_productos_indexed = data_productos.drop_duplicates('product_id').set_index('product_id').sort_index()\n",
        "# # data_dec2019_error_detail = data_dec2019_error.join(data_productos_indexed[['cat1', 'cat2', 'cat3']])\n",
        "\n",
        "# # # Ploteo los Errores, con sus clusters\n",
        "# # sns.scatterplot(data=data_dec2019_error_detail, x='Pred', y='True', hue='cat1')\n",
        "# # plt.axline((0, 0), slope=1, color='r', linestyle='--')\n",
        "# # plt.show()\n",
        "\n",
        "# # # Verificamos que Categoria es la que engloba mas productos\n",
        "# # print(data_productos['cat1'].value_counts())\n",
        "\n",
        "# # # Productos con mayores diferencias en la prediccion\n",
        "# # predictions_worst10 = abs(data_dec2019_pred - data_dec2019_true).sort_values(ascending=False).head(10)\n",
        "# # display(pd.DataFrame(predictions_worst10).join(data_productos[['product_id', 'cat1']].set_index('product_id').sort_index()).rename(columns={0: 'tn_diff'}).sort_values(by='tn_diff', ascending=False))\n",
        "\n",
        "# # # Ploteamos el error en las predicciones acumulaod por Categoria\n",
        "# # pd.DataFrame(abs(data_dec2019_pred - data_dec2019_true).sort_values(ascending=False)).join(data_productos[['product_id', 'cat1']].set_index('product_id').sort_index()).rename(columns={0: 'tn_diff'}).groupby('cat1').sum().sort_values(by='tn_diff', ascending=False).plot(kind='bar')\n",
        "# # plt.title('Diferencia en toneladas por Categoria')\n",
        "# # plt.show()"
      ],
      "metadata": {
        "id": "8tw6MlALfgrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Vemos claramente como estsamos prediciendo mal los productos de Health Care, mas que nada los que predice entre 350 y 600, esta prediciendo bastante de menos."
      ],
      "metadata": {
        "id": "7hM59Wm47VGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/10 - Cada cliente por separado"
      ],
      "metadata": {
        "id": "fPq4wBabw7gE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Esto lo corro en mi maquina local, en Colab se cuelga antes de terminar con los casi 600 clientes\n",
        "\n",
        "# # Inicializo el vector de predicciones\n",
        "# predicciones_all = data_productos_a_predecir.copy()\n",
        "# predicciones_all['tn'] = 0\n",
        "\n",
        "# # Probamos solo con los 3 primeros clientes\n",
        "# # customers = data['customer_id'].unique()\n",
        "# customers = ['10001', '10002', '10003']\n",
        "# customers.sort()\n",
        "\n",
        "# i = 0\n",
        "\n",
        "# for customer in customers:\n",
        "#   print('Vuelta: ', i)\n",
        "#   i += 1\n",
        "#   data_customer = data_filter.query('customer_id == @customer')\n",
        "#   data_customer_grouped = group_data(data_customer, 'product_id')\n",
        "#   data_customer_grouped_fixed = complete_sales(data_customer_grouped, data_productos_a_predecir)\n",
        "#   # display(data_customer_grouped_fixed)\n",
        "#   data_customer_filled = fill_nulls(data_customer_grouped_fixed) # Probar cual funciona mejor\n",
        "\n",
        "#     # Probamos reemplazando la crisis de Agosto 2019 por el promedio en Julio y Septiembre. Maybe no funciona\n",
        "#   data_customer_filled.drop(index='2019-08', axis=1, inplace=True)\n",
        "#   data_agosto_2019 = data_customer_filled.loc[['2019-07', '2019-09']].mean().to_frame().transpose()\n",
        "#   data_agosto_2019.index = pd.to_datetime(['2019-08-01'])\n",
        "#   data_customer_filled = pd.concat([data_customer_filled, data_agosto_2019]).sort_index()\n",
        "\n",
        "#   data_customer_norm, data_customer_norm_params = normalize_data(data_customer_filled, normalization=normalization)\n",
        "#   data_customer_norm_train, data_customer_norm_valid = split_data(data_customer_norm)\n",
        "#   data_train_windowed = windowed_dataset(data_customer_norm_train, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "#   data_valid_windowed = windowed_dataset(data_customer_norm_valid, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "#   # Model Variables\n",
        "#   model_name = 'M1'\n",
        "#   loss = 'mse'\n",
        "#   optimizer = 'adam'\n",
        "#   patience = 30\n",
        "#   epochs = 500\n",
        "#   callbacks = MyCallbacks(patience)\n",
        "#   model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "#   history = model.fit(\n",
        "#       data_train_windowed,\n",
        "#       validation_data = data_valid_windowed,\n",
        "#       callbacks = callbacks,\n",
        "#       verbose=0,\n",
        "#       epochs=epochs)\n",
        "\n",
        "#   plot_history(history)\n",
        "\n",
        "\n",
        "#   predicciones = generate_predictions(data_customer_norm, data_customer_norm_params, False)\n",
        "#   predicciones_all = sumar_predicciones(predicciones_all, predicciones)\n",
        "\n",
        "# predicciones_all.to_csv('predicciones_local.csv', header=True, index=False)"
      ],
      "metadata": {
        "id": "TvvXLKmpyS5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/10 - No Split"
      ],
      "metadata": {
        "id": "MFRKlhKimrIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # #########################################################################\n",
        "# # # Sin Splitear los datos, usando todo para entrenar\n",
        "# # # #########################################################################\n",
        "\n",
        "# data_train_windowed = windowed_dataset(data_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# # data_train_windowed = window_dataset(data_norm, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'M1'\n",
        "# # loss = 'mse'\n",
        "# # optimizer = 'adam'\n",
        "# # patience = 30\n",
        "# epochs = 10\n",
        "\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     # validation_data = data_valid_windowed,\n",
        "#     # callbacks = callbacks,\n",
        "#     verbose=2,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# plot_history(history)\n",
        "# predicciones = generate_predictions(True)\n",
        "# predicciones"
      ],
      "metadata": {
        "id": "JFTI6TUpmrRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/10 - Split #2"
      ],
      "metadata": {
        "id": "56uvfCGZfKek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # #########################################################################\n",
        "# # # Train desde 2017-01 hasta 2019-06\n",
        "# # # #########################################################################\n",
        "\n",
        "# data_train, data_valid = split_data_2(data_norm)\n",
        "# data_train_windowed = window_dataset(data_train, data_split='train', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "# data_valid_windowed = window_dataset(data_valid, data_split='valid', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'M1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "\n",
        "# callbacks = MyCallbacks(model_name, patience)\n",
        "# model = MyModel(loss, optimizer, window_size, n_future, n_features)\n",
        "\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data = data_valid_windowed,\n",
        "#     callbacks = callbacks,\n",
        "#     verbose=2,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# generate_predictions()"
      ],
      "metadata": {
        "id": "kMCpoMFHfMgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 06/10 - Split #1"
      ],
      "metadata": {
        "id": "Z2xfLSMdU96y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKqWpm9EmC_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # # #########################################################################\n",
        "# # # # Train 2018 & 2018, Validation 2019 (10/06)\n",
        "# # # # #########################################################################\n",
        "# data_train, data_valid = split_data_1(data_norm)\n",
        "# data_train_windowed = windowed_dataset(data_train, data_split='train', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "# data_valid_windowed = windowed_dataset(data_valid, data_split='valid', window_size=window_size, horizon=horizon, batch_size=batch_size)\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'M1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "\n",
        "# callbacks = MyCallbacks(patience)\n",
        "# model = MyModel(loss, optimizer, window_size, horizon, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data = data_valid_windowed,\n",
        "#     callbacks = callbacks,\n",
        "#     verbose=2,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# plot_history(history)\n",
        "# preddicciones = generate_predictions(True)\n",
        "# preddicciones"
      ],
      "metadata": {
        "id": "I4NrpvT1VgNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate: Product 20001"
      ],
      "metadata": {
        "id": "9L6P6xEM3XPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data_filled[['20001']]\n",
        "\n",
        "# # Parámetros\n",
        "# window_size = 6  # Tamaño de la ventana de tiempo\n",
        "# n_future = 2  # Número de pasos futuros a predecir\n",
        "# batch_size = 32\n",
        "# n_splits = 5  # Número de divisiones para validación \"walk forward\"\n",
        "# n_features = data.shape[1]  # Número de características en el conjunto de datos\n",
        "\n",
        "# data_norm, data_norm_params = normalize_data(data, normalization=normalization)\n",
        "# data_norm"
      ],
      "metadata": {
        "id": "keCpJUPo3ggY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proof of Concept"
      ],
      "metadata": {
        "id": "y28Ak-HH3TEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #########################################################################\n",
        "# # New Pipeline (09/06)\n",
        "# #########################################################################\n",
        "# data_norm, data_norm_params = normalize_data(data_filled, normalization=normalization)\n",
        "# # data_train, data_valid = split_data(data_norm) # Split pendiente\n",
        "# data_train = data_norm\n",
        "# print(data_train.shape)\n",
        "# # print(data_valid.shape)\n",
        "# data_train_windowed = window_dataset(data_train, data_split='train', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "# # data_valid_windowed = window_dataset(data_valid, data_split='valid', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "\n",
        "\n",
        "# #########################################################################\n",
        "# # Old Pipeline (08/06)\n",
        "# #########################################################################\n",
        "# # data_all = group_data(data, data_productos_a_predecir)\n",
        "# # data_all_norm, data_all_norm_params = normalize_data(data_all, normalization=normalization)\n",
        "# # data_all_norm['20001'].describe()\n",
        "# # data_train, data_valid = split_data_all(data_all_norm)\n",
        "# # print(data_train.shape)\n",
        "# # print(data_valid.shape)\n",
        "# # data_train = data_all_norm\n",
        "# # data_train_windowed = window_dataset(data_train, data_split='train', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "# # data_valid_windowed = window_dataset(data_valid, data_split='valid', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "\n",
        "\n",
        "# #########################################################################\n",
        "# # Modelo\n",
        "# #########################################################################\n",
        "# data_train, data_valid = split_data_1(data_norm)\n",
        "# data_train_windowed = window_dataset(data_train, data_split='train', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "# data_valid_windowed = window_dataset(data_valid, data_split='valid', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "\n",
        "# # Model Variables\n",
        "# model_name = 'M1'\n",
        "# loss = 'mse'\n",
        "# optimizer = 'adam'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "\n",
        "# callbacks = MyCallbacks(model_name, patience)\n",
        "# model = MyModel(loss, optimizer, window_size, n_future, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     validation_data = data_valid_windowed,\n",
        "#     callbacks = callbacks,\n",
        "#     verbose=2,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# generate_predictions()"
      ],
      "metadata": {
        "id": "bCx0jH7rFU-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "CRuRNJCI8J7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivos Preeliminares\n",
        "* [x] Algunos productos por promedio, otros por red neuronal. Identificar cuales\n",
        " (los que no tengo ventas todos o la mayoria de los meses)\n",
        "*[x] Saber como fueron las ventas en cada Agosto, comparado con Julio y Septiembre del mismo ano. Esto para poder sortear el problema de la no ventas en Agosto 2018\n",
        "*[x] Entender la distribucion de ventas por categoria\n",
        "*[ ] Entender la distribucion de los errores por categoria\n",
        "*[ ] entrenar en 2017 y 2018, y predecir feb 2019, teniendo en cuenta el trend negativo de alguna manera\n",
        "*[ ] Saber si la serie de todos los productos por categoria, son similares\n",
        "*[ ] Dividr las ventas por tipo de calidad de producto (Alto, Media Bajo), pedirlo si no esta\n",
        "*[ ] Ver el error por producto, para saber cual analizar individualmente\n",
        "*[ ] Identificar los productos mas importantes, separarlos por categoria, y fijarse si las series son similares. No con todos, maybe los 150 orimeros solametne\n",
        "*[ ] Probar Unvariado en cada producto?\n",
        "\n"
      ],
      "metadata": {
        "id": "oX5UG0OxbRrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot de Ventas General\n",
        "# data.groupby(['periodo'])['tn'].sum().plot()\n",
        "# plt.show()\n",
        "\n",
        "# # # Deidentificacionde los productos y clientes\n",
        "# # # Evidentemente cuando el profe deidentifico los customers, lo hizo asignandoles ID secuenciales al listado ordenado por la suma de ventas(tn)\n",
        "# # print('Listado de Clientes, ordenados por la sumatoria de ventas en tn:\\n', group_data(data, 'customer_id').sum(), '\\n')\n",
        "\n",
        "# # # Lo mismo cuando deidentifico a los productos, solo que esta vez empezo desde 20000\n",
        "# # print('Listado de Productos, ordenados por la sumatoria de ventas en tn:\\n', group_data(data, 'product_id').sum())"
      ],
      "metadata": {
        "id": "-PQsvGzWAIMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vemos la Tendencia Negativa\n",
        "* Tambien vemos la seasonalidad anual, y mas chica puede que tabien\n",
        "* Tambien se ve la caida en 2019-08, ya que decidimos no vender ese mes"
      ],
      "metadata": {
        "id": "talT1z4hc8jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top 74"
      ],
      "metadata": {
        "id": "tEP9EZ77NM46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # data\n",
        "# # # data_productos\n",
        "# # # data_stocks\n",
        "# # # data_productos_a_predecir\n",
        "\n",
        "\n",
        "# mask_product_id_sold36 = (data_grouped > 0).sum(axis=0)==36\n",
        "# print('Productos vendidos los 36 meses:', mask_product_id_sold36.sum())\n",
        "# mask_product_id_sold12 = (data_grouped > 0).sum(axis=0)<=12\n",
        "# print('Productos vendidos en 12 meses o menos:', mask_product_id_sold12.sum())\n"
      ],
      "metadata": {
        "id": "tjN0AgGnNL7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ajustar la opción para mostrar más filas\n",
        "# pd.set_option('display.max_rows', None)\n",
        "\n",
        "# # mask_product_id_sold36[:76]"
      ],
      "metadata": {
        "id": "-mfMCEo-SrSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Vamos a ver de el TOP 74 (hasta ID 84) de los productos mas vendidos, y solo los product_id 20032 y 20049 no se vendieron los 36 meses\n"
      ],
      "metadata": {
        "id": "Zn2bX_L8VB5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Analizamos esos casos en particular\n",
        "# data_grouped.loc[:, ['20032', '20049']].plot(title='Productos Top75 que no se vendieron los 36 meses')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "YuBGEZQhUQ4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Uno se empezo a vender en 2019-02, y el otro 2017-08"
      ],
      "metadata": {
        "id": "x-fmExFCWE1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hacemos el CumSum de cada producto\n",
        "# SUM_TOT = data_grouped.sum(axis=0).sum()\n",
        "# product_id_32_sum = data_grouped.sum(axis=0).loc['20032']/SUM_TOT\n",
        "# product_id_49_sum = data_grouped.sum(axis=0).loc['20049']/SUM_TOT\n",
        "\n",
        "# (data_grouped.sum(axis=0)/SUM_TOT).loc[:'20084'].sum() - product_id_32_sum - product_id_49_sum"
      ],
      "metadata": {
        "id": "sxyEGV2WWCG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* De los 74 productos mas vendidos (menos 32 y 49), disponemos de ventas los 36 meses\n",
        "* Esos 74 productos representan un %66 de las Toneladas totales vendidas"
      ],
      "metadata": {
        "id": "3HVeAeneZhpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Marco los que se vendieron los 36 meses\n",
        "# mask_products_id_top74 = mask_product_id_sold36\n",
        "\n",
        "# # No me interesan los +75\n",
        "# mask_products_id_top74.loc['20085':] = False\n",
        "# mask_products_id_top74.sum()"
      ],
      "metadata": {
        "id": "CozfxDIHjVgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis Agosto 2019"
      ],
      "metadata": {
        "id": "ePaHFgdPb0VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_grouped.loc['2017-06':'2017-10'].sum(axis=1).plot(title='Agosto crece-crece en 2017')\n",
        "# plt.show()\n",
        "\n",
        "# data_grouped.loc['2018-06':'2018-10'].sum(axis=1).plot(title='Agosto crece-decrece en 2018')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "SPJsHIyQdkhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Pareciera ser que siempre sube un 10% con respecto al Julio anterior"
      ],
      "metadata": {
        "id": "hiN9yUs1vtTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis por Categoria"
      ],
      "metadata": {
        "id": "AoScqaZOIrIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Genero el vector de categorias\n",
        "# categorias = data_productos_a_predecir_con_categorias.cat1.unique()\n",
        "\n",
        "# tn_TOT = data_grouped.sum().sum()\n",
        "\n",
        "# for cat in categorias:\n",
        "#   data_cat1 = filter_data_por_categoria(data_grouped, cat, 'cat1')\n",
        "#   n_features = data_cat1.shape[1]\n",
        "#   cat_tot = np.round(data_cat1.sum().sum() / tn_TOT, 2)\n",
        "#   print(f'{cat}, {data_cat1.shape}, {cat_tot}')\n"
      ],
      "metadata": {
        "id": "YIojBdWVI2m-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* La categoria con mas productos es PC con 444\n",
        "* Pero la que mas vende en toneladas es HC, con un 61% del total"
      ],
      "metadata": {
        "id": "dD5QG3mnLjKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisis Ventas en los Febreros"
      ],
      "metadata": {
        "id": "9M0IKSYdSrzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # En 2017\n",
        "\n",
        "# data_2017 =data_grouped.loc['2017'].mean(axis=0)\n",
        "# feb_2017 = data_grouped.loc['2017-02']\n",
        "\n",
        "# # # Ploteamos 2017\n",
        "# # fig, ax = plt.subplots(figsize=(10, 6))\n",
        "# # # Ploteamos promedio del 2017\n",
        "# # data_2017[:50].plot(ax=ax, label='Promedio 2017')\n",
        "# # # Ploteamos Febrero 2017\n",
        "# # feb_2017.T[:50].plot(ax=ax, label='Febrero 2017')\n",
        "# # ax.legend()\n",
        "# # plt.show()\n",
        "# # # Vemos como el promedio anual y las ventas de Feb tienen una cierta relacion\n",
        "\n",
        "# # Calculamos el ratio que Febrero corresponde al promedio anual\n",
        "# diff_2017 = pd.Series(((data_2017- feb_2017)/feb_2017).T.squeeze(), name='diff')\n",
        "\n",
        "# # Lo joineamos a las categorias\n",
        "# diff_2017_cat = pd.concat([diff_2017, data_productos_a_predecir_con_categorias[['cat1', 'cat2']]], axis=1)\n",
        "\n",
        "# # Analizamos\n",
        "# diff_2017_cat.groupby('cat1')['diff'].mean().plot(kind='bar')\n",
        "# plt.title('Ratio ventas Proemdio Anual sobre Febrero en 2017')\n",
        "# plt.show()\n",
        "\n",
        "# # display(diff_cat.sort_values(by='diff', ascending=False).head(30))\n",
        "# # Vemos que ciertos productos de Personal Care no siguen el patron\n",
        "# # Esto habra sido un problema puntual en 2017, el profe habia comentaso lo de las cremas?\n",
        "# # Lo que si nos interesa es ver que HC y FOODS estan cerca del 0.5"
      ],
      "metadata": {
        "id": "PaHvU0QWSs4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # En 2018\n",
        "\n",
        "# data_2018 =data_grouped.loc['2018'].mean(axis=0)\n",
        "# feb_2018 = data_grouped.loc['2018-02']\n",
        "\n",
        "\n",
        "# # Calculamos el ratio que Febrero corresponde al promedio anual\n",
        "# diff_2018 = pd.Series(((data_2018 - feb_2018)/feb_2018).T.squeeze(), name='diff')\n",
        "\n",
        "# # Lo joineamos a las categorias\n",
        "# diff_2018_cat = pd.concat([diff_2018, data_productos_a_predecir_con_categorias[['cat1', 'cat2']]], axis=1)\n",
        "\n",
        "# # Analizamos\n",
        "# diff_2018_cat.groupby('cat1')['diff'].mean().plot(kind='bar')\n",
        "# plt.title('Ratio ventas Proemdio Anual sobre Febrero en 2018')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # HC y FOODS estan cerca del 0.5, como antes\n",
        "# # En FOODS paso algo raro, igual no vamos a analizarlo\n",
        "# # REF es insifnificante (solo 17 productos)"
      ],
      "metadata": {
        "id": "yOhqXjPQgAeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # En 2019\n",
        "# data_2019 =data_grouped.loc['2019'].mean(axis=0)\n",
        "# feb_2019 = data_grouped.loc['2019-02']\n",
        "\n",
        "\n",
        "# # Calculamos el ratio que Febrero corresponde al promedio anual\n",
        "# diff_2019 = pd.Series(((data_2019 - feb_2019)/feb_2019).T.squeeze(), name='diff')\n",
        "\n",
        "# # Lo joineamos a las categorias\n",
        "# diff_2019_cat = pd.concat([diff_2019, data_productos_a_predecir_con_categorias[['cat1', 'cat2']]], axis=1)\n",
        "\n",
        "# # Analizamos\n",
        "# diff_2019_cat.groupby('cat1')['diff'].mean().plot(kind='bar')\n",
        "# plt.title('Ratio ventas Proemdio Anual sobre Febrero en 2019')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "K4lr12YdhUTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Que productos se vendieron los 36 meses"
      ],
      "metadata": {
        "id": "GEJxmKPZ-bZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_products_sales(data_bkp)"
      ],
      "metadata": {
        "id": "MKaQu--V7p4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Verificamos los productos nuevos\n",
        "\n",
        "# # Verificamos si hay valores nulos en el DataFrame\n",
        "# null_data = data.isnull()\n",
        "\n",
        "# # Creamos el heatmap para visualizar los valores nulos\n",
        "# plt.figure(figsize=(15, 10))\n",
        "# sns.heatmap(null_data, cmap='viridis', cbar=False)\n",
        "# plt.title('Productos sin ventas en algunos meses (null values)')\n",
        "# plt.xlabel('Product ID')\n",
        "# plt.ylabel('Fecha')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # Hay que decidir que hacer con los productos que no se vendieron todos los meses\n",
        "# # los sacamos del modelo y predecimos de alguna otra manera?"
      ],
      "metadata": {
        "id": "4D8PDrMLv_FZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}