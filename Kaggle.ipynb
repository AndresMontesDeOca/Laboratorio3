{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOFWNeAhNgaxJFJyxBKe17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/Laboratorio3/blob/main/Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle Experiments"
      ],
      "metadata": {
        "id": "crj3eqSV_WvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "eL3soxEh_cgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore', category=ValueWarning)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ajustar la opción para mostrar más filas\n",
        "# pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Si también quieres mostrar más columnas\n",
        "# pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "# Vamos a suprimir la notacion cientifica\n",
        "pd.set_option(\"display.float_format\", lambda x:\"%.2f\" %x)\n"
      ],
      "metadata": {
        "id": "4dKLvveO9QDs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga Datos"
      ],
      "metadata": {
        "id": "CCBiyQvD_nC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "# !pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "################################# Datasets ###################################\n",
        "# # Ventas\n",
        "id = \"158aOjqxaNO8l97yA6VWJkek_15YVLMhs\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('sell-in.txt')\n",
        "data_ventas = pd.read_csv(\"sell-in.txt\", sep=\"\\t\")\n",
        "data_ventas['periodo'] = pd.to_datetime(data_ventas['periodo'], format='%Y%m')\n",
        "data = data_ventas.copy()\n",
        "\n",
        "# # Productos\n",
        "id = \"15JS_k86LS0sgJXma7BOVXWlyNcMwxdhE\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_productos.txt')\n",
        "data_productos = pd.read_csv(\"tb_productos.txt\", sep=\"\\t\")\n",
        "\n",
        "# # Stocks\n",
        "id = \"15EV-8f_U7onpA1AcTxxXeD-z8yVR4fQu\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_stocks.txt')\n",
        "data_stocks = pd.read_csv(\"tb_stocks.txt\", sep=\"\\t\")\n",
        "data_stocks['periodo'] = pd.to_datetime(data_stocks['periodo'], format='%Y%m')\n",
        "\n",
        "# # Productos a predecir\n",
        "id = \"15LjADctFVwjzQFJvfJGFTEdgZx9xCoId\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('productos_a_predecir.txt')\n",
        "data_productos_a_predecir = pd.read_csv(\"productos_a_predecir.txt\", sep=\"\\t\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8GISdopF_obd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2ea45c-fac3-4f82-b65d-86898f560043"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Data"
      ],
      "metadata": {
        "id": "dJckQiyL08r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_data(data_all, data_filter):\n",
        "    # Filtrar el DataFrame 'data_all' para que solo contenga los 'product_id' presentes en 'data_filter'\n",
        "    data_filtered = data_all[data_all['product_id'].isin(data_filter['product_id'])]\n",
        "\n",
        "    return data_filtered"
      ],
      "metadata": {
        "id": "nnSdLDk60-bO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Data"
      ],
      "metadata": {
        "id": "5L-kvH-J_7SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Siempre como values toma las toneladas vendidas\n",
        "def group_data(data, column):\n",
        "  grouped_data = data.groupby([column, 'periodo']).sum().reset_index()\n",
        "\n",
        "  # Crea un DataFrame pivoteado donde las filas son las fechas y las columnas son los product_id\n",
        "  pivot_data = grouped_data.pivot(index='periodo', columns=column, values='tn')\n",
        "\n",
        "  # Asegúrate de que los nombres de las columnas sean strings\n",
        "  pivot_data.columns = pivot_data.columns.astype(str)\n",
        "\n",
        "  # Restablece el índice para asegurarse de que 'product_id' no sea un índice compuesto\n",
        "  pivot_data.columns.name = None\n",
        "\n",
        "  return pivot_data"
      ],
      "metadata": {
        "id": "Mrkkv5Kd0yCG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fill Nulls"
      ],
      "metadata": {
        "id": "p_XRfvor4fhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jugar con esto, no se si esta bien\n",
        "def fill_nulls(data):\n",
        "  # Primero usamos bfill para completar las ordenes mas viejas con los valores de las ordenes mas recientes\n",
        "  data = data.bfill()\n",
        "  # Luego completamos con ceros los productos que dejamos de vender, o se discontinuaron\n",
        "  data = data.fillna(0)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "WPghARRT5HE3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Filtrar el DataFrame 'data' para que solo contenga los 'product_id' presentes en 'data_productos_a_predecir'\n",
        "# data_filtered = data[data['product_id'].isin(data_productos_a_predecir['product_id'])]\n",
        "\n",
        "\n",
        "# # Agrupa los datos por 'product_id' y 'periodo', y calcula la suma de 'tn'\n",
        "# grouped_data = data_filtered.groupby(['product_id', 'periodo']).sum().reset_index()\n",
        "\n",
        "# # Crea un DataFrame pivoteado donde las filas son las fechas y las columnas son los product_id\n",
        "# pivot_data = grouped_data.pivot(index='periodo', columns='product_id', values='tn')\n",
        "\n",
        "# # Rellena los NaN\n",
        "# pivot_data = pivot_data.fillna(0)\n",
        "\n",
        "# # Asegúrate de que los nombres de las columnas sean strings\n",
        "# pivot_data.columns = pivot_data.columns.astype(str)\n",
        "\n",
        "# # Restablece el índice para asegurarse de que 'product_id' no sea un índice compuesto\n",
        "# pivot_data.columns.name = None\n",
        "\n",
        "# data_2019 = pivot_data.loc['2019']"
      ],
      "metadata": {
        "id": "yjM-cBgZ_9uu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize Data"
      ],
      "metadata": {
        "id": "a2ctIs9UCRRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################################################\n",
        "def normalize_data(df, normalization=\"MinMax\"):\n",
        "    \"\"\"\n",
        "    Normaliza cada serie de tiempo (columna) de manera individual usando MinMax o Zscore.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con series de tiempo de distintos productos, cada columna es un producto.\n",
        "        normalization (str): Tipo de normalización a aplicar. Opciones: \"MinMax\" o \"Zscore\". Default es \"MinMax\".\n",
        "\n",
        "    Returns:\n",
        "        normalized_df (pd.DataFrame): DataFrame con las series normalizadas.\n",
        "        normalization_params (dict): Diccionario con los parámetros necesarios para desnormalizar cada columna.\n",
        "            - Para \"MinMax\": valores min y max de cada columna.\n",
        "            - Para \"Zscore\": valores mean y std de cada columna.\n",
        "    \"\"\"\n",
        "    normalization_params = {}\n",
        "    normalized_df = pd.DataFrame()\n",
        "\n",
        "    for column in df.columns:\n",
        "        if normalization == \"MinMax\":\n",
        "            min_value = df[column].min()\n",
        "            max_value = df[column].max()\n",
        "            normalization_params[column] = {\"min\": min_value, \"max\": max_value}\n",
        "            normalized_df[column] = (df[column] - min_value) / (max_value - min_value)\n",
        "\n",
        "        elif normalization == \"ZScore\":\n",
        "            mean_value = df[column].mean()\n",
        "            std_value = df[column].std()\n",
        "            normalization_params[column] = {\"mean\": mean_value, \"std\": std_value}\n",
        "            normalized_df[column] = (df[column] - mean_value) / std_value\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'ZScore'.\")\n",
        "\n",
        "    return normalized_df, normalization_params\n",
        "##########################################################################################\n",
        "def denormalize_series(normalized_series, normalization_params, normalization=\"MinMax\"):\n",
        "    \"\"\"\n",
        "    Desnormaliza una serie de tiempo usando los valores almacenados.\n",
        "\n",
        "    Args:\n",
        "        normalized_series (pd.Series): Serie con los datos normalizados.\n",
        "        normalization_params (dict): Diccionario con los parámetros necesarios para desnormalizar cada serie.\n",
        "            - Para \"MinMax\": valores min y max de cada serie.\n",
        "            - Para \"Zscore\": valores mean y std de cada serie.\n",
        "        normalization (str): Tipo de normalización a deshacer. Opciones: \"MinMax\" o \"Zscore\". Default es \"MinMax\".\n",
        "\n",
        "    Returns:\n",
        "        denormalized_series (pd.Series): Serie con los datos desnormalizados.\n",
        "    \"\"\"\n",
        "    denormalized_series = pd.Series(index=normalized_series.index)\n",
        "\n",
        "    for index in normalized_series.index:\n",
        "        if str(index) in normalization_params:\n",
        "            params = normalization_params[str(index)]\n",
        "        else:\n",
        "            raise KeyError(f\"Index {index} not found in normalization parameters.\")\n",
        "\n",
        "        if normalization == \"MinMax\":\n",
        "            min_value = params[\"min\"]\n",
        "            max_value = params[\"max\"]\n",
        "            denormalized_series[index] = normalized_series[index] * (max_value - min_value) + min_value\n",
        "\n",
        "        elif normalization == \"ZScore\":\n",
        "            mean_value = params[\"mean\"]\n",
        "            std_value = params[\"std\"]\n",
        "            denormalized_series[index] = normalized_series[index] * std_value + mean_value\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'ZScore'.\")\n",
        "\n",
        "    return denormalized_series\n",
        "##########################################################################################"
      ],
      "metadata": {
        "id": "jTr6HsM8CTL2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data"
      ],
      "metadata": {
        "id": "6z54dcDlIyHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data_all(data):\n",
        "  data_train = data.loc['2017-01':'2018-12']\n",
        "  data_valid = data.loc['2019-01':'2019-12']\n",
        "  return data_train, data_valid"
      ],
      "metadata": {
        "id": "zZUKfILzC6Un"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window Data"
      ],
      "metadata": {
        "id": "xbYFP2j6EiEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_dataset(sequence, data_split, window_size, batch_size, n_future, shuffle_buffer=1000, seed=None):\n",
        "    \"\"\"Generates dataset windows for multi-step forecasting in a multivariable context.\n",
        "\n",
        "    Args:\n",
        "      sequence (array-like): Contains the values of the time series, where each element is an array of feature values.\n",
        "      data_split (str): Specifies if the dataset is for training or validation/test.\n",
        "      window_size (int): The number of time steps to include in the feature.\n",
        "      batch_size (int): The batch size.\n",
        "      n_future (int): The number of future steps to predict.\n",
        "      shuffle_buffer (int): Buffer size to use for the shuffle method.\n",
        "      seed (int, optional): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "      tf.data.Dataset: TF Dataset containing time windows.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size + n_future, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + n_future))\n",
        "\n",
        "    # Create tuples with features and labels\n",
        "    dataset = dataset.map(lambda window: (window[:window_size], window[window_size:]))\n",
        "\n",
        "    if data_split == 'train':\n",
        "        # Shuffle the training data to improve generalization\n",
        "        dataset = dataset.shuffle(shuffle_buffer, seed=seed)\n",
        "    else:\n",
        "        # Cache the validation/test data for improved performance\n",
        "        dataset = dataset.cache()\n",
        "\n",
        "    # Create batches of windows and prefetch for performance\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "c5g4WjakEjcM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "brfkj2XkXena"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "\n",
        "class MAEThresholdCallback(Callback):\n",
        "    def __init__(self, threshold=0.15):\n",
        "        super(MAEThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_mae = logs.get('val_mae')\n",
        "        if val_mae is not None and val_mae <= self.threshold:\n",
        "            print(f'\\nEpoch {epoch+1}: Validation MAE has reached {val_mae:.4f}, stopping training.')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def MyCallbacks(model_name, patience):\n",
        "    earlystop = tf.keras.callbacks.EarlyStopping('val_loss', patience=patience, restore_best_weights=True)\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'ckpts/{model_name}-' + '{epoch:02d}-{val_loss:.4f}.h5', monitor='val_loss')\n",
        "    mae_threshold_callback = MAEThresholdCallback(threshold=0.015)\n",
        "    return [earlystop] #, checkpoint] #, mae_threshold_callback]\n",
        "\n",
        "#############################################################################"
      ],
      "metadata": {
        "id": "ETzh0JyBXgRt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Design"
      ],
      "metadata": {
        "id": "cGAz7W4mXqO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "def compile_model(new_model, loss):\n",
        "  new_model.compile(optimizer='adam', loss=loss, metrics=['mae']) # metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "  print(new_model.summary())\n",
        "  return new_model\n",
        "#############################################################################\n",
        "def MyModel(loss, window_size, n_future, n_features):\n",
        "    new_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer((window_size, n_features)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=False)),\n",
        "        # tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(n_features * n_future, activation='relu'),\n",
        "        tf.keras.layers.Reshape((n_future, n_features)),\n",
        "        ])\n",
        "    return compile_model(new_model, loss)"
      ],
      "metadata": {
        "id": "eCESYECOXr45"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "F4yiWWu8FJZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "HWg00hIFX64c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "# data_productos\n",
        "# data_stocks\n",
        "# data_productos_a_predecir\n",
        "window_size = 6\n",
        "n_future = 2\n",
        "batch_size = 4\n",
        "normalization = 'MinMax'\n",
        "\n",
        "# #########################################################################\n",
        "# Old Pipeline\n",
        "# #########################################################################\n",
        "# data_all = group_data(data, data_productos_a_predecir)\n",
        "# data_all_norm, data_all_norm_params = normalize_data(data_all, normalization=normalization)\n",
        "# data_all_norm['20001'].describe()\n",
        "# data_train, data_valid = split_data_all(data_all_norm)\n",
        "# print(data_train.shape)\n",
        "# print(data_valid.shape)\n",
        "# data_train = data_all_norm\n",
        "# data_train_windowed = window_dataset(data_train, data_split='train', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "# data_valid_windowed = window_dataset(data_valid, data_split='valid', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "\n"
      ],
      "metadata": {
        "id": "vLrQTz5YEkPk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Train"
      ],
      "metadata": {
        "id": "3MO74bl3X9X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # # #########################################################################\n",
        "# # # # # Neural Netowrk Model\n",
        "# # # #########################################################################\n",
        "# model_name = 'TimeSeries'\n",
        "# loss = 'mse'\n",
        "# patience = 30\n",
        "# epochs = 500\n",
        "# n_features = data_all.shape[1]\n",
        "\n",
        "# callbacks = MyCallbacks(model_name, patience)\n",
        "# model = MyModel(loss, window_size, n_future, n_features)\n",
        "\n",
        "# history = model.fit(\n",
        "#     data_train_windowed,\n",
        "#     # validation_data = data_valid_windowed,\n",
        "#     # validation_split=0.2,\n",
        "#     # callbacks = callbacks,\n",
        "#     epochs=epochs)\n",
        "\n",
        "# # plot_history(history, 4)\n",
        "# # save_model(model, model_name, history, data_test_wrangled)\n",
        "# # show_predictions(model, data_test_wrangled, data_test[n_past:])"
      ],
      "metadata": {
        "id": "OoF2b2xwW2IM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Supongamos que `data_all` contiene tus datos históricos, incluyendo 2019.\n",
        "# # data_all debe tener la forma (n_samples, n_features)\n",
        "\n",
        "# # Convertir el DataFrame a un array de NumPy\n",
        "# data_all_array = data_all.values\n",
        "\n",
        "# # Extraer la última ventana de datos de 2019 para predecir enero de 2020\n",
        "# column_names = data_all.columns  # Obtener los nombres de las columnas\n",
        "\n",
        "# # Extraer los últimos `window_size` meses de 2019\n",
        "# input_data = data_all_array[-window_size:].reshape((1, window_size, n_features))\n",
        "\n",
        "# # Predecir enero de 2020\n",
        "# pred_january = model.predict(input_data)\n",
        "\n",
        "# # Asegurarse de que la predicción tenga la forma correcta\n",
        "# pred_january = pred_january.reshape((1, n_future, n_features))\n",
        "\n",
        "# # Crear un DataFrame para la predicción de enero de 2020\n",
        "# pred_january_df = pd.DataFrame(pred_january[0], columns=column_names)\n",
        "# pred_january_df.index = pd.date_range(start='2020-01-01', periods=n_future, freq='MS')\n",
        "\n",
        "# # Actualizar la ventana de entrada para predecir febrero de 2020\n",
        "# input_data = np.append(input_data[:, 1:, :], pred_january[:, 0, :].reshape(1, 1, n_features), axis=1)\n",
        "\n",
        "# # Predecir febrero de 2020\n",
        "# pred_february = model.predict(input_data)\n",
        "\n",
        "# # Asegurarse de que la predicción tenga la forma correcta\n",
        "# pred_february = pred_february.reshape((1, n_future, n_features))\n",
        "\n",
        "# # Crear un DataFrame para la predicción de febrero de 2020\n",
        "# pred_february_df = pd.DataFrame(pred_february[0], columns=column_names)\n",
        "# pred_february_df.index = pd.date_range(start='2020-02-01', periods=n_future, freq='MS')\n",
        "\n",
        "# # Predije dos veces, una volviendo a entrenar con los datos predichos de Enero 2020, y la otra no.\n",
        "# pred_1 = pred_january_df.loc['2020-02-01']\n",
        "\n",
        "# pred_1_denorm = denormalize_series(pred_1, data_all_norm_params, normalization=normalization)\n",
        "# data_pred1_denorm = pred_1_denorm.reset_index()\n",
        "# data_pred1_denorm.columns = ['product_id', 'tn']\n",
        "# data_pred1_denorm.to_csv('pred_1.csv', index=False)"
      ],
      "metadata": {
        "id": "CllkIp6PbPVx"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "CRuRNJCI8J7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evidentemente cuando el profe deidentifico los customers, lo hizo asignandoles ID secuenciales al listado ordenado por la suma de ventas(tn)\n",
        "print('Listado de Clientes, ordenados por la sumatoria de ventas en tn:\\n', group_data(data, 'customer_id').sum(), '\\n')\n",
        "\n",
        "# Lo mismo cuando deidentifico a los productos, solo que esta vez empezo desde 20000\n",
        "print('Listado de Productos, ordenados por la sumatoria de ventas en tn:\\n', group_data(data, 'product_id').sum())"
      ],
      "metadata": {
        "id": "QOAjN92m8LJU",
        "outputId": "cee5dfd1-7cfc-447c-a8fa-77a975714e45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listado de Clientes, ordenados por la sumatoria de ventas en tn:\n",
            " 10001   109203.60\n",
            "10002    77333.17\n",
            "10003    71375.92\n",
            "10004    63065.94\n",
            "10005    51467.05\n",
            "           ...   \n",
            "10633        0.14\n",
            "10634        0.10\n",
            "10635        0.10\n",
            "10636        0.04\n",
            "10637        0.00\n",
            "Length: 597, dtype: float64 \n",
            "\n",
            "Listado de Productos, ordenados por la sumatoria de ventas en tn:\n",
            " 20001   50340.40\n",
            "20002   36337.25\n",
            "20003   32004.15\n",
            "20004   24178.15\n",
            "20005   23191.22\n",
            "          ...   \n",
            "21295       0.01\n",
            "21296       0.01\n",
            "21297       0.01\n",
            "21298       0.01\n",
            "21299       0.01\n",
            "Length: 1233, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "00gWkwQg8MPq",
        "outputId": "98107c8f-8222-49ae-d5ae-f7569f7e5081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
              "0       2017-01-01        10234       20524                      0   \n",
              "1       2017-01-01        10032       20524                      0   \n",
              "2       2017-01-01        10217       20524                      0   \n",
              "3       2017-01-01        10125       20524                      0   \n",
              "4       2017-01-01        10012       20524                      0   \n",
              "...            ...          ...         ...                    ...   \n",
              "2945813 2019-12-01        10105       20853                      0   \n",
              "2945814 2019-12-01        10092       20853                      0   \n",
              "2945815 2019-12-01        10006       20853                      0   \n",
              "2945816 2019-12-01        10018       20853                      0   \n",
              "2945817 2019-12-01        10020       20853                      0   \n",
              "\n",
              "         cust_request_qty  cust_request_tn   tn  \n",
              "0                       2             0.05 0.05  \n",
              "1                       1             0.14 0.14  \n",
              "2                       1             0.03 0.03  \n",
              "3                       1             0.02 0.02  \n",
              "4                      11             1.54 1.54  \n",
              "...                   ...              ...  ...  \n",
              "2945813                 1             0.02 0.02  \n",
              "2945814                 1             0.01 0.01  \n",
              "2945815                 7             0.03 0.03  \n",
              "2945816                 4             0.02 0.02  \n",
              "2945817                 2             0.02 0.02  \n",
              "\n",
              "[2945818 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab071e5c-109d-4cd5-b200-9a67d1414f73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>periodo</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>plan_precios_cuidados</th>\n",
              "      <th>cust_request_qty</th>\n",
              "      <th>cust_request_tn</th>\n",
              "      <th>tn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10234</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10032</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10217</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10125</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2017-01-01</td>\n",
              "      <td>10012</td>\n",
              "      <td>20524</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945813</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>10105</td>\n",
              "      <td>20853</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945814</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>10092</td>\n",
              "      <td>20853</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945815</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>10006</td>\n",
              "      <td>20853</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945816</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>10018</td>\n",
              "      <td>20853</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2945817</th>\n",
              "      <td>2019-12-01</td>\n",
              "      <td>10020</td>\n",
              "      <td>20853</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2945818 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab071e5c-109d-4cd5-b200-9a67d1414f73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab071e5c-109d-4cd5-b200-9a67d1414f73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab071e5c-109d-4cd5-b200-9a67d1414f73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a1dd571-f823-41d3-9eb7-1f2883b3dad0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a1dd571-f823-41d3-9eb7-1f2883b3dad0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a1dd571-f823-41d3-9eb7-1f2883b3dad0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8f31bc95-29e0-428d-b0d2-c04a82e0b475\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8f31bc95-29e0-428d-b0d2-c04a82e0b475 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_qyQISS8bMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}