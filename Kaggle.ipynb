{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOL+CuJtwD4zU03KtjsuJd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndresMontesDeOca/Laboratorio3/blob/main/Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle Experiments"
      ],
      "metadata": {
        "id": "crj3eqSV_WvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "eL3soxEh_cgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "# from neuralprophet import NeuralProphet\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore', category=ValueWarning)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ajustar la opción para mostrar más filas\n",
        "# pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Si también quieres mostrar más columnas\n",
        "# pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "# Vamos a suprimir la notacion cientifica\n",
        "pd.set_option(\"display.float_format\", lambda x:\"%.2f\" %x)\n"
      ],
      "metadata": {
        "id": "4dKLvveO9QDs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnifBLRZ_jNx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga Datos"
      ],
      "metadata": {
        "id": "CCBiyQvD_nC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "# !pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "################################# Datasets ###################################\n",
        "# # Ventas\n",
        "id = \"158aOjqxaNO8l97yA6VWJkek_15YVLMhs\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('sell-in.txt')\n",
        "data_ventas = pd.read_csv(\"sell-in.txt\", sep=\"\\t\")\n",
        "data_ventas['periodo'] = pd.to_datetime(data_ventas['periodo'], format='%Y%m')\n",
        "data = data_ventas.copy()\n",
        "\n",
        "# # Productos\n",
        "id = \"15JS_k86LS0sgJXma7BOVXWlyNcMwxdhE\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_productos.txt')\n",
        "data_productos = pd.read_csv(\"tb_productos.txt\", sep=\"\\t\")\n",
        "\n",
        "# # Stocks\n",
        "id = \"15EV-8f_U7onpA1AcTxxXeD-z8yVR4fQu\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('tb_stocks.txt')\n",
        "data_stocks = pd.read_csv(\"tb_stocks.txt\", sep=\"\\t\")\n",
        "data_stocks['periodo'] = pd.to_datetime(data_stocks['periodo'], format='%Y%m')\n",
        "\n",
        "# # Productos a predecir\n",
        "id = \"15LjADctFVwjzQFJvfJGFTEdgZx9xCoId\"\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('productos_a_predecir.txt')\n",
        "data_productos_a_predecir = pd.read_csv(\"productos_a_predecir.txt\", sep=\"\\t\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8GISdopF_obd",
        "outputId": "be83f97f-5b3e-45fc-e8c6-eff077b3b260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Data"
      ],
      "metadata": {
        "id": "5L-kvH-J_7SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def group_data(data_all, data_filter):\n",
        "    # Filtrar el DataFrame 'data_all' para que solo contenga los 'product_id' presentes en 'data_filter'\n",
        "    data_filtered = data_all[data_all['product_id'].isin(data_filter['product_id'])]\n",
        "\n",
        "    # Agrupa los datos por 'product_id' y 'periodo', y calcula la suma de 'tn'\n",
        "    grouped_data = data_filtered.groupby(['product_id', 'periodo']).sum().reset_index()\n",
        "\n",
        "    # Crea un DataFrame pivoteado donde las filas son las fechas y las columnas son los product_id\n",
        "    pivot_data = grouped_data.pivot(index='periodo', columns='product_id', values='tn')\n",
        "\n",
        "    # Rellena los NaN\n",
        "    pivot_data = pivot_data.fillna(0)\n",
        "\n",
        "    # Asegúrate de que los nombres de las columnas sean strings\n",
        "    pivot_data.columns = pivot_data.columns.astype(str)\n",
        "\n",
        "    # Restablece el índice para asegurarse de que 'product_id' no sea un índice compuesto\n",
        "    pivot_data.columns.name = None\n",
        "\n",
        "    return pivot_data"
      ],
      "metadata": {
        "id": "yYcUNXXxGHIs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Filtrar el DataFrame 'data' para que solo contenga los 'product_id' presentes en 'data_productos_a_predecir'\n",
        "# data_filtered = data[data['product_id'].isin(data_productos_a_predecir['product_id'])]\n",
        "\n",
        "\n",
        "# # Agrupa los datos por 'product_id' y 'periodo', y calcula la suma de 'tn'\n",
        "# grouped_data = data_filtered.groupby(['product_id', 'periodo']).sum().reset_index()\n",
        "\n",
        "# # Crea un DataFrame pivoteado donde las filas son las fechas y las columnas son los product_id\n",
        "# pivot_data = grouped_data.pivot(index='periodo', columns='product_id', values='tn')\n",
        "\n",
        "# # Rellena los NaN\n",
        "# pivot_data = pivot_data.fillna(0)\n",
        "\n",
        "# # Asegúrate de que los nombres de las columnas sean strings\n",
        "# pivot_data.columns = pivot_data.columns.astype(str)\n",
        "\n",
        "# # Restablece el índice para asegurarse de que 'product_id' no sea un índice compuesto\n",
        "# pivot_data.columns.name = None\n",
        "\n",
        "# data_2019 = pivot_data.loc['2019']"
      ],
      "metadata": {
        "id": "yjM-cBgZ_9uu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize Data"
      ],
      "metadata": {
        "id": "a2ctIs9UCRRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def normalize_data(df, normalization=\"MinMax\"):\n",
        "    \"\"\"\n",
        "    Normaliza cada serie de tiempo (columna) de manera individual usando MinMax o Zscore.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame con series de tiempo de distintos productos, cada columna es un producto.\n",
        "        normalization (str): Tipo de normalización a aplicar. Opciones: \"MinMax\" o \"Zscore\". Default es \"MinMax\".\n",
        "\n",
        "    Returns:\n",
        "        normalized_df (pd.DataFrame): DataFrame con las series normalizadas.\n",
        "        normalization_params (dict): Diccionario con los parámetros necesarios para desnormalizar cada columna.\n",
        "            - Para \"MinMax\": valores min y max de cada columna.\n",
        "            - Para \"Zscore\": valores mean y std de cada columna.\n",
        "    \"\"\"\n",
        "    normalization_params = {}\n",
        "    normalized_df = pd.DataFrame()\n",
        "\n",
        "    for column in df.columns:\n",
        "        if normalization == \"MinMax\":\n",
        "            min_value = df[column].min()\n",
        "            max_value = df[column].max()\n",
        "            normalization_params[column] = {\"min\": min_value, \"max\": max_value}\n",
        "            normalized_df[column] = (df[column] - min_value) / (max_value - min_value)\n",
        "\n",
        "        elif normalization == \"ZScore\":\n",
        "            mean_value = df[column].mean()\n",
        "            std_value = df[column].std()\n",
        "            normalization_params[column] = {\"mean\": mean_value, \"std\": std_value}\n",
        "            normalized_df[column] = (df[column] - mean_value) / std_value\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'Zscore'.\")\n",
        "\n",
        "    return normalized_df, normalization_params\n",
        "##############################\n",
        "def denormalize_series(normalized_series, normalization_params, normalization=\"MinMax\"):\n",
        "    \"\"\"\n",
        "    Desnormaliza una serie de tiempo usando los valores almacenados.\n",
        "\n",
        "    Args:\n",
        "        normalized_series (pd.Series): Serie con los datos normalizados.\n",
        "        normalization_params (dict): Diccionario con los parámetros necesarios para desnormalizar cada serie.\n",
        "            - Para \"MinMax\": valores min y max de cada serie.\n",
        "            - Para \"Zscore\": valores mean y std de cada serie.\n",
        "        normalization (str): Tipo de normalización a deshacer. Opciones: \"MinMax\" o \"Zscore\". Default es \"MinMax\".\n",
        "\n",
        "    Returns:\n",
        "        denormalized_series (pd.Series): Serie con los datos desnormalizados.\n",
        "    \"\"\"\n",
        "    denormalized_series = pd.Series(index=normalized_series.index)\n",
        "\n",
        "    for index in normalized_series.index:\n",
        "        if str(index) in normalization_params:\n",
        "            params = normalization_params[str(index)]\n",
        "        else:\n",
        "            raise KeyError(f\"Index {index} not found in normalization parameters.\")\n",
        "\n",
        "        if normalization == \"MinMax\":\n",
        "            min_value = params[\"min\"]\n",
        "            max_value = params[\"max\"]\n",
        "            denormalized_series[index] = normalized_series[index] * (max_value - min_value) + min_value\n",
        "\n",
        "        elif normalization == \"Zscore\":\n",
        "            mean_value = params[\"mean\"]\n",
        "            std_value = params[\"std\"]\n",
        "            denormalized_series[index] = normalized_series[index] * std_value + mean_value\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Invalid normalization method. Choose 'MinMax' or 'Zscore'.\")\n",
        "\n",
        "    return denormalized_series\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jTr6HsM8CTL2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data"
      ],
      "metadata": {
        "id": "6z54dcDlIyHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data_all(data):\n",
        "  data_train = data.loc['2017':'2018']\n",
        "  data_valid = data.loc['2019']\n",
        "  return data_train, data_valid"
      ],
      "metadata": {
        "id": "zZUKfILzC6Un"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window Data"
      ],
      "metadata": {
        "id": "xbYFP2j6EiEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_dataset(sequence, data_split, window_size, batch_size, n_future, shuffle_buffer=1000, seed=None):\n",
        "    \"\"\"Generates dataset windows for multi-step forecasting in a multivariable context.\n",
        "\n",
        "    Args:\n",
        "      sequence (array-like): Contains the values of the time series, where each element is an array of feature values.\n",
        "      data_split (str): Specifies if the dataset is for training or validation/test.\n",
        "      window_size (int): The number of time steps to include in the feature.\n",
        "      batch_size (int): The batch size.\n",
        "      n_future (int): The number of future steps to predict.\n",
        "      shuffle_buffer (int): Buffer size to use for the shuffle method.\n",
        "      seed (int, optional): Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "      tf.data.Dataset: TF Dataset containing time windows.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size + n_future, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + n_future))\n",
        "\n",
        "    # Create tuples with features and labels\n",
        "    dataset = dataset.map(lambda window: (window[:window_size], window[window_size:]))\n",
        "\n",
        "    if data_split == 'train':\n",
        "        # Shuffle the training data to improve generalization\n",
        "        dataset = dataset.shuffle(shuffle_buffer, seed=seed)\n",
        "    else:\n",
        "        # Cache the validation/test data for improved performance\n",
        "        dataset = dataset.cache()\n",
        "\n",
        "    # Create batches of windows and prefetch for performance\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "c5g4WjakEjcM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "brfkj2XkXena"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "\n",
        "class MAEThresholdCallback(Callback):\n",
        "    def __init__(self, threshold=0.15):\n",
        "        super(MAEThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_mae = logs.get('val_mae')\n",
        "        if val_mae is not None and val_mae <= self.threshold:\n",
        "            print(f'\\nEpoch {epoch+1}: Validation MAE has reached {val_mae:.4f}, stopping training.')\n",
        "            self.model.stop_training = True\n",
        "\n",
        "def MyCallbacks(model_name, patience):\n",
        "    earlystop = EarlyStopping('val_loss', patience=patience, restore_best_weights=True)\n",
        "    checkpoint = ModelCheckpoint(filepath=f'ckpts/{model_name}-' + '{epoch:02d}-{val_loss:.4f}.h5', monitor='val_loss')\n",
        "    mae_threshold_callback = MAEThresholdCallback(threshold=0.015)\n",
        "    return [earlystop, checkpoint]#, mae_threshold_callback]\n",
        "\n",
        "#############################################################################"
      ],
      "metadata": {
        "id": "ETzh0JyBXgRt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Design"
      ],
      "metadata": {
        "id": "cGAz7W4mXqO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#############################################################################\n",
        "def compile_model(new_model, loss):\n",
        "  new_model.compile(optimizer='adam', loss=loss, metrics=['mae']) # metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
        "  print(new_model.summary())\n",
        "  return new_model\n",
        "#############################################################################\n",
        "def MyModel(loss, window_size, n_future, n_features):\n",
        "    new_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer((window_size, n_features)),\n",
        "        # tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1)), # probar esta layer\n",
        "        # tf.keras.layers.experimental.preprocessing.Resizing(125, 125),\n",
        "        tf.keras.layers.Conv1D(16, window_size + n_future, activation='relu', padding='causal'),\n",
        "        tf.keras.layers.MaxPool1D(),\n",
        "        # tf.keras.layers.LSTM(48, return_sequences=True),\n",
        "        # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False)),\n",
        "        # tf.keras.layers.LSTM(48, return_sequences=False),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(n_features * n_future, activation='relu'),\n",
        "        # tf.keras.layers.Dropout(0.4),\n",
        "        # tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Reshape((n_future, n_features)),\n",
        "        # tf.keras.layers.Dense(1)\n",
        "        ])\n",
        "    return compile_model(new_model, loss)"
      ],
      "metadata": {
        "id": "eCESYECOXr45"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "F4yiWWu8FJZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "HWg00hIFX64c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "# data_productos\n",
        "# data_stocks\n",
        "# data_productos_a_predecir\n",
        "# # if __name__ == '__main__':\n",
        "window_size = 3\n",
        "n_future = 2\n",
        "batch_size = 8\n",
        "normalization = 'MinMax'\n",
        "\n",
        "data_all = group_data(data, data_productos_a_predecir)\n",
        "data_all_norm, data_all_norm_params = normalize_data(data_all, normalization=normalization)\n",
        "# data_all_norm['20001'].describe()\n",
        "data_train, data_valid = split_data_all(data_all_norm)\n",
        "# print(data_train.shape)\n",
        "# print(data_valid.shape)\n",
        "data_train_windowed = window_dataset(data_train, data_split='train', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "data_valid_windowed = window_dataset(data_valid, data_split='valid', window_size=window_size, batch_size=batch_size, n_future=n_future)\n",
        "\n"
      ],
      "metadata": {
        "id": "vLrQTz5YEkPk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Train"
      ],
      "metadata": {
        "id": "3MO74bl3X9X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # # #########################################################################\n",
        "# # # # Neural Netowrk Model\n",
        "# # #########################################################################\n",
        "model_name = 'TimeSeries'\n",
        "loss = 'mse'\n",
        "patience = 10\n",
        "epochs = 500\n",
        "n_features = data_all.shape[1]\n",
        "\n",
        "callbacks = MyCallbacks(model_name, patience)\n",
        "# model = MyModel(loss)\n",
        "model = MyModel(loss, window_size, n_future, n_features)\n",
        "\n",
        "history = model.fit(\n",
        "    data_train_windowed,\n",
        "    validation_data = data_valid_windowed,\n",
        "    # callbacks = callbacks,\n",
        "    epochs=epochs)\n",
        "\n",
        "# plot_history(history, 4)\n",
        "# save_model(model, model_name, history, data_test_wrangled)\n",
        "# show_predictions(model, data_test_wrangled, data_test[n_past:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoF2b2xwW2IM",
        "outputId": "a8521717-fdc4-4dfd-eaac-2ccd6e5415bb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_2 (Conv1D)           (None, 3, 16)             62416     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 1, 16)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 64)                12544     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1560)              101400    \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 2, 780)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 176360 (688.91 KB)\n",
            "Trainable params: 176360 (688.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/500\n",
            "3/3 [==============================] - 4s 404ms/step - loss: 0.1966 - mae: 0.3349 - val_loss: 0.2002 - val_mae: 0.3650\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1785 - mae: 0.3173 - val_loss: 0.1855 - val_mae: 0.3449\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1580 - mae: 0.2947 - val_loss: 0.1689 - val_mae: 0.3219\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1389 - mae: 0.2720 - val_loss: 0.1526 - val_mae: 0.2994\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1179 - mae: 0.2460 - val_loss: 0.1395 - val_mae: 0.2817\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0981 - mae: 0.2223 - val_loss: 0.1326 - val_mae: 0.2736\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0880 - mae: 0.2102 - val_loss: 0.1319 - val_mae: 0.2758\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0811 - mae: 0.2035 - val_loss: 0.1340 - val_mae: 0.2808\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0745 - mae: 0.1947 - val_loss: 0.1329 - val_mae: 0.2789\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0684 - mae: 0.1844 - val_loss: 0.1309 - val_mae: 0.2747\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0669 - mae: 0.1808 - val_loss: 0.1300 - val_mae: 0.2727\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0635 - mae: 0.1768 - val_loss: 0.1284 - val_mae: 0.2694\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0638 - mae: 0.1770 - val_loss: 0.1268 - val_mae: 0.2661\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0604 - mae: 0.1698 - val_loss: 0.1270 - val_mae: 0.2672\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0598 - mae: 0.1692 - val_loss: 0.1274 - val_mae: 0.2688\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0588 - mae: 0.1698 - val_loss: 0.1276 - val_mae: 0.2697\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0587 - mae: 0.1682 - val_loss: 0.1263 - val_mae: 0.2673\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0558 - mae: 0.1648 - val_loss: 0.1241 - val_mae: 0.2631\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0574 - mae: 0.1677 - val_loss: 0.1214 - val_mae: 0.2575\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0563 - mae: 0.1644 - val_loss: 0.1198 - val_mae: 0.2539\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0558 - mae: 0.1632 - val_loss: 0.1194 - val_mae: 0.2537\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0554 - mae: 0.1637 - val_loss: 0.1200 - val_mae: 0.2558\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0526 - mae: 0.1595 - val_loss: 0.1202 - val_mae: 0.2567\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0544 - mae: 0.1625 - val_loss: 0.1200 - val_mae: 0.2560\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0533 - mae: 0.1607 - val_loss: 0.1189 - val_mae: 0.2528\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0537 - mae: 0.1603 - val_loss: 0.1178 - val_mae: 0.2504\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0538 - mae: 0.1606 - val_loss: 0.1169 - val_mae: 0.2490\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0510 - mae: 0.1580 - val_loss: 0.1152 - val_mae: 0.2452\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0491 - mae: 0.1539 - val_loss: 0.1143 - val_mae: 0.2431\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0507 - mae: 0.1556 - val_loss: 0.1128 - val_mae: 0.2415\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0496 - mae: 0.1540 - val_loss: 0.1120 - val_mae: 0.2418\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0491 - mae: 0.1523 - val_loss: 0.1103 - val_mae: 0.2385\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0476 - mae: 0.1507 - val_loss: 0.1089 - val_mae: 0.2352\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0479 - mae: 0.1500 - val_loss: 0.1083 - val_mae: 0.2342\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0457 - mae: 0.1478 - val_loss: 0.1076 - val_mae: 0.2330\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0458 - mae: 0.1470 - val_loss: 0.1070 - val_mae: 0.2321\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0448 - mae: 0.1460 - val_loss: 0.1065 - val_mae: 0.2314\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0463 - mae: 0.1479 - val_loss: 0.1057 - val_mae: 0.2300\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0452 - mae: 0.1453 - val_loss: 0.1051 - val_mae: 0.2298\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0450 - mae: 0.1456 - val_loss: 0.1045 - val_mae: 0.2290\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0425 - mae: 0.1411 - val_loss: 0.1040 - val_mae: 0.2286\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0431 - mae: 0.1422 - val_loss: 0.1034 - val_mae: 0.2270\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0422 - mae: 0.1405 - val_loss: 0.1033 - val_mae: 0.2259\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0407 - mae: 0.1368 - val_loss: 0.1031 - val_mae: 0.2255\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0412 - mae: 0.1376 - val_loss: 0.1026 - val_mae: 0.2255\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0415 - mae: 0.1385 - val_loss: 0.1022 - val_mae: 0.2257\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0433 - mae: 0.1413 - val_loss: 0.1021 - val_mae: 0.2248\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0411 - mae: 0.1382 - val_loss: 0.1028 - val_mae: 0.2249\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0448 - mae: 0.1458 - val_loss: 0.1019 - val_mae: 0.2245\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0403 - mae: 0.1360 - val_loss: 0.1024 - val_mae: 0.2262\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0426 - mae: 0.1399 - val_loss: 0.1023 - val_mae: 0.2254\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0420 - mae: 0.1388 - val_loss: 0.1020 - val_mae: 0.2242\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0396 - mae: 0.1361 - val_loss: 0.1019 - val_mae: 0.2239\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0397 - mae: 0.1340 - val_loss: 0.1020 - val_mae: 0.2239\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0388 - mae: 0.1332 - val_loss: 0.1017 - val_mae: 0.2237\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0384 - mae: 0.1329 - val_loss: 0.1014 - val_mae: 0.2240\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0406 - mae: 0.1369 - val_loss: 0.1014 - val_mae: 0.2248\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0391 - mae: 0.1353 - val_loss: 0.1016 - val_mae: 0.2242\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0395 - mae: 0.1354 - val_loss: 0.1015 - val_mae: 0.2239\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0366 - mae: 0.1306 - val_loss: 0.1014 - val_mae: 0.2237\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0351 - mae: 0.1272 - val_loss: 0.1013 - val_mae: 0.2234\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0357 - mae: 0.1279 - val_loss: 0.1012 - val_mae: 0.2234\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0379 - mae: 0.1319 - val_loss: 0.1010 - val_mae: 0.2225\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0380 - mae: 0.1311 - val_loss: 0.1006 - val_mae: 0.2226\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0369 - mae: 0.1307 - val_loss: 0.1006 - val_mae: 0.2223\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0345 - mae: 0.1263 - val_loss: 0.1014 - val_mae: 0.2220\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0363 - mae: 0.1287 - val_loss: 0.1026 - val_mae: 0.2232\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0355 - mae: 0.1273 - val_loss: 0.1020 - val_mae: 0.2223\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0361 - mae: 0.1279 - val_loss: 0.1002 - val_mae: 0.2207\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0328 - mae: 0.1225 - val_loss: 0.0999 - val_mae: 0.2211\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0351 - mae: 0.1263 - val_loss: 0.1002 - val_mae: 0.2210\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0318 - mae: 0.1209 - val_loss: 0.1015 - val_mae: 0.2219\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0325 - mae: 0.1211 - val_loss: 0.1014 - val_mae: 0.2215\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0326 - mae: 0.1207 - val_loss: 0.1004 - val_mae: 0.2205\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0325 - mae: 0.1197 - val_loss: 0.0997 - val_mae: 0.2207\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0328 - mae: 0.1218 - val_loss: 0.0996 - val_mae: 0.2207\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0310 - mae: 0.1182 - val_loss: 0.0998 - val_mae: 0.2202\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0295 - mae: 0.1153 - val_loss: 0.1009 - val_mae: 0.2211\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0337 - mae: 0.1233 - val_loss: 0.1005 - val_mae: 0.2208\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0314 - mae: 0.1195 - val_loss: 0.0997 - val_mae: 0.2211\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0329 - mae: 0.1228 - val_loss: 0.1001 - val_mae: 0.2236\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0310 - mae: 0.1191 - val_loss: 0.0995 - val_mae: 0.2210\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0291 - mae: 0.1140 - val_loss: 0.1002 - val_mae: 0.2200\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0305 - mae: 0.1165 - val_loss: 0.1004 - val_mae: 0.2200\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0300 - mae: 0.1152 - val_loss: 0.0998 - val_mae: 0.2194\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0320 - mae: 0.1193 - val_loss: 0.0994 - val_mae: 0.2201\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0296 - mae: 0.1153 - val_loss: 0.0997 - val_mae: 0.2214\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0279 - mae: 0.1119 - val_loss: 0.0998 - val_mae: 0.2209\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0282 - mae: 0.1125 - val_loss: 0.1002 - val_mae: 0.2202\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0281 - mae: 0.1123 - val_loss: 0.1002 - val_mae: 0.2200\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0267 - mae: 0.1090 - val_loss: 0.0998 - val_mae: 0.2190\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0287 - mae: 0.1131 - val_loss: 0.0995 - val_mae: 0.2188\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0285 - mae: 0.1124 - val_loss: 0.0996 - val_mae: 0.2190\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0285 - mae: 0.1119 - val_loss: 0.0995 - val_mae: 0.2194\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0294 - mae: 0.1140 - val_loss: 0.0995 - val_mae: 0.2194\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0258 - mae: 0.1069 - val_loss: 0.0998 - val_mae: 0.2195\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0300 - mae: 0.1163 - val_loss: 0.0997 - val_mae: 0.2193\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0298 - mae: 0.1155 - val_loss: 0.0994 - val_mae: 0.2194\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0285 - mae: 0.1137 - val_loss: 0.0996 - val_mae: 0.2197\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0282 - mae: 0.1120 - val_loss: 0.1000 - val_mae: 0.2200\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0258 - mae: 0.1069 - val_loss: 0.1003 - val_mae: 0.2203\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0278 - mae: 0.1104 - val_loss: 0.1002 - val_mae: 0.2201\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0264 - mae: 0.1078 - val_loss: 0.1008 - val_mae: 0.2205\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0258 - mae: 0.1068 - val_loss: 0.1010 - val_mae: 0.2207\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0269 - mae: 0.1086 - val_loss: 0.1009 - val_mae: 0.2205\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0286 - mae: 0.1124 - val_loss: 0.1003 - val_mae: 0.2199\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0261 - mae: 0.1067 - val_loss: 0.0999 - val_mae: 0.2208\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0298 - mae: 0.1154 - val_loss: 0.1000 - val_mae: 0.2209\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0267 - mae: 0.1095 - val_loss: 0.1004 - val_mae: 0.2206\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0291 - mae: 0.1142 - val_loss: 0.1010 - val_mae: 0.2208\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0273 - mae: 0.1091 - val_loss: 0.1010 - val_mae: 0.2205\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0260 - mae: 0.1061 - val_loss: 0.1003 - val_mae: 0.2192\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0264 - mae: 0.1082 - val_loss: 0.1000 - val_mae: 0.2186\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0263 - mae: 0.1064 - val_loss: 0.1001 - val_mae: 0.2188\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0267 - mae: 0.1062 - val_loss: 0.1002 - val_mae: 0.2190\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0254 - mae: 0.1053 - val_loss: 0.1002 - val_mae: 0.2192\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0239 - mae: 0.1027 - val_loss: 0.1000 - val_mae: 0.2191\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0268 - mae: 0.1082 - val_loss: 0.0998 - val_mae: 0.2191\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0256 - mae: 0.1060 - val_loss: 0.0997 - val_mae: 0.2194\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0249 - mae: 0.1046 - val_loss: 0.0999 - val_mae: 0.2197\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0225 - mae: 0.0988 - val_loss: 0.1001 - val_mae: 0.2198\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0267 - mae: 0.1075 - val_loss: 0.1001 - val_mae: 0.2197\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0249 - mae: 0.1046 - val_loss: 0.0997 - val_mae: 0.2190\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0241 - mae: 0.1024 - val_loss: 0.0994 - val_mae: 0.2186\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0260 - mae: 0.1058 - val_loss: 0.0993 - val_mae: 0.2189\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0239 - mae: 0.1027 - val_loss: 0.0999 - val_mae: 0.2198\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0253 - mae: 0.1051 - val_loss: 0.1009 - val_mae: 0.2210\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0275 - mae: 0.1109 - val_loss: 0.1006 - val_mae: 0.2204\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0259 - mae: 0.1068 - val_loss: 0.1001 - val_mae: 0.2199\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0232 - mae: 0.1005 - val_loss: 0.1000 - val_mae: 0.2198\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0265 - mae: 0.1096 - val_loss: 0.0995 - val_mae: 0.2189\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0261 - mae: 0.1089 - val_loss: 0.0999 - val_mae: 0.2192\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0260 - mae: 0.1060 - val_loss: 0.1006 - val_mae: 0.2202\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0242 - mae: 0.1026 - val_loss: 0.0996 - val_mae: 0.2191\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0259 - mae: 0.1065 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0223 - mae: 0.0970 - val_loss: 0.1000 - val_mae: 0.2194\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0252 - mae: 0.1047 - val_loss: 0.1005 - val_mae: 0.2201\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0225 - mae: 0.0992 - val_loss: 0.0997 - val_mae: 0.2190\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0223 - mae: 0.0986 - val_loss: 0.0992 - val_mae: 0.2182\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0235 - mae: 0.1028 - val_loss: 0.0997 - val_mae: 0.2187\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0229 - mae: 0.1000 - val_loss: 0.1013 - val_mae: 0.2211\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0235 - mae: 0.1018 - val_loss: 0.1015 - val_mae: 0.2214\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0230 - mae: 0.0996 - val_loss: 0.1003 - val_mae: 0.2195\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0244 - mae: 0.1032 - val_loss: 0.1000 - val_mae: 0.2191\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0227 - mae: 0.0986 - val_loss: 0.1000 - val_mae: 0.2194\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0241 - mae: 0.1024 - val_loss: 0.1002 - val_mae: 0.2200\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0232 - mae: 0.1003 - val_loss: 0.1001 - val_mae: 0.2199\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0242 - mae: 0.1016 - val_loss: 0.0997 - val_mae: 0.2191\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0213 - mae: 0.0969 - val_loss: 0.0996 - val_mae: 0.2190\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0232 - mae: 0.1006 - val_loss: 0.0995 - val_mae: 0.2189\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0245 - mae: 0.1037 - val_loss: 0.0995 - val_mae: 0.2191\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0225 - mae: 0.0997 - val_loss: 0.1000 - val_mae: 0.2195\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0234 - mae: 0.1019 - val_loss: 0.1001 - val_mae: 0.2195\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0213 - mae: 0.0963 - val_loss: 0.1000 - val_mae: 0.2194\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0217 - mae: 0.0972 - val_loss: 0.0997 - val_mae: 0.2189\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0216 - mae: 0.0973 - val_loss: 0.0995 - val_mae: 0.2187\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0217 - mae: 0.0976 - val_loss: 0.0999 - val_mae: 0.2192\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0210 - mae: 0.0953 - val_loss: 0.1008 - val_mae: 0.2205\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0227 - mae: 0.0996 - val_loss: 0.1009 - val_mae: 0.2206\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0220 - mae: 0.0982 - val_loss: 0.1000 - val_mae: 0.2195\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0220 - mae: 0.0977 - val_loss: 0.0992 - val_mae: 0.2188\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0218 - mae: 0.0979 - val_loss: 0.0993 - val_mae: 0.2191\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0200 - mae: 0.0942 - val_loss: 0.1004 - val_mae: 0.2200\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0217 - mae: 0.0977 - val_loss: 0.1016 - val_mae: 0.2216\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0220 - mae: 0.0976 - val_loss: 0.1013 - val_mae: 0.2212\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0233 - mae: 0.1021 - val_loss: 0.1003 - val_mae: 0.2195\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0208 - mae: 0.0945 - val_loss: 0.0998 - val_mae: 0.2186\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0235 - mae: 0.1025 - val_loss: 0.0997 - val_mae: 0.2188\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0210 - mae: 0.0960 - val_loss: 0.1003 - val_mae: 0.2201\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0212 - mae: 0.0960 - val_loss: 0.1006 - val_mae: 0.2208\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0202 - mae: 0.0946 - val_loss: 0.1002 - val_mae: 0.2203\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0214 - mae: 0.0952 - val_loss: 0.0997 - val_mae: 0.2193\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0207 - mae: 0.0942 - val_loss: 0.0995 - val_mae: 0.2190\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0208 - mae: 0.0945 - val_loss: 0.0995 - val_mae: 0.2187\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0196 - mae: 0.0922 - val_loss: 0.1001 - val_mae: 0.2194\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0202 - mae: 0.0931 - val_loss: 0.1001 - val_mae: 0.2193\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0206 - mae: 0.0935 - val_loss: 0.0996 - val_mae: 0.2188\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.0916 - val_loss: 0.0996 - val_mae: 0.2191\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.0920 - val_loss: 0.1001 - val_mae: 0.2198\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0208 - mae: 0.0964 - val_loss: 0.1007 - val_mae: 0.2205\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0209 - mae: 0.0963 - val_loss: 0.1008 - val_mae: 0.2206\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0203 - mae: 0.0943 - val_loss: 0.1000 - val_mae: 0.2193\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.0894 - val_loss: 0.0992 - val_mae: 0.2181\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0203 - mae: 0.0934 - val_loss: 0.0990 - val_mae: 0.2177\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0191 - mae: 0.0907 - val_loss: 0.0987 - val_mae: 0.2179\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0202 - mae: 0.0938 - val_loss: 0.0990 - val_mae: 0.2184\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0177 - mae: 0.0872 - val_loss: 0.0994 - val_mae: 0.2190\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.0885 - val_loss: 0.0995 - val_mae: 0.2191\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0193 - mae: 0.0903 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0181 - mae: 0.0879 - val_loss: 0.0991 - val_mae: 0.2183\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0189 - mae: 0.0910 - val_loss: 0.0989 - val_mae: 0.2180\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0195 - mae: 0.0926 - val_loss: 0.0990 - val_mae: 0.2180\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0208 - mae: 0.0953 - val_loss: 0.0993 - val_mae: 0.2185\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.0884 - val_loss: 0.0995 - val_mae: 0.2191\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0167 - mae: 0.0847 - val_loss: 0.0995 - val_mae: 0.2193\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0203 - mae: 0.0939 - val_loss: 0.0995 - val_mae: 0.2195\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0211 - mae: 0.0962 - val_loss: 0.0993 - val_mae: 0.2190\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.0885 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0187 - mae: 0.0899 - val_loss: 0.0997 - val_mae: 0.2190\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0192 - mae: 0.0912 - val_loss: 0.0995 - val_mae: 0.2187\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0200 - mae: 0.0928 - val_loss: 0.0991 - val_mae: 0.2185\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.0927 - val_loss: 0.0990 - val_mae: 0.2190\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0192 - mae: 0.0915 - val_loss: 0.0989 - val_mae: 0.2192\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0205 - mae: 0.0945 - val_loss: 0.0989 - val_mae: 0.2186\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0215 - mae: 0.0962 - val_loss: 0.0990 - val_mae: 0.2184\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0184 - mae: 0.0891 - val_loss: 0.0988 - val_mae: 0.2186\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0186 - mae: 0.0904 - val_loss: 0.0988 - val_mae: 0.2190\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0197 - mae: 0.0917 - val_loss: 0.0987 - val_mae: 0.2186\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0179 - mae: 0.0886 - val_loss: 0.0987 - val_mae: 0.2178\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0202 - mae: 0.0936 - val_loss: 0.0988 - val_mae: 0.2174\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0197 - mae: 0.0933 - val_loss: 0.0987 - val_mae: 0.2172\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0184 - mae: 0.0892 - val_loss: 0.0985 - val_mae: 0.2170\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.0889 - val_loss: 0.0987 - val_mae: 0.2173\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0189 - mae: 0.0909 - val_loss: 0.0993 - val_mae: 0.2183\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0187 - mae: 0.0904 - val_loss: 0.1003 - val_mae: 0.2196\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0212 - mae: 0.0977 - val_loss: 0.1008 - val_mae: 0.2203\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0184 - mae: 0.0896 - val_loss: 0.0999 - val_mae: 0.2190\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0205 - mae: 0.0951 - val_loss: 0.0992 - val_mae: 0.2184\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0194 - mae: 0.0918 - val_loss: 0.0993 - val_mae: 0.2189\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0204 - mae: 0.0946 - val_loss: 0.0995 - val_mae: 0.2189\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0160 - mae: 0.0840 - val_loss: 0.0995 - val_mae: 0.2189\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0187 - mae: 0.0906 - val_loss: 0.0996 - val_mae: 0.2189\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0170 - mae: 0.0864 - val_loss: 0.0999 - val_mae: 0.2192\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0174 - mae: 0.0854 - val_loss: 0.1004 - val_mae: 0.2201\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0177 - mae: 0.0874 - val_loss: 0.1009 - val_mae: 0.2210\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0174 - mae: 0.0879 - val_loss: 0.1010 - val_mae: 0.2210\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0177 - mae: 0.0881 - val_loss: 0.1005 - val_mae: 0.2201\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0173 - mae: 0.0874 - val_loss: 0.0995 - val_mae: 0.2182\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.0918 - val_loss: 0.0992 - val_mae: 0.2175\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0200 - mae: 0.0933 - val_loss: 0.0991 - val_mae: 0.2174\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0197 - mae: 0.0916 - val_loss: 0.0991 - val_mae: 0.2177\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0170 - mae: 0.0855 - val_loss: 0.0993 - val_mae: 0.2183\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0164 - mae: 0.0845 - val_loss: 0.0997 - val_mae: 0.2192\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0166 - mae: 0.0854 - val_loss: 0.1001 - val_mae: 0.2200\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0174 - mae: 0.0874 - val_loss: 0.1004 - val_mae: 0.2203\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0193 - mae: 0.0924 - val_loss: 0.0998 - val_mae: 0.2190\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0155 - mae: 0.0817 - val_loss: 0.0997 - val_mae: 0.2185\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0194 - mae: 0.0914 - val_loss: 0.0995 - val_mae: 0.2182\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0174 - mae: 0.0860 - val_loss: 0.0993 - val_mae: 0.2178\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0199 - mae: 0.0933 - val_loss: 0.0994 - val_mae: 0.2180\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0185 - mae: 0.0899 - val_loss: 0.1004 - val_mae: 0.2197\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0167 - mae: 0.0851 - val_loss: 0.1006 - val_mae: 0.2202\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.0846 - val_loss: 0.1002 - val_mae: 0.2198\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0159 - mae: 0.0838 - val_loss: 0.1000 - val_mae: 0.2194\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0166 - mae: 0.0844 - val_loss: 0.1000 - val_mae: 0.2193\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.0876 - val_loss: 0.1001 - val_mae: 0.2193\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0165 - mae: 0.0833 - val_loss: 0.0999 - val_mae: 0.2189\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0186 - mae: 0.0892 - val_loss: 0.0995 - val_mae: 0.2185\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0201 - mae: 0.0935 - val_loss: 0.0996 - val_mae: 0.2185\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0153 - mae: 0.0813 - val_loss: 0.1000 - val_mae: 0.2189\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0194 - mae: 0.0915 - val_loss: 0.0999 - val_mae: 0.2187\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0197 - mae: 0.0930 - val_loss: 0.0997 - val_mae: 0.2186\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0173 - mae: 0.0858 - val_loss: 0.1001 - val_mae: 0.2193\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0801 - val_loss: 0.1005 - val_mae: 0.2199\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0177 - mae: 0.0864 - val_loss: 0.1001 - val_mae: 0.2191\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0148 - mae: 0.0793 - val_loss: 0.0996 - val_mae: 0.2184\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0158 - mae: 0.0811 - val_loss: 0.0992 - val_mae: 0.2182\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0201 - mae: 0.0916 - val_loss: 0.0991 - val_mae: 0.2180\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0168 - mae: 0.0848 - val_loss: 0.0993 - val_mae: 0.2181\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0178 - mae: 0.0883 - val_loss: 0.0995 - val_mae: 0.2187\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0155 - mae: 0.0810 - val_loss: 0.0998 - val_mae: 0.2190\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0167 - mae: 0.0841 - val_loss: 0.0998 - val_mae: 0.2190\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0151 - mae: 0.0809 - val_loss: 0.0995 - val_mae: 0.2183\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0160 - mae: 0.0833 - val_loss: 0.0991 - val_mae: 0.2177\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0161 - mae: 0.0830 - val_loss: 0.0994 - val_mae: 0.2182\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0152 - mae: 0.0810 - val_loss: 0.0996 - val_mae: 0.2186\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0791 - val_loss: 0.0995 - val_mae: 0.2182\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0147 - mae: 0.0786 - val_loss: 0.0999 - val_mae: 0.2187\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0174 - mae: 0.0862 - val_loss: 0.1007 - val_mae: 0.2199\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0163 - mae: 0.0843 - val_loss: 0.1006 - val_mae: 0.2197\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0155 - mae: 0.0804 - val_loss: 0.1001 - val_mae: 0.2190\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0145 - mae: 0.0780 - val_loss: 0.0995 - val_mae: 0.2184\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0154 - mae: 0.0821 - val_loss: 0.0992 - val_mae: 0.2181\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0159 - mae: 0.0841 - val_loss: 0.0994 - val_mae: 0.2183\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0177 - mae: 0.0882 - val_loss: 0.0996 - val_mae: 0.2187\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.0903 - val_loss: 0.0994 - val_mae: 0.2187\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0162 - mae: 0.0854 - val_loss: 0.0994 - val_mae: 0.2192\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0167 - mae: 0.0849 - val_loss: 0.0994 - val_mae: 0.2196\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0162 - mae: 0.0836 - val_loss: 0.0991 - val_mae: 0.2188\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0164 - mae: 0.0848 - val_loss: 0.0991 - val_mae: 0.2184\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0169 - mae: 0.0852 - val_loss: 0.0994 - val_mae: 0.2183\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0794 - val_loss: 0.0999 - val_mae: 0.2190\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0160 - mae: 0.0828 - val_loss: 0.0995 - val_mae: 0.2183\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0805 - val_loss: 0.0990 - val_mae: 0.2179\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0800 - val_loss: 0.0993 - val_mae: 0.2190\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0170 - mae: 0.0862 - val_loss: 0.0994 - val_mae: 0.2185\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0159 - mae: 0.0846 - val_loss: 0.0998 - val_mae: 0.2185\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0175 - mae: 0.0876 - val_loss: 0.1001 - val_mae: 0.2190\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.0859 - val_loss: 0.0994 - val_mae: 0.2180\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0174 - mae: 0.0864 - val_loss: 0.0991 - val_mae: 0.2183\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0162 - mae: 0.0841 - val_loss: 0.0997 - val_mae: 0.2202\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0161 - mae: 0.0841 - val_loss: 0.0994 - val_mae: 0.2190\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0167 - mae: 0.0856 - val_loss: 0.0996 - val_mae: 0.2186\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.0888 - val_loss: 0.1005 - val_mae: 0.2197\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0168 - mae: 0.0845 - val_loss: 0.1009 - val_mae: 0.2203\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0156 - mae: 0.0825 - val_loss: 0.1000 - val_mae: 0.2189\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - mae: 0.0784 - val_loss: 0.0995 - val_mae: 0.2184\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0150 - mae: 0.0802 - val_loss: 0.0994 - val_mae: 0.2186\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0168 - mae: 0.0851 - val_loss: 0.0997 - val_mae: 0.2193\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0148 - mae: 0.0801 - val_loss: 0.0997 - val_mae: 0.2193\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0150 - mae: 0.0809 - val_loss: 0.0993 - val_mae: 0.2187\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0790 - val_loss: 0.0989 - val_mae: 0.2181\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0157 - mae: 0.0822 - val_loss: 0.0988 - val_mae: 0.2180\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.0713 - val_loss: 0.0987 - val_mae: 0.2181\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0151 - mae: 0.0811 - val_loss: 0.0986 - val_mae: 0.2182\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - mae: 0.0771 - val_loss: 0.0990 - val_mae: 0.2188\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0128 - mae: 0.0741 - val_loss: 0.0993 - val_mae: 0.2192\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0154 - mae: 0.0801 - val_loss: 0.0995 - val_mae: 0.2196\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0790 - val_loss: 0.0996 - val_mae: 0.2195\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0151 - mae: 0.0820 - val_loss: 0.0995 - val_mae: 0.2189\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0153 - mae: 0.0813 - val_loss: 0.0991 - val_mae: 0.2181\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0145 - mae: 0.0796 - val_loss: 0.0990 - val_mae: 0.2175\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0751 - val_loss: 0.0990 - val_mae: 0.2174\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.0858 - val_loss: 0.0994 - val_mae: 0.2179\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0766 - val_loss: 0.0995 - val_mae: 0.2181\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0137 - mae: 0.0767 - val_loss: 0.0998 - val_mae: 0.2184\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0780 - val_loss: 0.1000 - val_mae: 0.2186\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0144 - mae: 0.0778 - val_loss: 0.1005 - val_mae: 0.2195\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0742 - val_loss: 0.1002 - val_mae: 0.2190\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0148 - mae: 0.0785 - val_loss: 0.0997 - val_mae: 0.2182\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0133 - mae: 0.0754 - val_loss: 0.0997 - val_mae: 0.2183\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0126 - mae: 0.0726 - val_loss: 0.0999 - val_mae: 0.2189\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0131 - mae: 0.0749 - val_loss: 0.0999 - val_mae: 0.2191\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0157 - mae: 0.0818 - val_loss: 0.0997 - val_mae: 0.2186\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0165 - mae: 0.0851 - val_loss: 0.0998 - val_mae: 0.2188\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0804 - val_loss: 0.0999 - val_mae: 0.2189\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0141 - mae: 0.0780 - val_loss: 0.0996 - val_mae: 0.2184\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0151 - mae: 0.0812 - val_loss: 0.0994 - val_mae: 0.2181\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0790 - val_loss: 0.0993 - val_mae: 0.2182\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0157 - mae: 0.0831 - val_loss: 0.0993 - val_mae: 0.2186\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0779 - val_loss: 0.0996 - val_mae: 0.2197\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - mae: 0.0792 - val_loss: 0.0998 - val_mae: 0.2200\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0144 - mae: 0.0782 - val_loss: 0.0995 - val_mae: 0.2191\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0784 - val_loss: 0.0994 - val_mae: 0.2187\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0141 - mae: 0.0776 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0150 - mae: 0.0795 - val_loss: 0.0994 - val_mae: 0.2190\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.0716 - val_loss: 0.0997 - val_mae: 0.2195\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0166 - mae: 0.0834 - val_loss: 0.0998 - val_mae: 0.2197\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - mae: 0.0776 - val_loss: 0.0995 - val_mae: 0.2194\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0135 - mae: 0.0774 - val_loss: 0.0991 - val_mae: 0.2183\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0134 - mae: 0.0776 - val_loss: 0.0989 - val_mae: 0.2176\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0813 - val_loss: 0.0994 - val_mae: 0.2182\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0131 - mae: 0.0742 - val_loss: 0.0999 - val_mae: 0.2191\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - mae: 0.0786 - val_loss: 0.1002 - val_mae: 0.2197\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - mae: 0.0790 - val_loss: 0.1001 - val_mae: 0.2197\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0803 - val_loss: 0.0997 - val_mae: 0.2188\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0759 - val_loss: 0.0992 - val_mae: 0.2180\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0132 - mae: 0.0752 - val_loss: 0.0989 - val_mae: 0.2174\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0763 - val_loss: 0.0987 - val_mae: 0.2175\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0123 - mae: 0.0736 - val_loss: 0.0988 - val_mae: 0.2179\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0770 - val_loss: 0.0989 - val_mae: 0.2181\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - mae: 0.0769 - val_loss: 0.0988 - val_mae: 0.2182\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0109 - mae: 0.0680 - val_loss: 0.0990 - val_mae: 0.2183\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0127 - mae: 0.0740 - val_loss: 0.0991 - val_mae: 0.2186\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - mae: 0.0800 - val_loss: 0.0991 - val_mae: 0.2183\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0753 - val_loss: 0.0990 - val_mae: 0.2178\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0135 - mae: 0.0772 - val_loss: 0.0997 - val_mae: 0.2186\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0148 - mae: 0.0784 - val_loss: 0.1002 - val_mae: 0.2195\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0152 - mae: 0.0807 - val_loss: 0.1000 - val_mae: 0.2191\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0128 - mae: 0.0742 - val_loss: 0.0997 - val_mae: 0.2187\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.0708 - val_loss: 0.0993 - val_mae: 0.2180\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0128 - mae: 0.0744 - val_loss: 0.0990 - val_mae: 0.2176\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0125 - mae: 0.0727 - val_loss: 0.0991 - val_mae: 0.2180\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0120 - mae: 0.0724 - val_loss: 0.0996 - val_mae: 0.2190\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0791 - val_loss: 0.0997 - val_mae: 0.2195\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0135 - mae: 0.0754 - val_loss: 0.0999 - val_mae: 0.2200\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0790 - val_loss: 0.1001 - val_mae: 0.2205\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0790 - val_loss: 0.1003 - val_mae: 0.2209\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0811 - val_loss: 0.1003 - val_mae: 0.2208\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0775 - val_loss: 0.1003 - val_mae: 0.2206\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0138 - mae: 0.0770 - val_loss: 0.0999 - val_mae: 0.2194\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0131 - mae: 0.0749 - val_loss: 0.0996 - val_mae: 0.2187\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0125 - mae: 0.0724 - val_loss: 0.0994 - val_mae: 0.2182\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0121 - mae: 0.0712 - val_loss: 0.0992 - val_mae: 0.2181\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0145 - mae: 0.0766 - val_loss: 0.0993 - val_mae: 0.2185\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0722 - val_loss: 0.0996 - val_mae: 0.2191\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0132 - mae: 0.0764 - val_loss: 0.1001 - val_mae: 0.2200\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0123 - mae: 0.0716 - val_loss: 0.1002 - val_mae: 0.2201\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0163 - mae: 0.0828 - val_loss: 0.0997 - val_mae: 0.2195\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0783 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0672 - val_loss: 0.0993 - val_mae: 0.2184\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0112 - mae: 0.0698 - val_loss: 0.0991 - val_mae: 0.2179\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0165 - mae: 0.0850 - val_loss: 0.0993 - val_mae: 0.2183\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0136 - mae: 0.0754 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0135 - mae: 0.0780 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0726 - val_loss: 0.0997 - val_mae: 0.2190\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0771 - val_loss: 0.0998 - val_mae: 0.2191\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0118 - mae: 0.0715 - val_loss: 0.0999 - val_mae: 0.2196\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0135 - mae: 0.0750 - val_loss: 0.0997 - val_mae: 0.2191\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0149 - mae: 0.0799 - val_loss: 0.0993 - val_mae: 0.2184\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0113 - mae: 0.0697 - val_loss: 0.0991 - val_mae: 0.2179\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0130 - mae: 0.0743 - val_loss: 0.0992 - val_mae: 0.2181\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0142 - mae: 0.0768 - val_loss: 0.0993 - val_mae: 0.2184\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0131 - mae: 0.0753 - val_loss: 0.0995 - val_mae: 0.2186\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0144 - mae: 0.0799 - val_loss: 0.0999 - val_mae: 0.2192\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0116 - mae: 0.0699 - val_loss: 0.0999 - val_mae: 0.2192\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0148 - mae: 0.0799 - val_loss: 0.0994 - val_mae: 0.2186\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0121 - mae: 0.0720 - val_loss: 0.0993 - val_mae: 0.2189\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0151 - mae: 0.0809 - val_loss: 0.0994 - val_mae: 0.2193\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0118 - mae: 0.0727 - val_loss: 0.0994 - val_mae: 0.2190\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0158 - mae: 0.0834 - val_loss: 0.0994 - val_mae: 0.2187\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0140 - mae: 0.0778 - val_loss: 0.0992 - val_mae: 0.2188\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.0669 - val_loss: 0.0992 - val_mae: 0.2193\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0127 - mae: 0.0745 - val_loss: 0.0994 - val_mae: 0.2195\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.0707 - val_loss: 0.0995 - val_mae: 0.2195\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0115 - mae: 0.0697 - val_loss: 0.0995 - val_mae: 0.2197\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0127 - mae: 0.0740 - val_loss: 0.0995 - val_mae: 0.2194\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0112 - mae: 0.0696 - val_loss: 0.0993 - val_mae: 0.2189\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0099 - mae: 0.0658 - val_loss: 0.0991 - val_mae: 0.2182\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0110 - mae: 0.0699 - val_loss: 0.0989 - val_mae: 0.2176\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0113 - mae: 0.0704 - val_loss: 0.0988 - val_mae: 0.2173\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.0699 - val_loss: 0.0990 - val_mae: 0.2176\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0121 - mae: 0.0717 - val_loss: 0.0991 - val_mae: 0.2178\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0129 - mae: 0.0745 - val_loss: 0.0991 - val_mae: 0.2179\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0103 - mae: 0.0662 - val_loss: 0.0993 - val_mae: 0.2183\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0106 - mae: 0.0682 - val_loss: 0.0993 - val_mae: 0.2185\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0112 - mae: 0.0694 - val_loss: 0.0992 - val_mae: 0.2182\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.0701 - val_loss: 0.0994 - val_mae: 0.2182\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0100 - mae: 0.0651 - val_loss: 0.1000 - val_mae: 0.2189\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.0717 - val_loss: 0.1001 - val_mae: 0.2192\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0129 - mae: 0.0743 - val_loss: 0.0996 - val_mae: 0.2186\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0119 - mae: 0.0717 - val_loss: 0.0991 - val_mae: 0.2183\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0125 - mae: 0.0743 - val_loss: 0.0994 - val_mae: 0.2194\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0140 - mae: 0.0785 - val_loss: 0.0993 - val_mae: 0.2197\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0133 - mae: 0.0733 - val_loss: 0.0990 - val_mae: 0.2188\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0094 - mae: 0.0641 - val_loss: 0.0990 - val_mae: 0.2184\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0129 - mae: 0.0736 - val_loss: 0.0989 - val_mae: 0.2182\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0149 - mae: 0.0804 - val_loss: 0.0990 - val_mae: 0.2186\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0131 - mae: 0.0759 - val_loss: 0.0994 - val_mae: 0.2196\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0126 - mae: 0.0744 - val_loss: 0.0992 - val_mae: 0.2194\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0115 - mae: 0.0712 - val_loss: 0.0991 - val_mae: 0.2190\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0104 - mae: 0.0677 - val_loss: 0.0994 - val_mae: 0.2188\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0158 - mae: 0.0825 - val_loss: 0.0997 - val_mae: 0.2190\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0153 - mae: 0.0801 - val_loss: 0.0995 - val_mae: 0.2187\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0131 - mae: 0.0744 - val_loss: 0.0990 - val_mae: 0.2182\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0117 - mae: 0.0707 - val_loss: 0.0989 - val_mae: 0.2183\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0128 - mae: 0.0733 - val_loss: 0.0990 - val_mae: 0.2186\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0095 - mae: 0.0645 - val_loss: 0.0992 - val_mae: 0.2187\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0124 - mae: 0.0731 - val_loss: 0.0991 - val_mae: 0.2183\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0115 - mae: 0.0717 - val_loss: 0.0992 - val_mae: 0.2182\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0680 - val_loss: 0.0994 - val_mae: 0.2186\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0120 - mae: 0.0724 - val_loss: 0.0998 - val_mae: 0.2193\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.0702 - val_loss: 0.1003 - val_mae: 0.2202\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0754 - val_loss: 0.1004 - val_mae: 0.2204\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0131 - mae: 0.0761 - val_loss: 0.1002 - val_mae: 0.2199\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0784 - val_loss: 0.1000 - val_mae: 0.2194\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0099 - mae: 0.0640 - val_loss: 0.0998 - val_mae: 0.2194\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0121 - mae: 0.0725 - val_loss: 0.0998 - val_mae: 0.2199\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0109 - mae: 0.0688 - val_loss: 0.0999 - val_mae: 0.2201\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0128 - mae: 0.0745 - val_loss: 0.1001 - val_mae: 0.2207\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0118 - mae: 0.0713 - val_loss: 0.1003 - val_mae: 0.2213\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0132 - mae: 0.0754 - val_loss: 0.1002 - val_mae: 0.2210\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0781 - val_loss: 0.1000 - val_mae: 0.2205\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0133 - mae: 0.0765 - val_loss: 0.1000 - val_mae: 0.2204\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0102 - mae: 0.0662 - val_loss: 0.1001 - val_mae: 0.2204\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0133 - mae: 0.0758 - val_loss: 0.1000 - val_mae: 0.2202\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0087 - mae: 0.0613 - val_loss: 0.0996 - val_mae: 0.2196\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0108 - mae: 0.0686 - val_loss: 0.0991 - val_mae: 0.2190\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0124 - mae: 0.0734 - val_loss: 0.0990 - val_mae: 0.2186\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0087 - mae: 0.0599 - val_loss: 0.0991 - val_mae: 0.2181\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0155 - mae: 0.0811 - val_loss: 0.0990 - val_mae: 0.2178\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0108 - mae: 0.0676 - val_loss: 0.0990 - val_mae: 0.2181\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0157 - mae: 0.0784 - val_loss: 0.0990 - val_mae: 0.2184\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0137 - mae: 0.0774 - val_loss: 0.0989 - val_mae: 0.2185\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0110 - mae: 0.0697 - val_loss: 0.0988 - val_mae: 0.2181\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0114 - mae: 0.0707 - val_loss: 0.0988 - val_mae: 0.2182\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0098 - mae: 0.0648 - val_loss: 0.0988 - val_mae: 0.2184\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0110 - mae: 0.0686 - val_loss: 0.0990 - val_mae: 0.2188\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0739 - val_loss: 0.0990 - val_mae: 0.2186\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0145 - mae: 0.0770 - val_loss: 0.0991 - val_mae: 0.2186\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0111 - mae: 0.0684 - val_loss: 0.0991 - val_mae: 0.2186\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0108 - mae: 0.0680 - val_loss: 0.0993 - val_mae: 0.2192\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0093 - mae: 0.0641 - val_loss: 0.0992 - val_mae: 0.2193\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0119 - mae: 0.0713 - val_loss: 0.0990 - val_mae: 0.2189\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0121 - mae: 0.0723 - val_loss: 0.0989 - val_mae: 0.2186\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.0655 - val_loss: 0.0988 - val_mae: 0.2186\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0773 - val_loss: 0.0987 - val_mae: 0.2185\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0111 - mae: 0.0685 - val_loss: 0.0989 - val_mae: 0.2184\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0126 - mae: 0.0743 - val_loss: 0.0994 - val_mae: 0.2189\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0121 - mae: 0.0712 - val_loss: 0.1000 - val_mae: 0.2197\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0108 - mae: 0.0695 - val_loss: 0.1001 - val_mae: 0.2201\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0100 - mae: 0.0654 - val_loss: 0.0999 - val_mae: 0.2201\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0096 - mae: 0.0642 - val_loss: 0.0997 - val_mae: 0.2197\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0102 - mae: 0.0659 - val_loss: 0.0993 - val_mae: 0.2187\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0739 - val_loss: 0.0989 - val_mae: 0.2178\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0143 - mae: 0.0777 - val_loss: 0.0989 - val_mae: 0.2176\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0104 - mae: 0.0667 - val_loss: 0.0991 - val_mae: 0.2178\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0125 - mae: 0.0739 - val_loss: 0.0991 - val_mae: 0.2180\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0786 - val_loss: 0.0986 - val_mae: 0.2176\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0095 - mae: 0.0641 - val_loss: 0.0985 - val_mae: 0.2178\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0099 - mae: 0.0656 - val_loss: 0.0988 - val_mae: 0.2191\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0135 - mae: 0.0764 - val_loss: 0.0989 - val_mae: 0.2197\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0134 - mae: 0.0755 - val_loss: 0.0992 - val_mae: 0.2202\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0118 - mae: 0.0706 - val_loss: 0.0994 - val_mae: 0.2205\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0100 - mae: 0.0654 - val_loss: 0.0994 - val_mae: 0.2201\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0132 - mae: 0.0767 - val_loss: 0.0994 - val_mae: 0.2198\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0096 - mae: 0.0638 - val_loss: 0.0993 - val_mae: 0.2196\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0096 - mae: 0.0647 - val_loss: 0.0993 - val_mae: 0.2195\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0114 - mae: 0.0699 - val_loss: 0.0992 - val_mae: 0.2194\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.0121 - mae: 0.0718 - val_loss: 0.0993 - val_mae: 0.2193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Supongamos que `data_all` contiene tus datos históricos, incluyendo 2019.\n",
        "# data_all debe tener la forma (n_samples, n_features)\n",
        "\n",
        "# Convertir el DataFrame a un array de NumPy\n",
        "data_all_array = data_all.values\n",
        "\n",
        "# Extraer la última ventana de datos de 2019 para predecir enero de 2020\n",
        "# window_size = 12  # Ya definido anteriormente\n",
        "# n_features = data_all.shape[1]  # Ya definido anteriormente\n",
        "column_names = data_all.columns  # Obtener los nombres de las columnas\n",
        "\n",
        "# Extraer los últimos `window_size` meses de 2019\n",
        "input_data = data_all_array[-window_size:].reshape((1, window_size, n_features))\n",
        "\n",
        "# Predecir enero de 2020\n",
        "pred_january = model.predict(input_data)\n",
        "\n",
        "# Asegurarse de que la predicción tenga la forma correcta\n",
        "pred_january = pred_january.reshape((1, n_future, n_features))\n",
        "\n",
        "# Crear un DataFrame para la predicción de enero de 2020\n",
        "pred_january_df = pd.DataFrame(pred_january[0], columns=column_names)\n",
        "pred_january_df.index = pd.date_range(start='2020-01-01', periods=n_future, freq='MS')\n",
        "\n",
        "# Actualizar la ventana de entrada para predecir febrero de 2020\n",
        "input_data = np.append(input_data[:, 1:, :], pred_january[:, 0, :].reshape(1, 1, n_features), axis=1)\n",
        "\n",
        "# Predecir febrero de 2020\n",
        "pred_february = model.predict(input_data)\n",
        "\n",
        "# Asegurarse de que la predicción tenga la forma correcta\n",
        "pred_february = pred_february.reshape((1, n_future, n_features))\n",
        "\n",
        "# Crear un DataFrame para la predicción de febrero de 2020\n",
        "pred_february_df = pd.DataFrame(pred_february[0], columns=column_names)\n",
        "pred_february_df.index = pd.date_range(start='2020-02-01', periods=n_future, freq='MS')\n",
        "\n",
        "# Mostrar las predicciones\n",
        "print(\"Predicción para enero de 2020:\")\n",
        "print(pred_january_df)\n",
        "\n",
        "print(\"Predicción para febrero de 2020:\")\n",
        "print(pred_february_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CllkIp6PbPVx",
        "outputId": "3305099f-d90f-473b-9fb3-0e66eb159534"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 754ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Predicción para enero de 2020:\n",
            "            20001  20002  20003  20004  20005  20006  20007  20008  20009  \\\n",
            "2020-01-01   0.55   0.24   0.72   0.74   0.62   0.46   0.41   0.51   0.32   \n",
            "2020-02-01   0.24   0.39   0.61   0.35   0.08   0.38   0.17   0.30   0.42   \n",
            "\n",
            "            20010  ...  21248  21252  21256  21259  21262  21263  21265  \\\n",
            "2020-01-01   0.64  ...   0.12   0.00   0.07   0.10   0.07   0.10   0.00   \n",
            "2020-02-01   0.43  ...   0.22   0.00   0.13   0.14   0.27   0.29   0.00   \n",
            "\n",
            "            21266  21267  21276  \n",
            "2020-01-01   0.00   0.00   0.00  \n",
            "2020-02-01   0.00   0.00   0.00  \n",
            "\n",
            "[2 rows x 780 columns]\n",
            "Predicción para febrero de 2020:\n",
            "            20001  20002  20003  20004  20005  20006  20007  20008  20009  \\\n",
            "2020-02-01   0.39   0.12   0.69   0.69   0.50   0.46   0.33   0.40   0.18   \n",
            "2020-03-01   0.36   0.27   0.51   0.19   0.03   0.41   0.30   0.36   0.36   \n",
            "\n",
            "            20010  ...  21248  21252  21256  21259  21262  21263  21265  \\\n",
            "2020-02-01   0.63  ...   0.00   0.00   0.00   0.00   0.00   0.00   0.00   \n",
            "2020-03-01   0.39  ...   0.09   0.00   0.00   0.00   0.00   0.09   0.00   \n",
            "\n",
            "            21266  21267  21276  \n",
            "2020-02-01   0.00   0.00   0.00  \n",
            "2020-03-01   0.00   0.00   0.00  \n",
            "\n",
            "[2 rows x 780 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predije dos veces, una volviendo a entrenar con los datos predichos de Enero 2020, y la otra no.\n",
        "pred_1 = pred_january_df.loc['2020-02-01']\n",
        "pred_2 = pred_february_df.loc['2020-02-01']\n",
        "\n",
        "# Ojo que hay que agregar los nombres de las columnas: product_id,tn\n",
        "pred_1_denorm = denormalize_series(pred_1, data_all_norm_params, normalization=normalization)\n",
        "data_pred1_denorm = pred_1_denorm.reset_index()\n",
        "data_pred1_denorm.columns = ['product_id', 'tn']\n",
        "data_pred1_denorm.to_csv('pred_1.csv', index=False)\n",
        "\n",
        "pred_2_denorm = denormalize_series(pred_2, data_all_norm_params, normalization=normalization)\n",
        "data_pred2_denorm = pred_2_denorm.reset_index()\n",
        "data_pred2_denorm.columns = ['product_id', 'tn']\n",
        "data_pred2_denorm.to_csv('pred_2.csv', index=False)"
      ],
      "metadata": {
        "id": "Cx8zvFfqbgd4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtiNAaHJBflZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}